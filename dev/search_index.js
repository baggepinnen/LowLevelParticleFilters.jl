var documenterSearchIndex = {"docs":
[{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"","category":"page"},{"location":"api/","page":"API","title":"API","text":"Modules = [LowLevelParticleFilters]\nPrivate = false","category":"page"},{"location":"api/#LowLevelParticleFilters.AdvancedParticleFilter-Tuple{Integer, Function, Function, Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.AdvancedParticleFilter","text":"AdvancedParticleFilter(N::Integer, dynamics::Function, measurement::Function, measurement_likelihood, dynamics_density, initial_density; p = SciMLBase.NullParameters(), threads = false, kwargs...)\n\nThis type represents a standard particle filter but affords extra flexibility compared to the ParticleFilter type, e.g., non-additive noise in the dynamics and measurement functions.\n\nSee the docs for more information: https://baggepinnen.github.io/LowLevelParticleFilters.jl/stable/#AdvancedParticleFilter-1\n\nArguments:\n\nN: Number of particles\ndynamics: A discrete-time dynamics function (x, u, p, t, noise=false) -> x⁺. It's important that the noise argument defaults to false.\nmeasurement: A measurement function (x, u, p, t, noise=false) -> y. It's important that the noise argument defaults to false.\nmeasurement_likelihood: A function (x, u, y, p, t)->logl to evaluate the log-likelihood of a measurement.\ndynamics_density: This field is not used by the advanced filter and can be set to nothing.\ninitial_density: The distribution of the initial state.\nthreads: use threads to propagate particles in parallel. Only activate this if your dynamics is thread-safe. SeeToDee.SimpleColloc is not thread-safe by default due to the use of internal caches, but SeeToDee.Rk4 is.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.AuxiliaryParticleFilter-Tuple","page":"API","title":"LowLevelParticleFilters.AuxiliaryParticleFilter","text":"AuxiliaryParticleFilter(args...; kwargs...)\n\nTakes exactly the same arguments as ParticleFilter, or an instance of ParticleFilter.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.DAEUnscentedKalmanFilter-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.DAEUnscentedKalmanFilter","text":"DAEUnscentedKalmanFilter(ukf; g, get_x_z, build_xz, xz0, threads=false)\n\nAn Unscented Kalman filter for differential-algebraic systems (DAE).\n\nRef: \"Nonlinear State Estimation of Differential Algebraic Systems\",  Mandela, Rengaswamy, Narasimhan\n\nwarning: Warning\nThis filter is still considered experimental and subject to change without respecting semantic versioning. Use at your own risk.\n\nArguments\n\nukf is a regular UnscentedKalmanFilter that contains dynamics(xz, u, p, t) that propagates the combined state xz(k) to xz(k+1) and a measurement function with signature (xz, u, p, t)\ng(x, z, u, p, t) is a function that should fulfill g(x, z, u, p, t) = 0\nget_x_z(xz) -> x, z is a function that decomposes xz into x and z\nbuild_xz(x, z) is the inverse of get_x_z\nxz0 the initial full state.\nthreads: If true, evaluates dynamics on sigma points in parallel. This typically requires the dynamics to be non-allocating (use StaticArrays) to improve performance. \n\nAssumptions\n\nThe DAE dynamics is index 1 and can be written on the form \n\nbeginaligned\nx = f(x z u p t) quad textDifferential equations\n0 = g(x z u p t) quad textAlgebraic equations\ny = h(x z u p t) quad textMeasurements\nbeginaligned\n\nthe measurements may be functions of both differential state variables x and algebraic variables z. Please note, the actual dynamics and measurement functions stored in the internal ukf should have signatures (xz, u, p, t), i.e., they take the combined state (descriptor) containing both x and z in a single vector as dictated by the function build_xz. It is only the function g that is assumed to actually have the signature g(x,z,u,p,t).\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.ExtendedKalmanFilter","page":"API","title":"LowLevelParticleFilters.ExtendedKalmanFilter","text":"ExtendedKalmanFilter(kf, dynamics, measurement)\nExtendedKalmanFilter(dynamics, measurement, R1,R2,d0=MvNormal(Matrix(R1)); nu::Int, p = SciMLBase.NullParameters(), α = 1.0, check = true)\n\nA nonlinear state estimator propagating uncertainty using linearization.\n\nThe constructor to the extended Kalman filter takes dynamics and measurement functions, and either covariance matrices, or a KalmanFilter. If the former constructor is used, the number of inputs to the system dynamics, nu, must be explicitly provided with a keyword argument.\n\nThe filter will internally linearize the dynamics using ForwardDiff.\n\nThe dynamics and measurement function are on the following form\n\nx(t+1) = dynamics(x, u, p, t) + w\ny      = measurement(x, u, p, t) + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nSee also UnscentedKalmanFilter which is typically more accurate than ExtendedKalmanFilter. See KalmanFilter for detailed instructions on how to set up a Kalman filter kf.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.KalmanFilter","page":"API","title":"LowLevelParticleFilters.KalmanFilter","text":"KalmanFilter(A,B,C,D,R1,R2,d0=MvNormal(R1); p = SciMLBase.NullParameters(), α=1)\n\nThe matrices A,B,C,D define the dynamics\n\nx' = Ax + Bu + w\ny  = Cx + Du + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nThe matrices can be time varying such that, e.g., A[:, :, t] contains the A matrix at time index t. They can also be given as functions on the form\n\nAfun(x, u, p, t) -> A\n\nFor maximum performance, provide statically sized matrices from StaticArrays.jl\n\nα is an optional \"forgetting factor\", if this is set to a value > 1, such as 1.01-1.2, the filter will, in addition to the covariance inflation due to R_1, exhibit \"exponential forgetting\" similar to a Recursive Least-Squares (RLS) estimator. It is thus possible to get a RLS-like algorithm by setting R_1=0 R_2 = 1α and α  1 (α is the inverse of the traditional RLS parameter α = 1λ). The exact form of the covariance update is\n\nR(t+1t) = α AR(t)A^T + R_1\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.ParticleFilter-Tuple{Integer, Function, Function, Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.ParticleFilter","text":"ParticleFilter(N::Integer, dynamics, measurement, dynamics_density, measurement_density, initial_density; threads = false, p = SciMLBase.NullParameters(), kwargs...)\n\nSee the docs for more information: https://baggepinnen.github.io/LowLevelParticleFilters.jl/stable/#Particle-filter-1\n\nArguments:\n\nN: Number of particles\ndynamics: A discrete-time dynamics function (x, u, p, t) -> x⁺\nmeasurement: A measurement function (x, u, p, t) -> y\ndynamics_density: A probability-density function for additive noise in the dynamics. Use AdvancedParticleFilter for non-additive noise.\nmeasurement_density: A probability-density function for additive measurement noise. Use AdvancedParticleFilter for non-additive noise.\ninitial_density: Distribution of the initial state.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.TupleProduct","page":"API","title":"LowLevelParticleFilters.TupleProduct","text":"TupleProduct(v::NTuple{N,UnivariateDistribution})\n\nCreate a product distribution where the individual distributions are stored in a tuple. Supports mixed/hybrid Continuous and Discrete distributions\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.UnscentedKalmanFilter","page":"API","title":"LowLevelParticleFilters.UnscentedKalmanFilter","text":"UnscentedKalmanFilter(dynamics, measurement, R1, R2, d0=MvNormal(Matrix(R1)); p = SciMLBase.NullParameters(), ny, nu)\n\nA nonlinear state estimator propagating uncertainty using the unscented transform.\n\nThe dynamics and measurement function are on the following form\n\nx' = dynamics(x, u, p, t) + w\ny  = measurement(x, u, p, t) + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nThe matrices R1, R2 can be time varying such that, e.g., R1[:, :, t] contains the R_1 matrix at time index t. They can also be given as functions on the form\n\nRfun(x, u, p, t) -> R\n\nFor maximum performance, provide statically sized matrices from StaticArrays.jl\n\nny, nu indicate the number of outputs and inputs.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.commandplot","page":"API","title":"LowLevelParticleFilters.commandplot","text":"commandplot(pf, u, y, p=parameters(pf); kwargs...)\n\nProduce a helpful plot. For customization options (kwargs...), see ?pplot. After each time step, a command from the user is requested.\n\nq: quit\ns n: step n steps\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!","page":"API","title":"LowLevelParticleFilters.correct!","text":"(; ll, e, S, Sᵪ, K) = correct!(kf::AbstractKalmanFilter, u, y, p = parameters(kf), t::Integer = index(kf), R2)\n\nThe correct step for a Kalman filter returns not only the log likelihood ll and the prediction error e, but also the covariance of the output S, its Cholesky factor Sᵪ and the Kalman gain K.\n\nIf R2 stored in kf is a function R2(x, u, p, t), this function is evaluated at the state before the correction is performed. The measurement noise covariance matrix R2 stored in the filter object can optionally be overridden by passing the argument R2, in this case R2 must be a matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!-2","page":"API","title":"LowLevelParticleFilters.correct!","text":"ll, e = correct!(f, u, y, p = parameters(f), t = index(f))\n\nUpdate state/covariance/weights based on measurement y,  returns loglikelihood and prediction error (the error is always 0 for particle filters).\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.debugplot","page":"API","title":"LowLevelParticleFilters.debugplot","text":"debugplot(pf, u, y, p=parameters(pf); runall=false, kwargs...)\n\nProduce a helpful plot. For customization options (kwargs...), see ?pplot.\n\nrunall=false: if true, runs all time steps befor displaying (faster), if false, displays the plot after each time step.\n\nThe generated plot becomes quite heavy. Initially, try limiting your input to 100 time steps to verify that it doesn't crash.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.densityplot","page":"API","title":"LowLevelParticleFilters.densityplot","text":"densityplot(x,[w])\n\nPlot (weighted) particles densities\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.forward_trajectory","page":"API","title":"LowLevelParticleFilters.forward_trajectory","text":"sol = forward_trajectory(pf, u::AbstractVector, y::AbstractVector, p=parameters(pf))\n\nRun the particle filter for a sequence of inputs and measurements. Return a solution with x,w,we,ll = particles, weights, expweights and loglikelihood\n\nIf MonteCarloMeasurements.jl is loaded, you may transform the output particles to Matrix{MonteCarloMeasurements.Particles} using Particles(x,we). Internally, the particles are then resampled such that they all have unit weight. This is conventient for making use of the plotting facilities of MonteCarloMeasurements.jl.\n\nsol can be plotted\n\nplot(sol::ParticleFilteringSolution; nbinsy=30, xreal=nothing, dim=nothing)\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.forward_trajectory-2","page":"API","title":"LowLevelParticleFilters.forward_trajectory","text":"sol = forward_trajectory(kf::AbstractKalmanFilter, u::Vector, y::Vector, p=parameters(kf))\n\nRun a Kalman filter forward\n\nReturns a KalmanFilteringSolution: with the following\n\nx: predictions\nxt: filtered estimates\nR: predicted covariance matrices\nRt: filter covariances\nll: loglik\n\nsol can be plotted\n\nplot(sol::KalmanFilteringSolution; plotx = true, plotxt=true, plotu=true, ploty=true)\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.log_likelihood_fun-Tuple{Any, Vector{<:Distributions.Distribution}, Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.log_likelihood_fun","text":"ll(θ) = log_likelihood_fun(filter_from_parameters(θ::Vector)::Function, priors::Vector{Distribution}, u, y, p)\n\nreturns function θ -> p(y|θ)p(θ)\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.loglik","page":"API","title":"LowLevelParticleFilters.loglik","text":"ll = loglik(filter, u, y, p=parameters(filter))\n\nCalculate loglikelihood for entire sequences u,y\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.logsumexp!","page":"API","title":"LowLevelParticleFilters.logsumexp!","text":"ll = logsumexp!(w, we [, maxw])\n\nNormalizes the weight vector w and returns the weighted log-likelihood\n\nhttps://arxiv.org/pdf/1412.8695.pdf eq 3.8 for p(y) https://discourse.julialang.org/t/fast-logsumexp/22827/7?u=baggepinnen for stable logsumexp\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.mean_trajectory-Tuple{Any, Vector, Vector}","page":"API","title":"LowLevelParticleFilters.mean_trajectory","text":"x,ll = mean_trajectory(pf, u::Vector{Vector}, y::Vector{Vector}, p=parameters(pf))\n\nThis method resets the particle filter to the initial state distribution upon start\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.mean_trajectory-Tuple{LowLevelParticleFilters.ParticleFilteringSolution}","page":"API","title":"LowLevelParticleFilters.mean_trajectory","text":"mean_trajectory(sol::ParticleFilteringSolution)\nmean_trajectory(x::AbstractMatrix, we::AbstractMatrix)\n\nCompute the weighted mean along the trajectory of a particle-filter solution. Returns a matrix of size T × nx. If x and we are supplied, the weights are expected to be in the original space (not log space).\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.metropolis","page":"API","title":"LowLevelParticleFilters.metropolis","text":"metropolis(ll::Function(θ), R::Int, θ₀::Vector, draw::Function(θ) = naive_sampler(θ₀))\n\nPerforms MCMC sampling using the marginal Metropolis (-Hastings) algorithm draw = θ -> θ' samples a new parameter vector given an old parameter vector. The distribution must be symmetric, e.g., a Gaussian. R is the number of iterations. See log_likelihood_fun\n\nExample:\n\nfilter_from_parameters(θ) = ParticleFilter(N, dynamics, measurement, MvNormal(n,exp(θ[1])), MvNormal(p,exp(θ[2])), d0)\npriors = [Normal(0,0.1),Normal(0,0.1)]\nll     = log_likelihood_fun(filter_from_parameters,priors,u,y,1)\nθ₀ = log.([1.,1.]) # Initial point\ndraw = θ -> θ .+ rand(MvNormal(0.1ones(2))) # Function that proposes new parameters (has to be symmetric)\nburnin = 200 # If using threaded call, provide number of burnin iterations\n# @time theta, lls = metropolis(ll, 2000, θ₀, draw) # Run single threaded\n# thetam = reduce(hcat, theta)'\n@time thetalls = LowLevelParticleFilters.metropolis_threaded(burnin, ll, 5000, θ₀, draw) # run on all threads, will provide (2000-burnin)*nthreads() samples\nhistogram(exp.(thetalls[:,1:2]), layout=3)\nplot!(thetalls[:,3], subplot=3) # if threaded call, log likelihoods are in the last column\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.reset!-Tuple{LowLevelParticleFilters.AbstractKalmanFilter}","page":"API","title":"LowLevelParticleFilters.reset!","text":"reset!(kf::AbstractKalmanFilter; x0)\n\nReset the initial distribution of the state. Optionally, a new mean vector x0 can be provided.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.reset!-Tuple{LowLevelParticleFilters.AbstractParticleFilter}","page":"API","title":"LowLevelParticleFilters.reset!","text":"Reset the filter to initial state and covariance/distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.simulate","page":"API","title":"LowLevelParticleFilters.simulate","text":"x,u,y = simulate(f::AbstractFilter, T::Int, du::Distribution, p=parameters(f), [N]; dynamics_noise=true, measurement_noise=true)\nx,u,y = simulate(f::AbstractFilter, u, p=parameters(f); dynamics_noise=true, measurement_noise=true)\n\nSimulate dynamical system forward in time T steps, or for the duration of u, returns state sequence, inputs and measurements du is a distribution of random inputs.\n\nA simulation can be considered a draw from the prior distribution over the evolution of the system implied by the selected noise models. Such a simulation is useful in order to evaluate whether or not the noise models are reasonable.\n\nIf MonteCarloMeasurements.jl is loaded, the argument N::Int can be supplied, in which case N simulations are done and the result is returned in the form of Vector{MonteCarloMeasurements.Particles}.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smooth","page":"API","title":"LowLevelParticleFilters.smooth","text":"xb,ll = smooth(pf, M, u, y, p=parameters(pf))\nxb,ll = smooth(pf, xf, wf, wef, ll, M, u, y, p=parameters(pf))\n\nPerform particle smoothing using forward-filtering, backward simulation. Return smoothed particles and loglikelihood. See also smoothed_trajs, smoothed_mean, smoothed_cov\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smooth-2","page":"API","title":"LowLevelParticleFilters.smooth","text":"xT,RT,ll = smooth(kf::KalmanFilter, u::Vector, y::Vector, p=parameters(kf))\nxT,RT,ll = smooth(kf::ExtendedKalmanFilter, u::Vector, y::Vector, p=parameters(kf))\n\nReturns smoothed estimates of state x and covariance R given all input output data u,y\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smoothed_cov-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.smoothed_cov","text":"smoothed_cov(xb)\n\nHelper function to calculate the covariance of smoothed particle trajectories\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.smoothed_mean-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.smoothed_mean","text":"smoothed_mean(xb)\n\nHelper function to calculate the mean of smoothed particle trajectories\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.smoothed_trajs-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.smoothed_trajs","text":"smoothed_trajs(xb)\n\nHelper function to get particle trajectories as a 3-dimensions array (N,M,T) instead of matrix of vectors.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.update!","page":"API","title":"LowLevelParticleFilters.update!","text":"ll, e = update!(f::AbstractFilter, u, y, p = parameters(f), t = index(f))\n\nPerform one step of predict! and correct!, returns loglikelihood and prediction error\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.weighted_cov-Tuple{Any, Any}","page":"API","title":"LowLevelParticleFilters.weighted_cov","text":"weighted_cov(x,we)\n\nSimilar to weighted_mean, but returns covariances\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.weighted_mean-Tuple{Any, AbstractVector}","page":"API","title":"LowLevelParticleFilters.weighted_mean","text":"x̂ = weighted_mean(x,we)\n\nCalculated weighted mean of particle trajectories. we are expweights.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.weighted_mean-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.weighted_mean","text":"x̂ = weighted_mean(pf)\nx̂ = weighted_mean(s::PFstate)\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict!","page":"API","title":"StatsAPI.predict!","text":"predict!(kf::AbstractKalmanFilter, u, p = parameters(kf), t::Integer = index(kf); R1)\n\nPerform the prediction step (updating the state estimate to x(t+1t)). If R1 stored in kf is a function R1(x, u, p, t), this function is evaluated at the state before the prediciton is performed. The dynamics noise covariance matrix R1 stored in kf can optionally be overridden by passing the argument R1, in this case R1 must be a matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict!-2","page":"API","title":"StatsAPI.predict!","text":"predict!(f, u, p = parameters(f), t = index(f))\n\nMove filter state forward in time using dynamics equation and input vector u.\n\n\n\n\n\n","category":"function"},{"location":"api/","page":"API","title":"API","text":"LowLevelParticleFilters.prediction_errors!","category":"page"},{"location":"api/#LowLevelParticleFilters.prediction_errors!","page":"API","title":"LowLevelParticleFilters.prediction_errors!","text":"prediction_errors!(res, f::AbstractFilter, u, y, p = parameters(f), λ = 1)\n\nCalculate the prediction errors and store the result in res. Similar to sse, this funciton is useful for sum-of-squares optimization. In contrast to sse, this function returns the residuals themselves rather than their sum of squares. This is useful for Gauss-Newton style optimizers, such as LeastSquaresOptim.LevenbergMarquardt.\n\nArguments:\n\nres: A vector of length ny*length(y). Note, for each datapoint in u and u, there are ny outputs, and thus ny residuals.\nf: Any filter\nλ: A weighting factor to minimize dot(e, λ, e). A commonly used metric is λ = Diagonal(1 ./ (mag.^2)), where mag is a vector of the \"typical magnitude\" of each output. Internally, the square root of W = sqrt(λ) is calculated so that the residuals stored in res are W*e.\n\nSee example in Solving using Gauss-Newton optimization.\n\n\n\n\n\n","category":"function"},{"location":"parameter_estimation/#Parameter-Estimation","page":"Parameter estimation","title":"Parameter Estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"State estimation is an integral part of many parameter-estimation methods. Below, we will illustrate several different methods of performing parameter estimation. We can roughly divide the methods into two camps","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Methods that optimize prediction error or likelihood by tweaking model parameters.\nMethods that add the parameters to be estimated as state variables in the model and estimate them using standard state estimation. ","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"From the first camp, we provide som basic functionality for maximum-likelihood estimation and MAP estimation, described below. An example of (2), joint state and parameter estimation, is provided in Joint state and parameter estimation.","category":"page"},{"location":"parameter_estimation/#Maximum-likelihood-estimation","page":"Parameter estimation","title":"Maximum-likelihood estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Filters calculate the likelihood and prediction errors while performing filtering, this can be used to perform maximum likelihood estimation or prediction-error minimization. One can estimate all kinds of parameters using this method, in the example below, we will estimate the noise covariance. We may for example plot likelihood as function of the variance of the dynamics noise like this","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots\nnx = 2   # Dimension of state\nnu = 2   # Dimension of input\nny = 2   # Dimension of measurements\nN = 2000 # Number of particles\n\nconst dg = MvNormal(ny,1.0)          # Measurement noise Distribution\nconst df = MvNormal(nx,1.0)          # Dynamics noise Distribution\nconst d0 = MvNormal(randn(nx),2.0)   # Initial state Distribution\n\nconst A = SA[1 0.1; 0 1]\nconst B = @SMatrix [0.0 0.1; 1 0.1]\nconst C = @SMatrix [1.0 0; 0 1]\n\ndynamics(x,u,p,t) = A*x .+ B*u \nmeasurement(x,u,p,t) = C*x\nvecvec_to_mat(x) = copy(reduce(hcat, x)') # Helper function\npf = ParticleFilter(N, dynamics, measurement, df, dg, d0)\nxs,u,y = simulate(pf,300,df)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"p = nothing\nsvec = exp10.(LinRange(-0.8, 1.2, 60))\nllspf = map(svec) do s\n    df = MvNormal(nx,s)\n    pfs = AuxiliaryParticleFilter(N, dynamics, measurement, df, dg, d0)\n    loglik(pfs, u, y, p)\nend\nplot( svec, llspf,\n    xscale = :log10,\n    title = \"Log-likelihood\",\n    xlabel = \"Dynamics noise standard deviation\",\n    lab = \"PF\",\n)\nvline!([svec[findmax(llspf)[2]]], l=(:dash,:blue), primary=false)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"the correct value for the simulated data is 1 (the simulated system is the same as on the front page of the docs).","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We can do the same with a Kalman filter","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"eye(n) = Matrix{Float64}(I,n,n)\nllskf = map(svec) do s\n    kfs = KalmanFilter(A, B, C, 0, s^2*eye(nx), eye(ny), d0)\n    loglik(kfs, u, y, p)\nend\nplot!(svec, llskf, yscale=:identity, xscale=:log10, lab=\"Kalman\", c=:red)\nvline!([svec[findmax(llskf)[2]]], l=(:dash,:red), primary=false)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"the result can be quite noisy due to the stochastic nature of particle filtering. The particle filter likelihood never reaches as high as for the Kalman filter which is optimal for the linear example system we are simulating here. For maximum-likelihood estimation, the AuxiliaryParticleFilter is typically more accurate than the standard ParticleFilter","category":"page"},{"location":"parameter_estimation/#MAP-estimation","page":"Parameter estimation","title":"MAP estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In this example, we will estimate the variance of the noises in the dynamics and the measurement functions.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"To solve a MAP estimation problem, we need to define a function that takes a parameter vector and returns a filter, the parameters are used to construct the covariance matrices:","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"filter_from_parameters(θ, pf = nothing) = KalmanFilter(A, B, C, 0, exp(θ[1])^2*eye(nx), exp(θ[2])^2*eye(ny), d0) # Works with particle filters as well\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"The call to exp on the parameters is so that we can define log-normal priors","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"priors = [Normal(0,2),Normal(0,2)]","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Now we call the function log_likelihood_fun that returns a function to be minimized","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"ll = log_likelihood_fun(filter_from_parameters, priors, u, y, p)\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Since this is a low-dimensional problem, we can plot the LL on a 2d-grid","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"function meshgrid(a,b)\n    grid_a = [i for i in a, j in b]\n    grid_b = [j for i in a, j in b]\n    grid_a, grid_b\nend\nNv       = 20\nv        = LinRange(-0.7,1,Nv)\nllxy     = (x,y) -> ll([x;y])\nVGx, VGy = meshgrid(v,v)\nVGz      = llxy.(VGx, VGy)\nheatmap(\n    VGz,\n    xticks = (1:Nv, round.(v, digits = 2)),\n    yticks = (1:Nv, round.(v, digits = 2)),\n    xlabel = \"sigma v\",\n    ylabel = \"sigma w\",\n) # Yes, labels are reversed","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"For higher-dimensional problems, we may estimate the parameters using an optimizer, e.g., Optim.jl.","category":"page"},{"location":"parameter_estimation/#Bayesian-inference-using-PMMH","page":"Parameter estimation","title":"Bayesian inference using PMMH","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We proceed like we did for MAP above, but when calling the function metropolis, we will get the entire posterior distribution of the parameter vector, for the small cost of a massive increase in the amount of computations. metropolis runs the Metropolis Hastings algorithm, or more precisely if a particle filter is used, the \"Particle Marginal Metropolis Hastings\" (PMMH) algorithm. Here we use the Kalman filter simply to have the documentation build a bit faster, it can be quite heavy to run.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"filter_from_parameters(θ, pf = nothing) = KalmanFilter(A, B, C, 0, exp(θ[1])^2*I(nx), exp(θ[2])^2*I(ny), d0) # Works with particle filters as well\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"The call to exp on the parameters is so that we can define log-normal priors","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"priors = [Normal(0,2),Normal(0,2)]\nll     = log_likelihood_fun(filter_from_parameters, priors, u, y, p)\nθ₀     = log.([1.0, 1.0]) # Starting point\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We also need to define a function that suggests a new point from the \"proposal distribution\". This can be pretty much anything, but it has to be symmetric since I was lazy and simplified an equation.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"draw   = θ -> θ .+ 0.05 .* randn.() # This function dictates how new proposal parameters are being generated. \nburnin = 200 # remove this many initial samples (\"burn-in period\")\n@info \"Starting Metropolis algorithm\"\n@time theta, lls = metropolis(ll, 2200, θ₀, draw) # Run PMMH for 2200  iterations\nthetam = reduce(hcat, theta)'[burnin+1:end,:] # Build a matrix of the output\nhistogram(exp.(thetam), layout=(3,1), lab=[\"R1\" \"R2\"]); plot!(lls[burnin+1:end], subplot=3, lab=\"log likelihood\") # Visualize","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In this example, we initialize the MH algorithm on the correct value θ₀, in general, you'd see a period in the beginning where the likelihood (bottom plot) is much lower than during the rest of the sampling, this is the reason we remove a number of samples in the beginning, typically referred to as \"burn in\".","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"If you are lucky, you can run the above threaded as well. I tried my best to make particle filters thread safe with their own rngs etc., but your milage may vary. For threading to help, the dynamics must be non-allocating, e.g., by using StaticArrays etc.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"@time thetalls = LowLevelParticleFilters.metropolis_threaded(burnin, ll, 2200, θ₀, draw, nthreads=2)\nhistogram(exp.(thetalls[:,1:2]), layout=3)\nplot!(thetalls[:,3], subplot=3)","category":"page"},{"location":"parameter_estimation/#Joint-state-and-parameter-estimation","page":"Parameter estimation","title":"Joint state and parameter estimation","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In this example, we'll show how to perform parameter estimation by treating a parameter as a state variable. This method can not only estimate constant parameters, but also time-varying parameters. The system we will consider is a quadruple tank, where two upper tanks feed into two lower tanks. The outlet for tank 1 can vary in size, simulating, e.g., that something partially blocks the outlet. We start by defining the dynamics on a form that changes the outlet area a_1 at time t=500:","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using LowLevelParticleFilters\nusing SeeToDee\nusing Distributions\nusing StaticArrays\nusing Plots, LinearAlgebra\n\nfunction quadtank(h,u,p,t)\n    kc = 0.5\n    k1, k2, g = 1.6, 1.6, 9.81\n    A1 = A3 = A2 = A4 = 4.9\n    a1, a3, a2, a4 = 0.03, 0.03, 0.03, 0.03\n    γ1, γ2 = 0.2, 0.2\n\n    if t > 500\n        a1 *= 2 # Change the parameter at t = 500\n    end\n\n    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n    \n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]\n    ]\nend\n\nnu = 2 # number of control inputs\nnx = 4 # number of state variables\nny = 2 # number of measured outputs\nTs = 1 # sample time\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We then define a measurement function, we measure the levels of tanks 1 and 2, and discretize the continuous-time dynamics using a Runge-Kutta 4 integrator SeeToDee.Rk4:","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"measurement(x,u,p,t) = SA[x[1], x[2]]\ndiscrete_dynamics = SeeToDee.Rk4(quadtank, Ts, supersample=2)\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We simulate the system using the rollout function and add some noise to the measurements. The inputs in this case are just square waves.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Tperiod = 200\nt = 0:Ts:1000\nu = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* t)) .+ 0.25)\nu = vcat.(u,u)\nx0 = Float64[2,2,3,3]\nx = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u)[1:end-1]\ny = measurement.(x, u, 0, 0)\ny = [y .+ 0.01randn(ny) for y in y]\n\nplot(\n    plot(reduce(hcat, x)', title=\"State\"),\n    plot(reduce(hcat, u)', title=\"Inputs\")\n)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"To perform the joint state and parameter estimation, we define a version of the dynamics that contains an extra state, corresponding to the unknown or time varying parameter, in this case a_1. We do not have any apriori information about how this parameter changes, so we say that its derivative is 0 and it's thus only driven by noise:","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"function quadtank_paramest(h, u, p, t)\n    kc = 0.5\n    k1, k2, g = 1.6, 1.6, 9.81\n    A1 = A3 = A2 = A4 = 4.9\n    a3, a2, a4 = 0.03, 0.03, 0.03\n    γ1, γ2 = 0.2, 0.2\n\n    a1 = h[5] # the a1 parameter is a state\n\n    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n    \n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]\n        0 # the state is only driven by noise\n    ]\nend\n\ndiscrete_dynamics_params = SeeToDee.Rk4(quadtank_paramest, Ts, supersample=2)\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We then define a nonlinear state estimator, we will use the UnscentedKalmanFilter, and solve the filtering problem. We start by an initial state estimate x_0 that is slightly off for the parameter a_1","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"nx = 5\nR1 = Diagonal([0.1, 0.1, 0.1, 0.1, 0.0001])\nR2 = Diagonal((1e-2)^2 * ones(ny))\nx0 = [2, 2, 3, 3, 0.02]\n\nkf = UnscentedKalmanFilter(discrete_dynamics_params, measurement, R1, R2, MvNormal(x0, R1); ny, nu)\n\nsol = forward_trajectory(kf, u, y)\nplot(sol, plotx=false, plotxt=true, plotu=false, ploty=true, legend=:bottomright)\nplot!([0,500,500,1000], [0.03, 0.03, 0.06, 0.06], l=(:dash, :black), sp=5, lab=\"True param\")","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"as we can see, the correct value of the parameter is quickly found (x_5), and it also adapts at t=500 when the parameter value changes. The speed with which the parameter adapts to changes is determined by the covariance matrix R_1, a higher value results in faster adaptation, but also higher sensitivity to noise. ","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"If adaptive parameter estimation is coupled with a model-based controller, we get an adaptive controller! Note: the state that corresponds to the estimated parameter is typically not controllable, a fact that may require some special care for some control methods.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We may ask ourselves, what's the difference between a parameter and a state variable if we can add parameters as state variables? Typically, parameters do not vary with time, and if they do, they vary significantly slower than the state variables. State variables also have dynamics associate with them, whereas we often have no idea about how the parameters vary other than that they vary slowly.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Abrupt changes to the dynamics like in the example above can happen in practice, for instance, due to equipment failure or change of operating mode. This can be treated as a scenario with time-varying parameters that are continuously estimated. ","category":"page"},{"location":"parameter_estimation/#Using-an-optimizer","page":"Parameter estimation","title":"Using an optimizer","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"The state estimators in this package are all statistically motivated and thus compute things like the likelihood of the data as a by-product of the estimation. Maximum-likelihood or prediction-error estimation is thus very straight-forward by simply calling a gradient-based optimizer with gradients provided by differentiating through the state estimator using automatic differentiation. In this example, we will continue the example from above, but now estimate all the parameters of the quad-tank process. This time, they will not vary with time. We will first use a standard optimization algorithm from Optim.jl to minimize the cost function based on the prediction error, and then use a Gauss-Newton optimizer.","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We now define the dynamics function such that it takes its parameters from the p input argument. We also define a variable p_true that contains the true values that we will use to simulate some estimation data","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"function quadtank(h, u, p, t)\n    kc = p[1]\n    k1, k2, g = p[2], p[3], 9.81\n    A1 = A3 = A2 = A4 = p[4]\n    a1 = a3 = a2 = a4 = p[5]\n    γ1 = γ2 = p[6]\n\n    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n    \n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]\n    ]\nend\n\ndiscrete_dynamics = SeeToDee.Rk4(quadtank, Ts, supersample=2) # Discretize the dynamics using a 4:th order Runge-Kutta integrator\np_true = [0.5, 1.6, 1.6, 4.9, 0.03, 0.2]\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Similar to previous example, we simulate the system, this time using a more exciting input in order to be able to identify several parameters","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Tperiod = 200\nt = 0:Ts:1000\nu1 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2)) .+ 0.25)\nu2 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2 .+ pi/2)) .+ 0.25)\nu  = vcat.(u1,u2)\nx0 = Float64[2,2,3,3]\nx = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u, p_true)[1:end-1]\ny = measurement.(x, u, 0, 0)\ny = [y .+ 0.01randn(ny) for y in y]\n\nplot(\n    plot(reduce(hcat, x)', title=\"State\"),\n    plot(reduce(hcat, u)', title=\"Inputs\")\n)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"This time, we define a cost function for the optimizer to optimize, we'll use the sum of squared errors (sse). It's important to define the UKF with an initial state distribution with the same element type as the parameter vector so that automatic differentiation through the state estimator works, hence the explicit casting T.(x0).","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"nx = 4\nR1 = Diagonal([0.1, 0.1, 0.1, 0.1])\nR2 = Diagonal((1e-2)^2 * ones(ny))\nx0 = [2, 2, 3, 3]\n\nfunction cost(p::Vector{T}) where T\n    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), R1); ny, nu)\n    LowLevelParticleFilters.sse(kf, u, y, p) # Sum of squared prediction errors\nend\nnothing # hide","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We generate a random initial guess for the estimation problem","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"p_guess = p_true .+  0.1*p_true .* randn(length(p_true))","category":"page"},{"location":"parameter_estimation/#Solving-using-Optim","page":"Parameter estimation","title":"Solving using Optim","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We first minimize the cost using the BFGS optimization algorithm from Optim.jl","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using Optim\nres = Optim.optimize(\n    cost,\n    p_guess,\n    BFGS(),\n    Optim.Options(\n        show_trace = true,\n        show_every = 5,\n        iterations = 100,\n        time_limit = 30,\n    ),\n    autodiff = :forward, # Indicate that we want to use forward-mode AD to derive gradients\n)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"We started out with a normalized parameter error of","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using LinearAlgebra\nnorm(p_true - p_guess) / norm(p_true)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"and ended with","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"p_opt = res.minimizer\nnorm(p_true - p_opt) / norm(p_true)","category":"page"},{"location":"parameter_estimation/#Solving-using-Gauss-Newton-optimization","page":"Parameter estimation","title":"Solving using Gauss-Newton optimization","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Below, we optimize the sum of squared residuals again, but this time we do it using a Gauss-Newton style algorithm (Levenberg Marquardt). These algorithms want the entire residual vector rather than the sum of squares of the residuals, so we define an alternative \"cost function\" called residuals that calls the lower-level function LowLevelParticleFilters.prediction_errors!","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using LeastSquaresOptim\n\nfunction residuals!(res, p::Vector{T}) where T\n    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), R1); ny, nu)\n    LowLevelParticleFilters.prediction_errors!(res, kf, u, y, p) \nend\n\nres_gn = optimize!(LeastSquaresProblem(x = copy(p_guess), f! = residuals!, output_length = length(y)*ny, autodiff = :forward), LevenbergMarquardt())\n\np_opt_gn = res_gn.minimizer\nnorm(p_true - p_opt_gn) / norm(p_true)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Gauss-Newton algorithms are often more efficient at sum-of-squares minimization than the more generic BFGS optimizer. This form of Gauss-Newton optimization of prediction errors is also available through ControlSystemIdentification.jl, which uses this package undernath the hood.","category":"page"},{"location":"parameter_estimation/#Identifiability","page":"Parameter estimation","title":"Identifiability","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"There is no guarantee that we will recover the true parameters for this system, especially not if the input excitation is poor, but we will generally find parameters that results in a good predictor for the system (this is after all what we're optimizing for). A tool like StructuralIdentifiability.jl may be used to determine the identifiability of parameters and state variables, something that for this system could look like","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using StructuralIdentifiability\n\node = @ODEmodel(\n    h1'(t) = -a1/A1 * h1(t) + a3/A1*h3(t) +     gam*k1/A1 * u1(t),\n    h2'(t) = -a2/A2 * h2(t) + a4/A2*h4(t) +     gam*k2/A2 * u2(t),\n    h3'(t) = -a3/A3*h3(t)                 + (1-gam)*k2/A3 * u2(t),\n    h4'(t) = -a4/A4*h4(t)                 + (1-gam)*k1/A4 * u1(t),\n\ty1(t) = h1(t),\n    y2(t) = h2(t),\n)\n\nlocal_id = assess_local_identifiability(ode, 0.99)","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"where we have made the substitution sqrt h rightarrow h due to a limitation of the tool. The output of the above analysis is ","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"julia> local_id = assess_local_identifiability(ode, 0.99)\nDict{Nemo.fmpq_mpoly, Bool} with 15 entries:\n  a3  => 0\n  gam => 1\n  k2  => 0\n  A4  => 0\n  h4  => 0\n  h2  => 1\n  A3  => 0\n  a1  => 0\n  A2  => 0\n  k1  => 0\n  a4  => 0\n  h3  => 0\n  h1  => 1\n  A1  => 0\n  a2  => 0","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"indicating that we can not hope to resolve all of the parameters. However, using appropriate regularization from prior information, we might still recover a lot of information about the system. Regularization could easily be added to the function cost above, e.g., using a penalty like (p-p_guess)'Γ*(p-p_guess) for some matrix Gamma, to indicate our confidence in the initial guess.","category":"page"},{"location":"parameter_estimation/#Videos","page":"Parameter estimation","title":"Videos","text":"","category":"section"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Examples of parameter estimation are available here","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"By using an optimizer to optimize the likelihood of an UnscentedKalmanFilter:","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/0RxQwepVsoM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Estimation of time-varying parameters:","category":"page"},{"location":"parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/zJcOPPLqv4A?si=XCvpo3WD-4U3PJ2S\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"page"},{"location":"adaptive_kalmanfilter/#Noise-adaptive-Kalman-filter","page":"Kalman-filter tutorial","title":"Noise-adaptive Kalman filter","text":"","category":"section"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"In this tutorial we will consider filtering of a 1D position track, similar in spirit to what one could have obtained from a GPS device, but limited to 1D for easier visualization. We will use a constant-velocity model, i.e., use a double integrator,","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"beginaligned\nx_k+1 = beginbmatrix 1  T_s  0  1 endbmatrix x_k + beginbmatrix T_s^22  T_s endbmatrix w_k \ny_k = beginbmatrix 1  0 endbmatrix x_k + v_k\nendaligned","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"where w_k sim mathcalN(0 σ_w) is the process noise, and v_k sim mathcalN(0 R_2) is the measurement noise, and illustrate how we can make use of an adaptive noise covariance to improve the filter performance.","category":"page"},{"location":"adaptive_kalmanfilter/#Data-generation","page":"Kalman-filter tutorial","title":"Data generation","text":"","category":"section"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"We start by generating some position data that we want to perform filtering on. The \"object\" we want to track is initially stationary, and transitions to moving with a constant velocity after a while. ","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"using LowLevelParticleFilters, Plots, Random\nRandom.seed!(1)\n\n# Create a time series for filtering\nx = [zeros(50); 0:100]\nT = length(x)\nY = x + randn(T)\nplot([Y x], lab=[\"Measurement\" \"True state to be tracked\"], c=[1 :purple])","category":"page"},{"location":"adaptive_kalmanfilter/#Simple-Kalman-filtering","page":"Kalman-filter tutorial","title":"Simple Kalman filtering","text":"","category":"section"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"We will use a Kalman filter to perform the filtering. The model is a double integrator, i.e., a constant-acceleration model. The state vector is thus x = p v^T, where p is the position and v is the velocity. When designing a Kalman filter, we need to specify the noise covariances R_1 and R_2. While it's often easy to measure the covariance of the measurement noise, R_2, it can be quite difficult to know ahead of time what the dynamics noise covariance, R_1, should be. In this example, we will use an adaptive filter, where we will increase the dynamics noise covariance if the filter prediction error is too large. However, we first run the filter twice, once with a large R_1 and once with a small R_1 to illustrate the difference.","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"y = [[y] for y in Y] # create a vector of vectors for the KF\nu = fill([], T) # No inputs in this example :(\n\n# Define the model\nTs = 1\nA = [1 Ts; 0 1]\nB = zeros(2, 0)\nC = [1 0]\nD = zeros(0, 0)\nR2 = [1;;]\n\nσws = [1e-2, 1e-5] # Dynamics noise standard deviations\n\nfig = plot(Y, lab=\"Measurement\")\nfor σw in σws\n    R1 = σw*[Ts^3/3 Ts^2/2; Ts^2/2 Ts] # The dynamics noise covariance matrix is σw*Bw*Bw' where Bw = [Ts^2/2; Ts]\n    kf = KalmanFilter(A, B, C, D, R1, R2)\n    yh = []\n    measure = LowLevelParticleFilters.measurement(kf)\n    for t = 1:T # Main filter loop\n        kf(u[t], y[t]) # Performs both prediction and correction\n        xh = state(kf)\n        yht = measure(xh, u[t], nothing, t)\n        push!(yh, yht)\n    end\n\n    Yh = reduce(hcat, yh)\n    plot!(Yh', lab=\"Estimate \\$σ_w\\$ = $σw\")\nend\nfig","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"When R_1 is small (controlled by σ_w), we get a nice and smooth filter estimate, but this estimate clearly lags behind the true state. When R_1 is large, the filter estimate is much more responsive, but it also has a lot of noise.","category":"page"},{"location":"adaptive_kalmanfilter/#Adaptive-noise-covariance","page":"Kalman-filter tutorial","title":"Adaptive noise covariance","text":"","category":"section"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"Below, we will implement an adaptive filter, where we keep the dynamics noise covariance low by default, but increase it if the filter prediction error is too large. We will use a Z-score to determine if the prediction error is too large. The Z-score is defined as the number of standard deviations the prediction error is away from the estimated mean. This time around we use separate correct! and predict! calls, so that we can access the prediction error as well as the prior covariance of the prediction error, S. S (or the Cholesky factor Sᵪ) will be used to compute the Z-score.","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"σw = 1e-5 # Set the covariance to a low value by default\nR1 = σw*[Ts^3/3 Ts^2/2; Ts^2/2 Ts]\nkf = KalmanFilter(A, B, C, D, R1, R2)\nmeasure = LowLevelParticleFilters.measurement(kf)\n\n# Some arrays to store simulation data\nyh = []\nes = Float64[]\nσs = Float64[]\nfor t = 1:T # Main filter loop\n    ll, e, S, Sᵪ = correct!(kf, u[t], y[t], nothing, t) # Manually call the prediction step\n    σ = √(e'*(Sᵪ\\e)) # Compute the Z-score\n    push!(es, e[]) # Save for plotting\n    push!(σs, σ)\n    if σ > 3 # If the Z-score is too high\n        # we temporarily increase the dynamics noise covariance by 1000x to adapt faster\n        predict!(kf, u[t], nothing, t; R1 = 1000kf.R1) \n    else\n        predict!(kf, u[t], nothing, t)\n    end\n    xh = state(kf)\n    yht = measure(xh, u[t], nothing, t)\n    push!(yh, yht)\nend\n\nYh = reduce(hcat, yh)\nplot([Y Yh'], lab=[\"Measurement\" \"Adaptive estimate\"])","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"Not too bad! This time the filter estimate is much more responsive during the transition, but exhibits favorable noise properties during the stationary phases. We can also plot the prediction error and the Z-score to see how the filter adapts to the dynamics noise covariance.","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"plot([es σs], lab=[\"Prediction error\" \"Z-score\"])","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"Notice how the prediction errors, that should ideally be centered around zero, remain predominantly negative for a long time interval after the transition. This can be attributed to an overshoot in the velocity state of the estimator, but the rapid decrease of the covariance after the transition makes the filter slow at correcting its overshoot. If we want, we could mitigate this and make the adaptation even more sophisticated by letting the covariance remain large for a while after a transition in operating mode has been detected. Below, we implement a simple version of this, where we use a multiplier σ_wt that defaults to 1, but is increase to a very large value of 1000 if a transition is detected. When no transition is detected, σ_wt is decreased exponentially back down to 1.","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"σw  = 1e-5 # Set the covariance to a low value by default\nσwt = 1.0\nR1  = σw*[Ts^3/3 Ts^2/2; Ts^2/2 Ts]\nkf  = KalmanFilter(A, B, C, D, R1, R2)\nmeasure = LowLevelParticleFilters.measurement(kf)\n\n# Some arrays to store simulation data\nyh = []\nes = Float64[]\nσs = Float64[]\nσwts = Float64[]\nfor t = 1:T # Main filter loop\n    global σwt # Note, do not make use of global variables in performance critical code\n    ll, e, S, Sᵪ = correct!(kf, u[t], y[t], nothing, t) # Manually call the prediction step\n    σ = √(e'*(Sᵪ\\e)) # Compute the Z-score\n    push!(es, e[]) # Save for plotting\n    push!(σs, σ)\n    if σ > 3 # If the Z-score is too high\n        σwt = 1000.0 # Set the R1 multiplier to a very large value\n    else\n        σwt = max(0.7σwt, 1.0) # Decrease exponentially back to 1\n    end\n    push!(σwts, σwt)\n    predict!(kf, u[t], nothing, t; R1 = σwt*kf.R1) \n    xh = state(kf)\n    yht = measure(xh, u[t], nothing, t)\n    push!(yh, yht)\nend\n\nYh = reduce(hcat, yh)\nplot([Y Yh'], lab=[\"Measurement\" \"Adaptive estimate\"])","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"plot([es σs σwts], lab=[\"Prediction error\" \"Z-score\" \"\\$σ_{wt}\\$ multiplier\"], layout=2, sp=[1 1 2])","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"This time, the prediction errors look more like white noise centered around zero after the initial transient caused by the transition.","category":"page"},{"location":"adaptive_kalmanfilter/#Summary","page":"Kalman-filter tutorial","title":"Summary","text":"","category":"section"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"This tutorial demonstrated simple Kalman filtering for a double integrator without control inputs. We saw how the filtering estimate could be improved by playing around with the covariance matrices of the estimator, helping it catch up to fast changes in the behavior of the system without sacrificing steady-state noise properties.","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"In this case, we handled the modification of R_1 outside of the filter, implementing our own filtering loop. Some applications get away with instead providing time-varying matrices in the form of a 3-dimension array, where the third dimension corresponds to time, or instead of providing a matrix, providing a function R_1(x u p t) allows the matrix to be a function of state, input, parameters and time. These options apply to all matrices in the filter, including the dynamics matrices, ABCD.","category":"page"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"Lastly, we mention the ability of the KalmanFilter to act like a recursive least-squares estimator, by setting the \"forgetting factor α1 when creating the KalmanFilter. α1 will cause the filter will exhibit exponential forgetting similar to an RLS estimator, in addition to the covariance inflation due to R1. It is thus possible to get a RLS-like algorithm by setting R_1 = 0 R_2 = 1α and α  1.","category":"page"},{"location":"adaptive_kalmanfilter/#Disturbance-modeling-and-noise-tuning","page":"Kalman-filter tutorial","title":"Disturbance modeling and noise tuning","text":"","category":"section"},{"location":"adaptive_kalmanfilter/","page":"Kalman-filter tutorial","title":"Kalman-filter tutorial","text":"See this notebook for a blog post about disturbance modeling and noise tuning using LowLevelParticleFilter.jl","category":"page"},{"location":"dae/#State-estimation-for-high-index-DAEs","page":"State estimation for DAE systems","title":"State estimation for high-index DAEs","text":"","category":"section"},{"location":"dae/","page":"State estimation for DAE systems","title":"State estimation for DAE systems","text":"This tutorial is hosted as a notebook.","category":"page"},{"location":"beetle_example/#Smoothing-the-track-of-a-moving-beetle","page":"Particle-filter tutorial","title":"Smoothing the track of a moving beetle","text":"","category":"section"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"This is an example of smoothing the 2-dimensional trajectory of a moving dung beetle. The example spurred off of this Discourse topic. For more information about the research behind this example, see Artificial light disrupts dung beetles’ sense of direction and A dung beetle that path integrates without the use of landmarks. Special thanks to Yakir Gagnon for providing this example.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"In this example we will describe the position coordinates, x and y, of the beetle as functions of its velocity, v_t, and direction, θ_t:","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"beginaligned\nx_t+1 = x_t + cos(θ_t)v_t \ny_t+1 = y_t + sin(θ_t)v_t \nv_t+1 = v_t + e_t \nθ_t+1 = θ_t + w_t\nendaligned","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"where e_t  N(0σ_e) w_t  N(0σ_w) The beetle further has two \"modes\", one where it's moving towards a goal, and one where it's searching in a more erratic manner. Figuring out when this mode switch occurs is the goal of the filtering. The mode will be encoded as a state variable, and used to determine the amount of dynamic noise affecting the velocity of the beetle, i.e., in the searching mode, the beetle has more velocity noise. The mode switching is modeled as a stochastic process with a binomial distribution (coin flip) describing the likelihood of a switch from mode 0 (moving to goal) and mode 1 (searching). Once the beetle has started searching, it stays in that mode, i.e., the searching mode is \"sticky\" or \"terminal\".","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We load a single experiment from file for the purpose of this example (in practice, there may be hundreds of experiments)","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"using LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots, Random\nusing DelimitedFiles\npath = \"../track.csv\"\nxyt = readdlm(path)\ntosvec(y) = reinterpret(SVector{length(y[1]),Float64}, reduce(hcat,y))[:] |> copy # helper function\ny = tosvec(collect(eachrow(xyt[:,1:2])))\nnothing # hide","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We then define some properties of the dynamics and the filter. We will use an AdvancedParticleFilter since we want to have fine-grained control over the noise sampling for the mode switch.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"N = 2000 # Number of particles in the particle filter\nn = 4 # Dimension of state: we have speed and angle, so two\np = 2 # Dimension of measurements, we can measure the x and the y, so also two\n@inline pos(s) = s[SVector(1,2)]\n@inline vel(s) = s[3]\n@inline ϕ(s) = s[4]\n@inline mode(s) = s[5]\nnothing # hide","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We then define the probability distributions we need.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"dgσ = 1 # the deviation of the measurement noise distribution\ndvσ = 0.3 # the deviation of the dynamics noise distribution\nϕσ  = 0.5\nconst switch_prob = 0.03 # Probability of mode switch\nconst dg = MvNormal(@SVector(zeros(p)), dgσ^2) # Measurement noise Distribution\nconst df = LowLevelParticleFilters.TupleProduct((Normal.(0,[1e-1, 1e-1, dvσ, ϕσ])...,Binomial(1,switch_prob)))\nconst d0 = MvNormal(SVector(y[1]..., 0.5, atan((y[2]-y[1])...), 0), [3.,3,2,2,0])\nconst noisevec = zeros(5) # cache vector\nnothing # hide","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We now define the dynamics, since we use the advanced filter, we include the noise=false argument. The dynamics is directly defined in discrete time.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"@inline function dynamics(s,u,p,t,noise=false)\n    # current state\n    m = mode(s)\n    v = vel(s)\n    a = ϕ(s)\n    p = pos(s)\n    # get noise\n    if noise\n        y_noise, x_noise, v_noise, ϕ_noise,_ = rand!(df, noisevec)\n    else\n        y_noise, x_noise, v_noise, ϕ_noise = 0.,0.,0.,0.\n    end\n    # next state\n    v⁺ = max(0.999v + v_noise, 0.0)\n    m⁺ = Float64(m == 0 ? rand() < switch_prob : true)\n    a⁺ = a + (ϕ_noise*(1 + m*10))/(1 + v) # next state velocity is used here\n    p⁺ = p + SVector(y_noise, x_noise) + SVector(sincos(a))*v # current angle but next velocity\n    SVector{5,Float64}(p⁺[1], p⁺[2], v⁺, a⁺, m⁺) # all next state\nend\nfunction measurement_likelihood(s,u,y,p,t)\n    logpdf(dg, pos(s)-y) # A simple linear measurement model with normal additive noise\nend\n@inline measurement(s,u,p,t,noise=false) = s[SVector(1,2)] + noise*rand(dg) # We observer the position coordinates with the measurement\nnothing # hide","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"In this example, we have no control inputs, we thus define a vector of only zeros. We then solve the forward filtering problem and plot the results.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"u = zeros(length(y))\npf = AuxiliaryParticleFilter(AdvancedParticleFilter(N, dynamics, measurement, measurement_likelihood, df, d0))\nT = length(y)\nsol = forward_trajectory(pf,u[1:T],y[1:T])\n(; x,w,we,ll) = sol\nplot(sol, markerstrokecolor=:auto, m=(2,0.5), format=:png)","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We can clearly see when the beetle switched mode (state variable 5). This corresponds well to annotations provided by a biologist and is the fundamental question we want to answer with the filtering procedure.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We can plot the mean of the filtered trajectory as well","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"xh = mean_trajectory(x,we)\n\n\"plotting helper function\"\nfunction to1series(x::AbstractVector, y)\n    r,c = size(y)\n    y2 = vec([y; fill(Inf, 1, c)])\n    x2 = repeat([x; Inf], c)\n    x2,y2\nend\nto1series(y) = to1series(1:size(y,1),y)\n\nfig1 = plot(xh[:,1],xh[:,2], c=:blue, lab=\"estimate\", legend=:bottomleft)\nplot!(xyt[:,1],xyt[:,2], c=:red, lab=\"measurement\")","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"as well as the angle state variable (we subsample the particles to not get sluggish plots)","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"fig2 = scatter(to1series(ϕ.(x)'[:,1:5:end])..., m=(:black, 0.03, 2), lab=\"\", size=(500,300), format=:png)\nplot!(identity.(xh[:,4]), lab=\"Filtered angle\", legend=:topleft, ylims=(-30, 70))","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"The particle plot above indicate that the posterior is multimodal. This phenomenon arises due to the simple model that uses an angle that is allowed to leave the interval `0-2\\pi rad. In this example, we are not interested in the angle, but rather when the beetle switches mode. The filtering distribution above gives a hint at when this happens, but we will not plot the mode trajectory until we have explored smoothing as well.","category":"page"},{"location":"beetle_example/#Smoothing","page":"Particle-filter tutorial","title":"Smoothing","text":"","category":"section"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"The filtering results above does not use all the available information when trying to figure out the state trajectory. To do this, we may call a smoother. We use a particle smoother and compute 10 smoothing trajectories.","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"M = 10 # Number of smoothing trajectories, NOTE: if this is set higher, the result will be better at the expense of linear scaling of the computational cost.\nsb,ll = smooth(pf, M, u, y) # Sample smooting particles (b for backward-trajectory)\nsbm = smoothed_mean(sb)     # Calculate the mean of smoothing trajectories\nsbt = smoothed_trajs(sb)    # Get smoothing trajectories\nplot!(fig1, sbm[1,:],sbm[2,:], lab=\"xs\")","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"plot!(fig2, identity.(sbm'[:,4]), lab=\"smoothed\")","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We see that the smoothed trajectory may look very different from the filter trajectory. This is an indication that it's hard to tell what state the beetle is currently in, but easier to look back and tell what state the beetle must have been in at a historical point. ","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"We can also visualize the mode state","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"plot(xh[:,5], lab=\"Filtering\")\nplot!(to1series(sbt[5,:,:]')..., lab=\"Smoothing\", title=\"Mode trajectories\", l=(:black,0.2))","category":"page"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"also this state variable indicates that it's hard to tell what state the beetle is in during filtering, but obvious with hindsight (smoothing). The mode switch occurs when the filtering distribution of the angle becomes drastically wider, indicating that increased dynamics noise is required in order to describe the motion of the beetle.","category":"page"},{"location":"beetle_example/#Summary","page":"Particle-filter tutorial","title":"Summary","text":"","category":"section"},{"location":"beetle_example/","page":"Particle-filter tutorial","title":"Particle-filter tutorial","text":"This example has demonstrated filtering and smoothing in an advanced application that includes manual control over noise, mixed continuous and discrete state.","category":"page"},{"location":"discretization/#Discretization","page":"Discretization","title":"Discretization","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"This package operates exclusively on discrete-time dynamics, and dynamics describing, e.g., ODE systems must thus be discretized. This page describes the details around discretization for nonlinear and linear systems, as well as how to discretize continuous-time noise processes. ","category":"page"},{"location":"discretization/#Nonlinear-ODEs","page":"Discretization","title":"Nonlinear ODEs","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"Continuous-time dynamics functions on the form (x,u,p,t) -> ẋ can be discretized (integrated) using the function SeeToDee.Rk4, e.g.,","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"using SeeToDee\ndiscrete_dynamics = SeeToDee.Rk4(continuous_dynamics, sampletime; supersample=1)","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"where the integer supersample determines the number of RK4 steps that is taken internally for each change of the control signal (1 is often sufficient and is the default). The returned function discrete_dynamics is on the form (x,u,p,t) -> x⁺.","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"note: Note\nWhen solving state-estimation problems, accurate integration is often less important than during simulation. The motivations for this are severalThe dynamics model is often inaccurate, and solving an inaccurate model to high accuracy can be a waste of effort.\nThe performance is often dictated by the disturbances acting on the system.\nState-estimation enjoys feedback from measurements that corrects for slight errors due to integration.","category":"page"},{"location":"discretization/#Linear-systems","page":"Discretization","title":"Linear systems","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"A linear system on the form ","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"dotx(t) = Ax(t) + Bu(t)\ny(t) = Cx(t) + Du(t)","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"can be discretized using ControlSystems.c2d, which defaults to a zero-order hold discretization. See the example below for more info.","category":"page"},{"location":"discretization/#Covariance-matrices","page":"Discretization","title":"Covariance matrices","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"Covariance matrices for continuous-time noise processes can be discretized using","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"using ControlSystemIdentification\nR1d = c2d(sys::StateSpace{<:Discrete}, R1::Matrix)\nR1d, R2d = c2d(sys::StateSpace{<:Discrete}, R1::Matrix, R2::Matrix)","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"This samples a continuous-time covariance matrix to fit the provided discrete-time system sys.","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"The method used comes from theorem 5 in the reference below.","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"Ref: \"Discrete-time Solutions to the Continuous-time Differential Lyapunov Equation With Applications to Kalman Filtering\",  Patrik Axelsson and Fredrik Gustafsson","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"On singular covariance matrices: The traditional double integrator with covariance matrix Q = diagm([0,σ²]) can not be sampled with this method. Instead, the input matrix (\"Cholesky factor\") of Q must be manually kept track of, e.g., the noise of variance σ² enters like N = [0, 1] which is sampled using ZoH and becomes Nd = [Ts^2 / 2; Ts] which results in the covariance matrix σ² * Nd * Nd' (see example below).","category":"page"},{"location":"discretization/#Example","page":"Discretization","title":"Example","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"The following example will discretize a linear double integrator system. Double integrators arise when the position of an object is controlled by a force, i.e., when Newtons second law f = ma governs the dynamics. The system can be written on the form","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"dot x(t) = Ax(t) + Bu(t) + Nw(t)\ny(t) = Cx(t) + e(t)","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"where N = B are both equal to [0, 1], indicating that the noise w(t) enters like a force (this could be for instance due to air resistance or friction).","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"We start by defining the system that takes u as an input and discretize that with a sample time of T_s = 01.","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"using ControlSystemsBase\nA = [0 1; 0 0]\nB = [0; 1;;]\nC = [1 0]\nD = 0\nTs = 0.1 # Sample time\n\nsys = ss(A,B,C,D)\nsysd = c2d(sys, Ts) # Discretize the dynamics","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"We then form another system, this time with w(t) as the input, and thus N as the input matrix instead of B. We assume that the noise has a standard deviation of sigma_1 = 05","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"σ1 = 0.5\nN  = σ1*[0; 1;;]\nsys_w  = ss(A,N,C,D)\nsys_wd = c2d(sys_w, Ts) # Discretize the noise system\nNd  = sys_wd.B # The discretized noise input matrix\nR1d = Nd*Nd' # The final discrete-time covariance matrix","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"We can verify that the matrix we computed corresponds to the theoretical covariance matrix for a discrete-time double integrator:","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"R1d ≈ σ1^2*[Ts^2 / 2; Ts]*[Ts^2 / 2; Ts]'","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"For a nonlinear system, we could adopt a similar strategy by first linearizing the system around a suitable operating point. Alternatively, we could make use of the fact that some of the state estimators in this package allows the covariance matrices to be functions of the state, and thus compute a new discretized covariance matrix using a linearization around the current state.","category":"page"},{"location":"discretization/#Non-uniform-sample-rates","page":"Discretization","title":"Non-uniform sample rates","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"Special care is needed if the sample rate is not constant, i.e., the time interval between measurements varies. ","category":"page"},{"location":"discretization/#Dropped-samples","page":"Discretization","title":"Dropped samples","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"A common case is that the sample rate is constant, but some measurements are lost. This case is very easy to handle; the filter loop iterates between two steps","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"Prediction using predict!(filter, x, u, p, t)\nCorrection using correct!(f, u, y, p, t)","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"If a measurement y is lacking, one simply skips the corresponding call to correct! where y is missing. Repeated calls to predict! corresponds to simulating the system without any feedback from measurements, like if an ODE was solved. Internally, the filter will keep track of the covariance of the estimate, which is likely to grow if no measurements are used to inform the filter about the state of the system.","category":"page"},{"location":"discretization/#Stochastic-sample-rate","page":"Discretization","title":"Stochastic sample rate","text":"","category":"section"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"In some situations, such as in event-based systems, the sample rate is truly stochastic. There is no single correct way of handling this, and we instead outline some alternative approaches.","category":"page"},{"location":"discretization/","page":"Discretization","title":"Discretization","text":"If the filtering is performed offline on a batch of data, time-varying dynamics can be used, for instance by supplying matrices to a KalmanFilter on the form A[:, :, t]. Each A is then computed as the discretization with the sample time given as the time between measurement t and measurement t+1.\nA conceptually simple approach is to choose a very small sample interval T_s which is smaller than the smallest occuring sample interval in the data, and approximate each sample interval by rounding it to the nearest integer multiple of T_s. This transforms the problem to an instance of the \"dropped samples\" problem described above.\nMake use of an adaptive integrator instead of the fixed-step rk4 supplied in this package, and manually keep track of the step length that needs to be taken.","category":"page"},{"location":"benchmark/#Benchmark-test","page":"Benchmark","title":"Benchmark test","text":"","category":"section"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"To see how the performance varies with the number of particles, we simulate several times. The following code simulates the system and performs filtering using the simulated measurements. We do this for varying number of time steps and varying number of particles.","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"note: Note\nTo run this code, see the bottom of src/example_lineargaussian.jl.","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"function run_test()\n    particle_count = [10, 20, 50, 100, 200, 500, 1000]\n    time_steps = [20, 100, 200]\n    RMSE = zeros(length(particle_count),length(time_steps)) # Store the RMS errors\n    propagated_particles = 0\n    t = @elapsed for (Ti,T) = enumerate(time_steps)\n        for (Ni,N) = enumerate(particle_count)\n            montecarlo_runs = 2*maximum(particle_count)*maximum(time_steps) ÷ T ÷ N\n            E = sum(1:montecarlo_runs) do mc_run\n                pf = ParticleFilter(N, dynamics, measurement, df, dg, d0) # Create filter\n                u = @SVector randn(2)\n                x = SVector{2,Float64}(rand(rng, d0))\n                y = SVector{2,Float64}(sample_measurement(pf,x,u,0,1))\n                error = 0.0\n                @inbounds for t = 1:T-1\n                    pf(u, y) # Update the particle filter\n                    x = dynamics(x,u,t) + SVector{2,Float64}(rand(rng, df)) # Simulate the true dynamics and add some noise\n                    y = SVector{2,Float64}(sample_measurement(pf,x,u,0,t)) # Simulate a measuerment\n                    u = @SVector randn(2) # draw a random control input\n                    error += sum(abs2,x-weighted_mean(pf))\n                end # t\n                √(error/T)\n            end # MC\n            RMSE[Ni,Ti] = E/montecarlo_runs\n            propagated_particles += montecarlo_runs*N*T\n            @show N\n        end # N\n        @show T\n    end # T\n    println(\"Propagated $propagated_particles particles in $t seconds for an average of $(propagated_particles/t/1000) particles per millisecond\")\n    return RMSE\nend\n\n@time RMSE = run_test()","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"Propagated 8400000 particles in 1.140468043 seconds for an average of 7365.397085484139 particles per millisecond","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"We then plot the results","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"time_steps     = [20, 100, 200]\nparticle_count = [10, 20, 50, 100, 200, 500, 1000]\nnT             = length(time_steps)\nleg            = reshape([\"$(time_steps[i]) time steps\" for i = 1:nT], 1,:)\nplot(particle_count,RMSE,xscale=:log10, ylabel=\"RMS errors\", xlabel=\" Number of particles\", lab=leg)","category":"page"},{"location":"benchmark/","page":"Benchmark","title":"Benchmark","text":"(Image: window)","category":"page"},{"location":"distributions/#High-performance-Distributions","page":"High-performance distributions","title":"High performance Distributions","text":"","category":"section"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"When using LowLevelParticleFilters, a number of methods related to distributions are defined for static arrays, making logpdf etc. faster. We also provide a new kind of distribution: TupleProduct <: MultivariateDistribution that behaves similarly to the Product distribution. The TupleProduct however stores the individual distributions in a tuple, has compile-time known length and supports Mixed <: ValueSupport, meaning that it can be a product of both Continuous and Discrete dimensions, something not supported by the standard Product. Example","category":"page"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"using BenchmarkTools, LowLevelParticleFilters, Distributions\ndt = TupleProduct((Normal(0,2), Normal(0,2), Binomial())) # Mixed value support","category":"page"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"A small benchmark","category":"page"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"sv = @SVector randn(2)\nd = Distributions.Product([Normal(0,2), Normal(0,2)])\ndt = TupleProduct((Normal(0,2), Normal(0,2)))\ndm = MvNormal(2, 2)\n@btime logpdf($d,$(Vector(sv))) # 32.449 ns (1 allocation: 32 bytes)\n@btime logpdf($dt,$(Vector(sv))) # 21.141 ns (0 allocations: 0 bytes)\n@btime logpdf($dm,$(Vector(sv))) # 48.745 ns (1 allocation: 96 bytes)","category":"page"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"@btime logpdf($d,$sv) # 22.651 ns (0 allocations: 0 bytes)\n@btime logpdf($dt,$sv) # 0.021 ns (0 allocations: 0 bytes)\n@btime logpdf($dm,$sv) # 0.021 ns (0 allocations: 0 bytes)","category":"page"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"Without loading LowLevelParticleFilters, the timing for the native distributions are the following","category":"page"},{"location":"distributions/","page":"High-performance distributions","title":"High-performance distributions","text":"@btime logpdf($d,$sv) # 32.621 ns (1 allocation: 32 bytes)\n@btime logpdf($dm,$sv) # 46.415 ns (1 allocation: 96 bytes)","category":"page"},{"location":"#LowLevelParticleFilters","page":"Home","title":"LowLevelParticleFilters","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"(Image: CI) (Image: codecov)","category":"page"},{"location":"","page":"Home","title":"Home","text":"This is a library for state estimation, that is, given measurements y(t) from a dynamical system, estimate the state vector x(t). Throughout, we assume dynamics on the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"x(t+1) = f(x(t) u(t) p t w(t))\ny(t) = g(x(t) u(t) p t e(t))","category":"page"},{"location":"","page":"Home","title":"Home","text":"where x is the state vector, u an input, p some form of parameters, t is the time and we are disturbances (noise). Throughout the documentation, we often call the function f dynamics and the function g measurement.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The dynamics above describe a discrete-time system, i.e., the function f takes the current state and produces the next state. This is in contrast to a continuous-time system, where f takes the current state but produces the time derivative of the state. A continuous-time system can be discretized, described in detail in Discretization.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The parameters p can be anything, or left out. You may write the dynamics functions such that they depend on p and include parameters when you create a filter object. You may also override the parameters stored in the filter object when you call any function on the filter object. This behavior is modeled after the SciML ecosystem.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Depending on the nature of f and g, the best method of estimating the state may vary. If fg are linear and the disturbances are additive and Gaussian, the KalmanFilter is an optimal state estimator. If any of the above assumptions fail to hold, we may need to resort to more advanced estimators. This package provides several filter types, outlined below.","category":"page"},{"location":"#Estimator-types","page":"Home","title":"Estimator types","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We provide a number of filter types","category":"page"},{"location":"","page":"Home","title":"Home","text":"KalmanFilter. A standard Kalman filter. Is restricted to linear dynamics (possibly time varying) and Gaussian noise.\nExtendedKalmanFilter: For nonlinear systems, the EKF runs a regular Kalman filter on linearized dynamics. Uses ForwardDiff.jl for linearization. The noise model must be Gaussian.\nUnscentedKalmanFilter: The Unscented Kalman filter often performs slightly better than the Extended Kalman filter but may be slightly more computationally expensive. The UKF handles nonlinear dynamics and measurement model, but still requires an additive Gaussian noise model and assumes all posterior distributions are Gaussian, i.e., can not handle multi-modal posteriors.\nParticleFilter: The particle filter is a nonlinear estimator. This version of the particle filter is simple to use and assumes that both dynamics noise and measurement noise are additive. Particle filters handle multi-modal posteriors.\nAdvancedParticleFilter: This filter gives you more flexibility, at the expense of having to define a few more functions. This filter does not require the noise to be additive and is thus the most flexible filter type.\nAuxiliaryParticleFilter: This filter is identical to ParticleFilter, but uses a slightly different proposal mechanism for new particles.\nDAEUnscentedKalmanFilter: An Unscented Kalman filter for differential-algebraic systems (DAE).","category":"page"},{"location":"#Functionality","page":"Home","title":"Functionality","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package provides ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Filtering, estimating x(t) given measurements up to and including time t. We call the filtered estimate x(tt) (read as x at t given t).\nSmoothing, estimating x(t) given data up to T  t, i.e., x(tT).\nParameter estimation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"All filters work in two distinct steps.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The prediction step (predict!). During prediction, we use the dynamics model to form x(tt-1) = f(x(t-1) )\nThe correction step (correct!). In this step, we adjust the predicted state x(tt-1) using the measurement y(t) to form x(tt).","category":"page"},{"location":"","page":"Home","title":"Home","text":"In general, all filters represent not only a point estimate of x(t), but a representation of the complete posterior probability distribution over x given all the data available up to time t. One major difference between different filter types is how they represent these probability distributions.","category":"page"},{"location":"#Particle-filter","page":"Home","title":"Particle filter","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A particle filter represents the probability distribution over the state as a collection of samples, each sample is propagated through the dynamics function f individually. When a measurement becomes available, the samples, called particles, are given a weight based on how likely the particle is given the measurement. Each particle can thus be seen as representing a hypothesis about the current state of the system. After a few time steps, most weights are inevitably going to be extremely small, a manifestation of the curse of dimensionality, and a resampling step is incorporated to refresh the particle distribution and focus the particles on areas of the state space with high posterior probability.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Defining a particle filter is straightforward, one must define the distribution of the noise df in the dynamics function, dynamics(x,u,p,t) and the noise distribution dg in the measurement function measurement(x,u,p,t). Both of these noise sources are assumed to be additive, but can have any distribution. The distribution of the initial state d0 must also be provided. An example for a linear Gaussian system is given below.","category":"page"},{"location":"","page":"Home","title":"Home","text":"using LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots","category":"page"},{"location":"","page":"Home","title":"Home","text":"Define problem","category":"page"},{"location":"","page":"Home","title":"Home","text":"n = 2   # Dimension of state\nm = 1   # Dimension of input\np = 1   # Dimension of measurements\nN = 500 # Number of particles\n\nconst dg = MvNormal(p,1.0)          # Measurement noise Distribution\nconst df = MvNormal(n,1.0)          # Dynamics noise Distribution\nconst d0 = MvNormal(randn(n),2.0)   # Initial state Distribution\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Define linear state-space system (using StaticArrays for maximum performance)","category":"page"},{"location":"","page":"Home","title":"Home","text":"const A = SA[0.97043   -0.097368\n             0.09736    0.970437]\nconst B = SA[0.1; 0;;]\nconst C = SA[0 1.0]\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Next, we define the dynamics and measurement equations, they both take the signature (x,u,p,t) = (state, input, parameters, time) ","category":"page"},{"location":"","page":"Home","title":"Home","text":"dynamics(x,u,p,t) = A*x .+ B*u\nmeasurement(x,u,p,t) = C*x\nvecvec_to_mat(x) = copy(reduce(hcat, x)') # Helper function\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"the parameter p can be anything, and is often optional. If p is not provided when performing operations on filters, any p stored in the filter objects (if supported) is used. The default if none is provided and none is stored in the filter is p = SciMLBase.NullParameters().","category":"page"},{"location":"","page":"Home","title":"Home","text":"We are now ready to define and use a filter","category":"page"},{"location":"","page":"Home","title":"Home","text":"pf = ParticleFilter(N, dynamics, measurement, df, dg, d0)","category":"page"},{"location":"","page":"Home","title":"Home","text":"With the filter in hand, we can simulate from its dynamics and query some properties","category":"page"},{"location":"","page":"Home","title":"Home","text":"du = MvNormal(m,1.0)         # Random input distribution for simulation\nxs,u,y = simulate(pf,200,du) # We can simulate the model that the pf represents\npf(u[1], y[1])               # Perform one filtering step using input u and measurement y\nparticles(pf)                # Query the filter for particles, try weights(pf) or expweights(pf) as well\nx̂ = weighted_mean(pf)        # using the current state","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you want to perform filtering using vectors of inputs and measurements, try any of the functions","category":"page"},{"location":"","page":"Home","title":"Home","text":"sol = forward_trajectory(pf, u, y) # Filter whole vectors of signals\nx̂,ll = mean_trajectory(pf, u, y)\nplot(sol, xreal=xs, markersize=2)","category":"page"},{"location":"","page":"Home","title":"Home","text":"u ad y are then assumed to be vectors of vectors. StaticArrays is recommended for maximum performance.","category":"page"},{"location":"","page":"Home","title":"Home","text":"If MonteCarloMeasurements.jl is loaded, you may transform the output particles to Matrix{MonteCarloMeasurements.Particles} with the layout T × n_state using Particles(x,we). Internally, the particles are then resampled such that they all have unit weight. This is conventient for making use of the plotting facilities of MonteCarloMeasurements.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For a full usage example, see the benchmark section below or example_lineargaussian.jl","category":"page"},{"location":"#Resampling","page":"Home","title":"Resampling","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The particle filter will perform a resampling step whenever the distribution of the weights has become degenerate. The resampling is triggered when the effective number of samples is smaller than pf.resample_threshold in 0 1, this value can be set when constructing the filter. How the resampling is done is governed by pf.resampling_strategy, we currently provide ResampleSystematic <: ResamplingStrategy as the only implemented strategy. See https://en.wikipedia.org/wiki/Particle_filter for more info.","category":"page"},{"location":"#Particle-Smoothing","page":"Home","title":"Particle Smoothing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Smoothing is the process of finding the best state estimate given both past and future data. Smoothing is thus only possible in an offline setting. This package provides a particle smoother, based on forward filtering, backward simulation (FFBS), example usage follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"N     = 2000 # Number of particles\nT     = 80   # Number of time steps\nM     = 100  # Number of smoothed backwards trajectories\npf    = ParticleFilter(N, dynamics, measurement, df, dg, d0)\ndu    = MvNormal(m,1)     # Control input distribution\nx,u,y = simulate(pf,T,du) # Simulate trajectory using the model in the filter\ntosvec(y) = reinterpret(SVector{length(y[1]),Float64}, reduce(hcat,y))[:] |> copy\nx,u,y = tosvec.((x,u,y))\n\nxb,ll = smooth(pf, M, u, y) # Sample smooting particles\nxbm   = smoothed_mean(xb)   # Calculate the mean of smoothing trajectories\nxbc   = smoothed_cov(xb)    # And covariance\nxbt   = smoothed_trajs(xb)  # Get smoothing trajectories\nxbs   = [diag(xbc) for xbc in xbc] |> vecvec_to_mat .|> sqrt\nplot(xbm', ribbon=2xbs, lab=\"PF smooth\")\nplot!(vecvec_to_mat(x), l=:dash, lab=\"True\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can plot the particles themselves as well","category":"page"},{"location":"","page":"Home","title":"Home","text":"downsample = 5\nplot(vecvec_to_mat(x), l=(4,), layout=(2,1), show=false)\nscatter!(xbt[1, 1:downsample:end, :]', subplot=1, show=false, m=(1,:black, 0.5), lab=\"\")\nscatter!(xbt[2, 1:downsample:end, :]', subplot=2, m=(1,:black, 0.5), lab=\"\")","category":"page"},{"location":"#Kalman-filter","page":"Home","title":"Kalman filter","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The KalmanFilter (wiki) assumes that f and g are linear functions, i.e., that they can be written on the form","category":"page"},{"location":"","page":"Home","title":"Home","text":"x(t+1) = Ax(t) + Bu(t) + w(t)\ny(t) = Cx(t) + Du(t) + e(t)","category":"page"},{"location":"","page":"Home","title":"Home","text":"for some matrices ABCD where w sim N(0 R_1) and e sim N(0 R_2) are zero mean and Gaussian. The Kalman filter represents the posterior distributions over x by the mean and a covariance matrix. The magic behind the Kalman filter is that linear transformations of Gaussian distributions remain Gaussian, and we thus have a very efficient way of representing them.","category":"page"},{"location":"","page":"Home","title":"Home","text":"A Kalman filter is easily created using the constructor. Many of the functions defined for particle filters, are defined also for Kalman filters, e.g.:","category":"page"},{"location":"","page":"Home","title":"Home","text":"R1 = cov(df)\nR2 = cov(dg)\nkf = KalmanFilter(A, B, C, 0, R1, R2, d0)\nsol = forward_trajectory(kf, u, y) # filtered, prediction, pred cov, filter cov, loglik\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"It can also be called in a loop like the pf above","category":"page"},{"location":"","page":"Home","title":"Home","text":"for t = 1:T\n    kf(u,y) # Performs both correct and predict!!\n    # alternatively\n    ll, e = correct!(kf, y, nothing, t) # Returns loglikelihood and prediction error\n    x     = state(kf)\n    R     = covariance(kf)\n    predict!(kf, u, nothing, t)\nend","category":"page"},{"location":"","page":"Home","title":"Home","text":"The matrices in the Kalman filter may be time varying, such that A[:, :, t] is A(t). They may also be provided as functions on the form A(t) = A(x u p t). This works for both dynamics and covariance matrices.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The numeric type used in the Kalman filter is determined from the mean of the initial state distribution, so make sure that this has the correct type if you intend to use, e.g., Float32 or ForwardDiff.Dual for automatic differentiation.","category":"page"},{"location":"#Smoothing-using-KF","page":"Home","title":"Smoothing using KF","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Kalman filters can also be used for smoothing ","category":"page"},{"location":"","page":"Home","title":"Home","text":"kf = KalmanFilter(A, B, C, 0, cov(df), cov(dg), d0)\nxT,R,lls = smooth(kf, u, y, p) # Smoothed state, smoothed cov, loglik\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"Plot and compare PF and KF","category":"page"},{"location":"","page":"Home","title":"Home","text":"plot(vecvec_to_mat(xT), lab=\"Kalman smooth\", layout=2)\nplot!(xbm', lab=\"pf smooth\")\nplot!(vecvec_to_mat(x), lab=\"true\")","category":"page"},{"location":"#Unscented-Kalman-Filter","page":"Home","title":"Unscented Kalman Filter","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The UnscentedKalmanFilter represents posterior distributions over x as Gaussian distributions, but propagate them through a nonlinear function f by a deterministic sampling of a small number of particles called sigma points (this is referred to as the unscented transform). This UKF thus handles nonlinear functions fg, but only Gaussian disturbances and unimodal posteriors.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The UKF takes the same arguments as a regular KalmanFilter, but the matrices defining the dynamics are replaced by two functions, dynamics and measurement, working in the same way as for the ParticleFilter above.","category":"page"},{"location":"","page":"Home","title":"Home","text":"ukf = UnscentedKalmanFilter(dynamics, measurement, cov(df), cov(dg), MvNormal([1.,1.]), nu=m, ny=p)","category":"page"},{"location":"","page":"Home","title":"Home","text":"info: Info\nIf your function dynamics describes a continuous-time ODE, do not forget to discretize it before passing it to the UKF. See Discretization for more information.","category":"page"},{"location":"#UKF-for-DAE-systems","page":"Home","title":"UKF for DAE systems","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See the docstring for DAEUnscentedKalmanFilter or the test file. This filter is modeled after","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"Nonlinear State Estimation of Differential Algebraic Systems\" Ravi K. Mandela, Raghunathan Rengaswamy, Shankar Narasimhan","category":"page"},{"location":"","page":"Home","title":"Home","text":"warning: Warning\nThis filter is still considered experimental and subject to change without respecting semantic versioning. Use at your own risk. The AdvancedParticleFilter also supports DAE systems, see this tutorial.","category":"page"},{"location":"#Extended-Kalman-Filter","page":"Home","title":"Extended Kalman Filter","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The ExtendedKalmanFilter (EKF) is similar to the UKF, but propagates Gaussian distributions by linearizing the dynamics and using the formulas for linear systems similar to the standard Kalman filter. This can be slightly faster than the UKF (not always), but also less accurate for strongly nonlinear systems. The linearization is performed automatically using ForwardDiff.jl. In general, the UKF is recommended over the EKF unless the EKF is faster and computational performance is the top priority.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The EKF constructor has the following two signatures","category":"page"},{"location":"","page":"Home","title":"Home","text":"ExtendedKalmanFilter(dynamics, measurement, R1,R2,d0=MvNormal(Matrix(R1)); nu::Int, p = SciMLBase.NullParameters(), α = 1.0, check = true)\nExtendedKalmanFilter(kf, dynamics, measurement)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first constructor takes all the arguments required to initialize the extended Kalman filter, while the second one takes an already defined standard Kalman filter. using the first constructor, the user must provide the number of inputs to the system, nu.","category":"page"},{"location":"","page":"Home","title":"Home","text":"where kf is a standard KalmanFilter from which the covariance properties are taken.","category":"page"},{"location":"","page":"Home","title":"Home","text":"info: Info\nIf your function dynamics describes a continuous-time ODE, do not forget to discretize it before passing it to the UKF. See Discretization for more information.","category":"page"},{"location":"#AdvancedParticleFilter","page":"Home","title":"AdvancedParticleFilter","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The AdvancedParticleFilter works very much like the ParticleFilter, but admits more flexibility in its noise models.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The AdvancedParticleFilter type requires you to implement the same functions as the regular ParticleFilter, but in this case you also need to handle sampling from the noise distributions yourself. The function dynamics must have a method signature like below. It must provide one method that accepts state vector, control vector, parameter, time and noise::Bool that indicates whether or not to add noise to the state. If noise should be added, this should be done inside dynamics An example is given below","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Random\nconst rng = Random.Xoshiro()\nfunction dynamics(x, u, p, t, noise=false) # It's important that this defaults to false\n    x = A*x .+ B*u # A simple linear dynamics model in discrete time\n    if noise\n        x += rand(rng, df) # it's faster to supply your own rng\n    end\n    x\nend\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"The measurement_likelihood function must have a method accepting state, input, measurement, parameter and time, and returning the log-likelihood of the measurement given the state, a simple example below:","category":"page"},{"location":"","page":"Home","title":"Home","text":"function measurement_likelihood(x, u, y, p, t)\n    logpdf(dg, C*x-y) # A simple linear measurement model with normal additive noise\nend\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"This gives you very high flexibility. The noise model in either function can, for instance, be a function of the state, something that is not possible for the simple ParticleFilter. To be able to simulate the AdvancedParticleFilter like we did with the simple filter above, the measurement method with the signature measurement(x,u,p,t,noise=false) must be available and return a sample measurement given state (and possibly time). For our example measurement model above, this would look like this","category":"page"},{"location":"","page":"Home","title":"Home","text":"measurement(x, u, p, t, noise=false) = C*x + noise*rand(rng, dg)\nnothing # hide","category":"page"},{"location":"","page":"Home","title":"Home","text":"We now create the AdvancedParticleFilter and use it in the same way as the other filters:","category":"page"},{"location":"","page":"Home","title":"Home","text":"apf = AdvancedParticleFilter(N, dynamics, measurement, measurement_likelihood, df, d0)\nsol = forward_trajectory(apf, u, y, p)","category":"page"},{"location":"","page":"Home","title":"Home","text":"plot(sol, xreal=x)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We can even use this type as an AuxiliaryParticleFilter","category":"page"},{"location":"","page":"Home","title":"Home","text":"apfa = AuxiliaryParticleFilter(apf)\nsol = forward_trajectory(apfa, u, y, p)\nplot(sol, dim=1, xreal=x) # Same as above, but only plots a single dimension","category":"page"},{"location":"","page":"Home","title":"Home","text":"See the tutorials section for more advanced examples, including state estimation for DAE (Differential-Algebraic Equation) systems.","category":"page"},{"location":"#Troubleshooting-and-tuning","page":"Home","title":"Troubleshooting and tuning","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Tuning a particle filter can be quite the challenge. To assist with this, we provide som visualization tools","category":"page"},{"location":"","page":"Home","title":"Home","text":"debugplot(pf,u[1:20],y[1:20], runall=true, xreal=x[1:20])","category":"page"},{"location":"","page":"Home","title":"Home","text":"The plot displays all states and all measurements. The heatmap in the background represents the weighted particle distributions per time step. For the measurement sequences, the heatmap represent the distributions of predicted measurements. The blue dots corresponds to measured values. In this case, we simulated the data and we had access to states as well, if we do not have that, just omit xreal. You can also manually step through the time-series using","category":"page"},{"location":"","page":"Home","title":"Home","text":"commandplot(pf,u,y; kwargs...)","category":"page"},{"location":"","page":"Home","title":"Home","text":"For options to the debug plots, see ?pplot.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Something seems to be off with this figure as the hottest spot is not really where we would expect it","category":"page"},{"location":"","page":"Home","title":"Home","text":"Optimization of the log likelihood can be done by, e.g., global/black box methods, see BlackBoxOptim.jl, see examples in Parameter Estimation. Standard tricks apply, such as performing the parameter search in log-space etc.","category":"page"}]
}
