var documenterSearchIndex = {"docs":
[{"location":"distributions/#Performance-tips","page":"Performance tips","title":"Performance tips","text":"","category":"section"},{"location":"distributions/#StaticArrays","page":"Performance tips","title":"StaticArrays","text":"Use of StaticArrays.jl is recommended for optimal performance when the state dimension is small, e.g., less than about 10-15 for Kalman filters and less than about 100 for particle filters. In the section Parameter optimization we demonstrate one workflow that makes use of StaticArrays everywhere it is needed for an UnscentedKalmanFilter in order to get a completely allocation free filter. The following arrays must be static for this to hold\n\nThe initial state distribution (the vector and matrix passed to d0 = MvNormal(Î¼, Î£) for Kalman filters). If you are performing parameter optimization with gradients derived using ForwardDiff.jl, these must further have the correct element type. How to achieve this is demonstrated in the liked example above.\nInputs u measured outputs y.\nIn case of Kalman filters, the dynamic model matrices A, B, C, D and the covariance matrices R1, R2.\nThe dynamics functions for UnscentedKalmanFilter and particle filters must further return static arrays when passed static arrays as inputs.","category":"section"},{"location":"distributions/#Simplified-measurement-model","page":"Performance tips","title":"Simplified measurement model","text":"While using, e.g., an UnscentedKalmanFilter for a system with a linear or almost linear measurement model, consider using a linear or EKF measurement model. See Measurement models for more details.","category":"section"},{"location":"distributions/#Analysis-using-JET","page":"Performance tips","title":"Analysis using JET","text":"All flavors of Kalman filters are analyzed for potential runtime dispatch using JET.jl. This analysis is performed in the tests and generally requires a completely static filter using static arrays internally. See the tests for an example of how to set a filter up this way.","category":"section"},{"location":"distributions/#High-performance-Distributions","page":"Performance tips","title":"High performance Distributions","text":"When using LowLevelParticleFilters, a number of methods related to distributions are defined for static arrays, making logpdf etc. faster. We also provide a new kind of distribution: TupleProduct <: MultivariateDistribution that behaves similarly to the Product distribution. The TupleProduct however stores the individual distributions in a tuple, has compile-time known length and supports Mixed <: ValueSupport, meaning that it can be a product of both Continuous and Discrete dimensions, something not supported by the standard Product. Example\n\nusing BenchmarkTools, LowLevelParticleFilters, Distributions, StaticArrays\ndt = TupleProduct((Normal(0,2), Normal(0,2), Binomial())) # Mixed value support\n\nA small benchmark\n\nsv = @SVector randn(2)\nd = Distributions.Product([Normal(0,2), Normal(0,2)])\ndt = TupleProduct((Normal(0,2), Normal(0,2)))\ndm = MvNormal(2, 2)\n@btime logpdf($d,$(Vector(sv)))  # 19.536 ns (0 allocations: 0 bytes)\n@btime logpdf($dt,$(Vector(sv))) # 13.742 ns (0 allocations: 0 bytes)\n@btime logpdf($dm,$(Vector(sv))) # 11.392 ns (0 allocations: 0 bytes)\n\n@btime logpdf($d,$sv)  # 13.964 ns (0 allocations: 0 bytes)\n@btime logpdf($dt,$sv) # 12.817 ns (0 allocations: 0 bytes)\n@btime logpdf($dm,$sv) # 8.383  ns (0 allocations: 0 bytes)\n\nWithout loading LowLevelParticleFilters, the timing for the native distributions are the following\n\n@btime logpdf($d,$sv)  # 18.040 ns (0 allocations: 0 bytes)\n@btime logpdf($dm,$sv) # 9.938  ns (0 allocations: 0 bytes)","category":"section"},{"location":"sample_rate/#Influence-of-sample-rate-on-performance","page":"Influence of sample rate on performance","title":"Influence of sample rate on performance","text":"Naturally, if we sample more often, we obtain more information about the system and can thus expect better performance. Frequent sampling allows for an averaging effect that can mitigate the influence of measurement noise. Sampling \"frequently enough\" is also important in order to rely on theoretical concepts such as observability when analyzing what modes of the system can be accurately recovered. To understand this, consider an extreme case: a particle subject to a random force where we can measure the position of the particle (this is a double integrator system). If we measure the position of the particle often, we can infer both the position and the velocity of the particle, the system is observable. However, if we measure the position rather infrequently, we can't say much about the velocity of the particle since the noisy force driving the particle will have had a large influence on the velocity, which isn't directly measured, since the last measurement of the position. When analyzing observability traditionally, we may compute\n\nThe observability matrix. This can tell us the theoretical observable and unobservable subspaces of the system. One may take measurement noise into account by scaling the outputs to have equal variance, but one can not take driving noise properties into account.\nThe observability Gramian. This gives us a measure of how well we can estimate modes of the system in a balanced realization from the available measurements, but there is once again no way to take the driving noise into account.\n\nTo estimate the practical observability of the system we may instead consider an analysis of the stationary error covariance of a state estimator. For a linear-Gaussian system observed with a Kalman filter, the stationary Kalman gain and error covariance is obtained by solving an algebraic Riccati equation:\n\nbeginalign\nx^+ = Ax + w\ny = Cx + e \n\nx^+ = Ax + K(y - Cx)  qquad textestimator\n\nÎµ = x - x qquad textprediction error\nÎµ^+ = Ax + w - big(Ax + K(y - Cx) big) qquad textprediction error dynamics\nÎµ^+ = Ax + w - big(Ax + K(Cx + e - Cx) big)\nÎµ^+ = (A - KC)Îµ + w - Ke \nE(we^T) = 0 Longrightarrow \nE(w - Ke)(w - Ke)^T = R_1 + K R_2 K^T\nendalign\n\nThe stationary covariance of the prediction error Îµ(t+1t), R_(t+1t) = E_(Îµ(t+1t)Îµ(t+1t)^T), is automatically computed by the solver of the algebraic Riccati equation that computes the stationary Kalman gain K.\n\nBy incorporating the measurement, we form a filtering estimate Îµ(tt) and in doing so, reduce the covariance of the prediction error according to R_(tt) = (I - KC)R_(tt-1). \n\nnote: Note\nDue to the exact formulation of K returned by the Riccati solver in MatrixEquations.jl, we must either use A^-1K or compute K = RC^T (R_2 + C R C^T)^-1 ourselves. MatrixEquations.ared solves the Riccati equation corresponding to the filter form, but returns the K matrix for the prediction form. The matrix A is invertible as long as the system has no poles in the origin, which physical systems does not tend to have since this would correspond to either a pole at -infty in continuous time, i.e., a non-proper system, or a pole with much faster dynamics than the chosen discretization time.\n\nusing ControlSystemsBase, LinearAlgebra\nimport ControlSystemsBase.MatrixEquations\n\nfunction kalman_are(sys::AbstractStateSpace{<:Discrete}, R1, R2)\n    A,B,C,D = ssdata(sys)\n    Râˆž, p, K, args... = MatrixEquations.ared(A', C', R2, R1)\n    K', Râˆž, args...\nend\n\nTo perform an analysis of the performance as a function of the sample rate, we will assume that we have a continuous-time LTI system with a continuous-time Gaussian noise process driving the system. This will allow us to discretize both the system dynamics and noise process at varying sample rates and compute the stationary Kalman filter and associated stationary covariance matrix (see Discretization for more details). We assume that the measurement noise is a discrete-time noise process with a fixed covariance, representing a scenario where the sensor equipment is predetermined but the sample rate is not. ","category":"section"},{"location":"sample_rate/#Example-1:-Double-integrator","page":"Influence of sample rate on performance","title":"Example 1: Double integrator","text":"A double integrator can be thought of as a particle subject to a force, the continuous-time dynamics are ddot x = w.\n\nusing ControlSystemsBase, Plots, Test\nsysc  = ss([0 1; 0 0], [0; 1], [1 0], 0) # Continuous-time double integrator\nR1c   = [0 0; 0 1]                       # Continuous-time process noise covariance\nR2    = [1;;]                            # Measurement noise covariance\n\nTs    = 1                                # Sample interval\nsysd  = c2d(sysc, Ts)                    # Discretize the system\nR1d   = c2d(sysc, R1c, Ts)               # Discretize the process noise covariance\nK, Râˆž = kalman_are(sysd, R1d, R2)        # Compute the stationary Kalman gain and covariance\nRâˆž\n\nDoes the computed stationary covariance matrix match the expected covariance matrix we derived above? \n\nA,B,C,D = ssdata(sysd)\n@test lyap(Discrete, A-K*C, R1d + K*R2*K') â‰ˆ Râˆž\n\nFor this system, we expect the stationary filtering covariance R_(tt) to go to zero for small T_s since the system is observable. For large T_s, we expect the variance of the position estimate to approach the variance of the measurement noise, i.e., we don't expect the model to be of any use if it's forced to predict for too long. The variance of the velocity estimate is expected to go to infinity since the disturbance force has increasingly more time to affect the velocity and we cannot measure this. Let's investigate:\n\nTss = exp10.(LinRange(-3, 3, 30))\nRâˆžs = map(Tss) do Ts\n    sysd    = c2d(sysc, Ts)\n    A,B,C,D = ssdata(sysd)\n    R1d     = c2d(sysc, R1c, Ts)\n    AK, Râˆž  = kalman_are(sysd, R1d, R2)\n\n    # diag((I-A\\AK*C)*Râˆž) # This also works\n\n    K = (Râˆž*C')/(R2 + C*Râˆž*C')\n    diag((I-K*C)*Râˆž)\nend\nplot(Tss, reduce(hcat, Râˆžs)', label=[\"\\$Ïƒ^2 p\\$\" \"\\$Ïƒ^2 v\\$\"], xlabel=\"Sample interval [s]\", ylabel=\"Stationary filtering variance\", title=\"Double integrator\", xscale=:log10, yscale=:log10)\nhline!(R2, label=\"\\$R_2\\$\", linestyle=:dash, legend=:bottomright)\n\nThe plot confirms our expectations. Note: this plot shows the filtering covariance, the prediction-error covariance R_(t+1t) would in this case go to infinity for both state variables.","category":"section"},{"location":"sample_rate/#Example-2:-Double-integrator-with-friction","page":"Influence of sample rate on performance","title":"Example 2: Double integrator with friction","text":"If we take the same system as above, but introduce some friction in the system, we expect similar behavior for small sample intervals, but for large sample intervals we expect the stationary variance of the velocity to converge to a finite value due to the dissipation of energy in the system:\n\nsysc = ss([0 1; 0 -0.02], [0; 1], [1 0], 0) # Continuous-time double integrator with friction\n\nRâˆžs = map(Tss) do Ts\n    sysd    = c2d(sysc, Ts)\n    A,B,C,D = ssdata(sysd)\n    R1d     = c2d(sysc, R1c, Ts)\n    AK, Râˆž  = kalman_are(sysd, R1d, R2)\n    K       = (Râˆž*C')/(R2 + C*Râˆž*C')\n    diag((I-K*C)*Râˆž)\nend\nplot(Tss, reduce(hcat, Râˆžs)', label=[\"\\$Ïƒ^2 p\\$\" \"\\$Ïƒ^2 v\\$\"], xlabel=\"Sample interval [s]\", ylabel=\"Stationary filtering variance\", title=\"Double integrator with friction\", xscale=:log10, yscale=:log10)\nhline!(R2, label=\"\\$R_2\\$\", linestyle=:dash, legend=:bottomright)\n\nNice, it did.\n\nIf we instead look at the prediction-error covariance, we see the opposite behavior\n\nRâˆžs = map(Tss) do Ts\n    sysd   = c2d(sysc, Ts)\n    R1d    = c2d(sysc, R1c, Ts)\n    AK, Râˆž = kalman_are(sysd, R1d, R2)\n    diag(Râˆž)\nend\nplot(Tss, reduce(hcat, Râˆžs)', label=[\"\\$Ïƒ^2 p\\$\" \"\\$Ïƒ^2 v\\$\"], xlabel=\"Sample interval [s]\", ylabel=\"Stationary filtering variance\", title=\"Double integrator with friction\", xscale=:log10, yscale=:log10)\nhline!(R2, label=\"\\$R_2\\$\", linestyle=:dash, legend=:bottomright)\n\nin this case, the variance of the position prediction goes to infinity for large T_s since the position dynamics still contain a pure integrator. The velocity prediction variance still converges to a finite value, the same finite value as the filtering variance, which also happens to be the same value as we get by computing the stationary covariance of the noise filtered through the system without any Kalman filter. This indicates that the estimator is completely useless for large sample intervals and we can't predict the velocity any better than its long-term average:\n\nvelocity_dynamics = ss(-0.02, 1, 1, 0)\nRâˆžs[end][end] â‰ˆ lyap(velocity_dynamics, [1;;])[]","category":"section"},{"location":"sample_rate/#Convergence-of-time-varying-Kalman-filter","page":"Influence of sample rate on performance","title":"Convergence of time-varying Kalman filter","text":"When the dynamics is time invariant and the noise process is stationary, the time-varying Kalman filter converges to the stationary Kalman filter irrespective of what the inputs and outputs are. We can confirm this by running a simulation of the time-varying Kalman filter and checking that the stationary covariance converges to the stationary covariance we computed above. \n\nusing LowLevelParticleFilters\nTs    = 1\nsysd  = c2d(sysc, Ts)\nR1d   = c2d(sysc, R1c, Ts)\n_, Râˆž = kalman_are(sysd, R1d, R2)\nkf    = KalmanFilter(sysd, R1d, R2) # A Kalman filter can be constructed from a discrete-time system statespace model\nfor i = 1:1000 # Perform 1000 prediction and measurement updates to let the filter converge\n    update!(kf, [0], [0])\nend\n@test kf.R â‰ˆ Râˆž # The Kalman filter prediction error covariance converges to the stationary covariance\n\n(; K) = correct!(kf, [0], [0])   # Perform a measurement update\n@test K â‰ˆ (Râˆž*C')/(R2 + C*Râˆž*C') # The time varying Kalman gain converges to the stationary Kalman gain (direct form)\n@test kf.R â‰ˆ (I-K*C)*Râˆž          # The time varying Kalman filter filtering error covariance (after measurement update) converges to the stationary covariance","category":"section"},{"location":"parameter_estimation/#Parameter-Estimation","page":"Overview","title":"Parameter Estimation","text":"State estimation is an integral part of many parameter-estimation methods. Below, we will illustrate several different methods of performing parameter estimation. We can roughly divide the methods into two camps:\n\nMethods that optimize prediction error or likelihood by tweaking model parameters.\nMethods that add the parameters to be estimated as state variables in the model and estimate them using standard state estimation.\n\nFrom the first camp, we provide some basic functionality for maximum-likelihood estimation and MAP estimation in Maximum-likelihood and MAP estimation. An example of (2), joint state and parameter estimation, is provided in Joint state and parameter estimation.","category":"section"},{"location":"parameter_estimation/#Which-method-should-I-use?","page":"Overview","title":"Which method should I use?","text":"The methods demonstrated in this section have slightly different applicability, here, we try to outline which methods to consider for different problems:\n\nMethod Parameter Estimation Covariance Estimation Time Varying Parameters Online Estimation\nMaximum likelihood ðŸŸ¢ ðŸŸ¢ ðŸŸ¥ ðŸŸ¥\nJoint state/par estim ðŸ”¶ ðŸŸ¥ ðŸŸ¢ ðŸŸ¢\nPrediction-error opt. ðŸŸ¢ ðŸŸ¥ ðŸŸ¥ ðŸŸ¥\n\nWhen trying to optimize parameters of the noise distributions, most commonly the covariance matrices, maximum-likelihood (or MAP) is the only recommened method. Similarly, when parameters are time varying or you want an online estimate, the method that jointly estimates state and parameter is the only applicable method. When fitting standard parameters, all methods are applicable. In this case the joint state and parameter estimation tends to be inefficient and unneccesarily complex, and it is recommended to opt for maximum likelihood or prediction-error minimization. The prediction-error minimization (PEM) with a Gauss-Newtown optimizer is often the most efficient method for this type of problem.\n\nMaximum likelihood estimation tends to yield an estimator with better estimates of posterior covariance since this is explicitly optimized for, while PEM tends to produce the smallest possible prediction errors.","category":"section"},{"location":"parameter_estimation/#Pages-in-this-section","page":"Overview","title":"Pages in this section","text":"Maximum-likelihood and MAP estimation: Learn how to use particle filters and Kalman filters to compute likelihoods for parameter estimation.\nBayesian inference: Full Bayesian inference using PMMH and DynamicHMC.\nJoint state and parameter estimation: Estimate time-varying parameters by augmenting the state space.\nJoint state and parameter estimation using MUKF: Use the Marginalized Unscented Kalman Filter for efficient joint estimation.\nUsing an optimizer: Use gradient-based optimization with automatic differentiation for parameter estimation.\nIdentifiability: Analyze structural identifiability and Fisher information for parameter estimation problems.","category":"section"},{"location":"parameter_estimation/#Videos","page":"Overview","title":"Videos","text":"Examples of parameter estimation are available here.\n\nBy using an optimizer to optimize the likelihood of an UnscentedKalmanFilter:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/0RxQwepVsoM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nEstimation of time-varying parameters:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/zJcOPPLqv4A?si=XCvpo3WD-4U3PJ2S\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\nAdaptive control by means of estimation of time-varying parameters:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/Ip_prmA7QTU?si=Fat_srMTQw5JtW2d\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n<script>\n(function() {\n    var hash = window.location.hash;\n    if (!hash) return;\n\n    var redirects = {\n        '#Maximum-likelihood-estimation': '../param_est_ml/#Maximum-likelihood-estimation',\n        '#Generate-data-by-simulation': '../param_est_ml/#Generate-data-by-simulation',\n        '#Compute-likelihood-for-various-values-of-the-parameters': '../param_est_ml/#Compute-likelihood-for-various-values-of-the-parameters',\n        '#MAP-estimation': '../param_est_ml/#MAP-estimation',\n        '#Bayesian-inference-using-PMMH': '../param_est_bayesian/#Bayesian-inference-using-PMMH',\n        '#Bayesian-inference-using-DynamicHMC.jl': '../param_est_bayesian/#Bayesian-inference-using-DynamicHMC.jl',\n        '#Joint-state-and-parameter-estimation': '../param_est_joint/#Joint-state-and-parameter-estimation',\n        '#Joint-state-and-parameter-estimation-using-MUKF': '../param_est_mukf/#Joint-state-and-parameter-estimation-using-MUKF',\n        '#Using-an-optimizer': '../param_est_optimizer/#Using-an-optimizer',\n        '#Solving-using-Optim': '../param_est_optimizer/#Solving-using-Optim',\n        '#Solving-using-Gauss-Newton-optimization': '../param_est_optimizer/#Solving-using-Gauss-Newton-optimization',\n        '#Identifiability': '../param_est_identifiability/#Identifiability',\n        '#Polynomial-methods': '../param_est_identifiability/#Polynomial-methods',\n        '#Linear-methods': '../param_est_identifiability/#Linear-methods',\n        '#Fisher-Information-and-Augmented-State-Covariance': '../param_est_identifiability/#Fisher-Information-and-Augmented-State-Covariance',\n    };\n\n    if (redirects[hash]) {\n        window.location.replace(redirects[hash]);\n    }\n})();\n</script>","category":"section"},{"location":"disturbance_gallery/#Disturbance-gallery","page":"Disturbance gallery","title":"Disturbance gallery","text":"Most filters in this package assume that the disturbances acting on the system are comprised of Gaussian white noise. This may at first appear as a severe limitation, but together with a dynamical model, this is a surprisingly flexible combination. Most disturbance models we list are linear, which means that they work for any state estimator, including standard Kalman filters. In the end, we also mention some nonlinear disturbance models that require a nonlinear state estimator, such as an UnscentedKalmanFilter. For each disturbance model, we provide a statespace model and show a number of samples from the model, we also list a number of example scenarios where the model is useful. In many cases, models have an interpretation also in the Laplace domain or as a temporal Gaussian process. ","category":"section"},{"location":"disturbance_gallery/#Stochastic-vs.-deterministic-but-unknown","page":"Disturbance gallery","title":"Stochastic vs. deterministic but unknown","text":"While some sources of errors are random, such as sensor noise, other sources of errors are deterministic but unknown. For example, a miscalibrated sensor is affected by a static but unknown error. We may communicate these properties to our state estimator by\n\nProviding the initial distribution of the state. If this is, e.g., a wide Gaussian distribution, we indicate that we are uncertain about the initial state. If the covariance is zero, we indicate that the initial state is perfectly known. The initial state distribution is usually denoted d_0 in this documentation.\nProviding the covariance of the driving disturbance noise. If this is zero, the disturbance is deterministic and the uncertainty about it comes solely from the initial state distribution. If this is positive, the disturbance is random and the uncertainty about it comes from both the initial state distribution and the disturbance noise. Where distributions are assumed to be Gaussian, we refer to the covariance matrix of the dynamics noise as R_1 and the measurement noise R_2. When noises can take any distribution, we refer to these distributions as df and dg instead.","category":"section"},{"location":"disturbance_gallery/#White-noise","page":"Disturbance gallery","title":"White noise","text":"This is the simplest possible disturbance model and require no dynamical system at all, just the driving white-noise input. Most state estimators in this package assume that the noise is Gaussian, but particle filters can also be used with non-Gaussian noise.\n\nWhite noise has a flat spectrum (analogous to how white light contains all colors). ","category":"section"},{"location":"disturbance_gallery/#Samples","page":"Disturbance gallery","title":"Samples","text":"using Plots\nw = randn(100)\nplot(\n    plot(w, label=\"Gaussian white noise\"),\n    histogram(w, title=\"Histogram\"),\n)","category":"section"},{"location":"disturbance_gallery/#Integrated-white-noise","page":"Disturbance gallery","title":"Integrated white noise","text":"This simplest dynamical disturbance model is white noise integrated once. This is a non-stationary process since the variance grows over time, which means that this model is suitable for disturbances that can have any arbitrary magnitude, but no particular properties of the evolution of the disturbance over time is known. This models is sometimes called a Brownian random walk, or a Wiener process.","category":"section"},{"location":"disturbance_gallery/#Model","page":"Disturbance gallery","title":"Model","text":"Continuous time\n\ndotx = w\n\nDiscrete time\n\nx_k+1 = x_k + T_s w_k\n\nFrequency domain\n\nG(s) = frac1s","category":"section"},{"location":"disturbance_gallery/#Samples-2","page":"Disturbance gallery","title":"Samples","text":"Below, we draw samples from the disturbance model by creating a linear statespace system from ControlSystemsBase.jl and call lsim to simulate the system with white noise w sim mathcalN(0 1) input. We also compute the time-varying covariance of the disturbance process, assuming that the covariance of the initial state is zero. This is done by solving the discrete time-varying Lyapunov equation\n\nbeginaligned\nR_k+1 = A R_k A^T + BB^T \nR_0 = mathbf0 \nR_y_k = C R_k C^T\nendaligned\n\nimplemented in the function covariance_dynamics. \n\nusing ControlSystemsBase, Plots, LinearAlgebra\n\nfunction covariance_dynamics(sys, N=1000; R1=I)\n    # Calculate the covariance of the dynamics noise\n    iscontinuous(sys) && error(\"Only discrete-time systems are supported\")\n    (; A, B, C) = sys\n    Q = B * R1 * B' # Covariance of the dynamics noise\n    R = 0*I(size(A, 1)) # Initial covariance\n    Ry = [(C*R*C')[]] # Covariance of the output\n    for i = 1:N-1\n        R = A*R*A' + Q # Discrete-time Lyapunov equation\n        push!(Ry, (C*R*C')[])\n    end\n    return 2 .* sqrt.(Ry) # 2Ïƒ(t)\nend\n\nTs = 0.01 # Sampling time\nsys = ss(1, Ts, 1, 0, Ts) # Discrete-time integrator\nres = map(1:10) do i\n    w = randn(1, 1000) # White noise input\n    lsim(sys, w)\nend\nfigsim = plot(res)\nplot!(res[1].t, [1 -1] .* covariance_dynamics(sys), lab=\"2Ïƒ(t)\", color=:black, linestyle=:dash)\nfigspec = bodeplot(sys, plotphase=false)\nfigimp = plot(impulse(sys, 10), title=\"Impulse response\")\nplot(figsim, figspec, figimp, plot_title=\"Integrated white noise\")\n\nNote, the samples from this process do not look random and step like, but a random step-like process can nevertheless be well modeled by such a process (this is hinted at by the transfer function 1s which is identical to the Laplace transform of the step function). This model is used in a number of examples that demonstrate this property:\n\nJoint state and parameter estimation\nFault detection\nLQG control with integral action\n\nWhen the noise w has the variance 1, this leads to a process that has a linearly increasing variance with slope BB^T  T_s = T_s^2  T_s = T_s, that is, after 10 seconds the variance is 10T_s = 01. To make the covariance dynamics invariant to the choice of sample interval, we can use the variance R1 = ÏƒÂ² / Ts, in which case the variance is ÏƒÂ² after 1 second and 10ÏƒÂ² after 10 seconds, irrespective of the choice of sample interval T_s.","category":"section"},{"location":"disturbance_gallery/#Suitable-for","page":"Disturbance gallery","title":"Suitable for","text":"Random-step like disturbances\nFriction\nUnknown change of operating point or set point\nStatic or slowly varying calibration errors (if the error is completely static but initially unknown, use nonzero initial covariance but zero covariance for w).\nGyroscope drift","category":"section"},{"location":"disturbance_gallery/#Double-integrated-white-noise","page":"Disturbance gallery","title":"Double integrated white noise","text":"This is a second-order dynamical disturbance model that is white noise integrated twice. This is a non-stationary process since the variance grows over time, which means that this model is suitable for disturbances that can have any arbitrary magnitude, and where the evolution of the disturbance is subject to inertia, that is, the disturbance is expected to evolve be smoothly. ","category":"section"},{"location":"disturbance_gallery/#Model-2","page":"Disturbance gallery","title":"Model","text":"Continuous time\n\nddotx = w\n\nDiscrete time\n\nbeginaligned\nx_k+1 = x_k + T_s v_k + fracT_s^22w_k \nv_k+1 = v_k + T_s w_k\nendaligned\n\nFrequency domain\n\nG(s) = frac1s^2","category":"section"},{"location":"disturbance_gallery/#Samples-3","page":"Disturbance gallery","title":"Samples","text":"using ControlSystemsBase, Plots\nTs = 0.01 # Sampling time\nsys = ss([1 Ts; 0 1], [Ts^2/2; Ts], [1 0], 0, Ts) # Discrete-time double integrator\nres = map(1:10) do i\n    w = randn(1, 1000) # White noise input\n    lsim(sys, w)\nend\nfigsim = plot(res)\nplot!(res[1].t, [1 -1] .* covariance_dynamics(sys), lab=\"2Ïƒ(t)\", color=:black, linestyle=:dash)\nfigspec = bodeplot(sys, plotphase=false)\nplot(figsim, figspec, plot_title=\"Double integrated white noise\")","category":"section"},{"location":"disturbance_gallery/#Suitable-for-2","page":"Disturbance gallery","title":"Suitable for","text":"Random ramp-like disturbances\nSmoothly varying disturbances","category":"section"},{"location":"disturbance_gallery/#Low-pass-filtered-white-noise","page":"Disturbance gallery","title":"Low-pass filtered white noise","text":"If we pass white noise through a low-pass filter, we get a signal that is random but primarily contains low frequencies. This is a stationary process, which means that the variance does not grow indefinitely over time, and we can calculate the stationary covariance of the process by solving a Lyapunov equation (done by ControlSystemsBase.covar). We do this below in order to indicate the stationary standard deviation of the process in the plot of the samples. This model is associated with a tuning parameter that determines the cutoff frequency of the low-pass filter, `tau. ","category":"section"},{"location":"disturbance_gallery/#Model-3","page":"Disturbance gallery","title":"Model","text":"Continuous time\n\ndotx = frac1tau(-x + w)\n\nDiscrete time\n\nx_k+1 = Î± x_k + (1-Î±) w_k qquad Î± = e^-T_stau","category":"section"},{"location":"disturbance_gallery/#Transfer-function","page":"Disturbance gallery","title":"Transfer function","text":"G(s) = frac1tau s + 1","category":"section"},{"location":"disturbance_gallery/#Samples-4","page":"Disturbance gallery","title":"Samples","text":"using ControlSystemsBase, Plots\nTs = 0.01 # Sampling time\nÏ„ = 1.0\nsys = ss(c2d(tf(1, [Ï„, 1]), Ts)) # Discrete-time first-order low-pass filter\nres = map(1:10) do i\n    w = randn(1, 1000) # White noise input\n    lsim(sys, w)\nend\nfigsim = plot(res)\nhline!(2*sqrt.(covar(sys, I(1))) .* [1 -1], color=:black, linestyle=:dash, linewidth=2, label=\"2Ïƒ(âˆž)\") # Stationary standard deviation\nplot!(res[1].t, [1 -1] .* covariance_dynamics(sys), lab=\"2Ïƒ(t)\", color=:black, linestyle=:dash)\nfigspec = bodeplot(sys, plotphase=false)\nfigimp = plot(impulse(sys, 10), title=\"Impulse response\")\nplot(figsim, figspec, figimp, plot_title=\"Low-pass filtered white noise\")","category":"section"},{"location":"disturbance_gallery/#Suitable-for-3","page":"Disturbance gallery","title":"Suitable for","text":"Stationary noise dominated by low frequencies","category":"section"},{"location":"disturbance_gallery/#Alternative-names","page":"Disturbance gallery","title":"Alternative names","text":"Ornsteinâ€“Uhlenbeck process\nGaussian process: Exponential covariance function","category":"section"},{"location":"disturbance_gallery/#Higher-order-low-pass-filtered-white-noise","page":"Disturbance gallery","title":"Higher-order low-pass filtered white noise","text":"If we add more poles to the low-pass filter, we can model Gaussian processes with the MatÃ©rn covariance function with half-integer smoothness. The MatÃ©rn covariance with Î½=12 is equivalent to the first-order low-pass filter above, and with Î½=32 we get the model\n\nbeginaligned\nA = beginbmatrix\n0  1 \n-lambda^2  -2 lambda\nendbmatrix \nB = beginbmatrix\n0  1\nendbmatrix \nC = beginbmatrix\n1  0\nendbmatrix \nlambda = sqrt3  l\nendaligned\n\nwhere l is the length scale of the covariance function.","category":"section"},{"location":"disturbance_gallery/#Samples-from-MatÃ©rn-3/2-covariance-function","page":"Disturbance gallery","title":"Samples from MatÃ©rn 3/2 covariance function","text":"using ControlSystemsBase, Plots\nTs = 0.01 # Sampling time\nl = 1.0 # Length scale\nÎ» = sqrt(3) / l\nA = [0 1; -Î»^2 -2Î»]\nB = [0; 1]\nC = [1 0]\nsys = c2d(ss(A, B, C, 0), Ts)\nres = map(1:10) do i\n    w = randn(1, 1000) # White noise input\n    lsim(sys, w)\nend\nfigsim = plot(res)\n(; B,C) = sys\nplot!(res[1].t, [1 -1] .* covariance_dynamics(sys), lab=\"2Ïƒ(t)\", color=:black, linestyle=:dash)\nfigspec = bodeplot(sys, plotphase=false)\nfigimp = plot(impulse(sys, 10), title=\"Impulse response\")\nplot(figsim, figspec, figimp, plot_title=\"Low-pass (second order) filtered white noise\")\n\nNote how this produces smoother signals compared to the first-order low-pass filter. The MatÃ©rn covariance function with Î½=52 can be modeled by adding a third state to the system above, and so on.\n\nFor more details on the relation between temporal Gaussian processes and linear systems, see section 3.3 in \"Stochastic Differential Equation Methods for Spatio-Temporal Gaussian Process Regression\", Arno Solin.","category":"section"},{"location":"disturbance_gallery/#Periodic-disturbance","page":"Disturbance gallery","title":"Periodic disturbance","text":"If disturbances have a dominant frequency or period, such as 50Hz from the electrical grid, or 24hr from the sun, a periodic disturbance model can be used. A second-order linear system with a complex-conjugate pair of poles close to the imaginary axis has a resonance peak in the frequency response which is suitable for modeling periodic disturbances. If the disturbance is perfectly sinusoidal but the phase is unknown, we may indicate this by setting the covariance of the driving noise to zero and placing the poles exactly on the imaginary axis. ","category":"section"},{"location":"disturbance_gallery/#Model-4","page":"Disturbance gallery","title":"Model","text":"Continuous time\n\nbeginaligned\ndotx = beginbmatrix\n-zeta  -omega_0 \nomega_0  -zeta\nendbmatrix x + beginbmatrix\nomega_0 \n0\nendbmatrix w \ny = beginbmatrix\n0  omega_0\nendbmatrix x\nendaligned\n\nFrequency domain\n\nG(s) = fracomega_0s^2 + 2zeta omega_0 s + omega_0^2","category":"section"},{"location":"disturbance_gallery/#Samples-5","page":"Disturbance gallery","title":"Samples","text":"using ControlSystemsBase, Plots\nÏ‰0 = 2Ï€/3 # Resonance frequency [rad/s]\nÎ¶ = 0.1 # Damping ratio, smaller value gives higher amplitude\nTs = 0.05\nt = 0:Ts:20 # Time vector\nsys = c2d(ss([-Î¶ -Ï‰0; Ï‰0 -Î¶], [Ï‰0; 0], [0 Ï‰0], 0), Ts)\nres = map(1:10) do i\n    w = randn(1, length(t)) # White noise input\n    lsim(sys, w, t)\nend\nfigsim = plot(res)\n(; B,C) = sys\nplot!(res[1].t, [1 -1] .* covariance_dynamics(sys, length(res[1].t)), lab=\"2Ïƒ(t)\", color=:black, linestyle=:dash)\nfigspec = bodeplot(sys, plotphase=false)\nfigimp = plot(impulse(sys, 10), title=\"Impulse response\")\nplot(figsim, figspec, figimp, plot_title=\"Periodic disturbance\")","category":"section"},{"location":"disturbance_gallery/#One-sided-random-bumps","page":"Disturbance gallery","title":"One sided random bumps","text":"This is a nonlinear disturbance model that is useful when the disturbance is expected to be non-negative (or non-positive). The model is a combination of low-pass filtered white noise and a nonlinear integrator that integrates the low-pass filtered white noise only when it is positive. ","category":"section"},{"location":"disturbance_gallery/#Model-5","page":"Disturbance gallery","title":"Model","text":"Continuous time\n\nbeginaligned\ndotx = beginbmatrix\n-a x_1 + w \n-b x_2 + max(0 x_1)^n\nendbmatrix \ny = x_2\nendaligned","category":"section"},{"location":"disturbance_gallery/#Samples-6","page":"Disturbance gallery","title":"Samples","text":"Since this is a nonlinear model, we cannot use the lsim function to simulate it. Instead, we use the package SeeToDee.jl to discretize the nonlinear dynamics model, learn more under Discretization.\n\nusing LowLevelParticleFilters, SeeToDee, Plots, Random\nTs = 0.1 # Sampling time\na = 1 # Low-pass filter (inverse) time constant, controls how often the bumps appear (higher value âŸ¹ more often)\nb = 2 # Bump decay (inverse) time constant\nn = 2 # Nonlinearity exponent\n\n# Define dynamics function\nfunction dynamics(x, w, p, t) # We assume that the noise is coming in through the second argument here. When using this model with an UnscentedKalmanFilter, we may instead add w as the 5:th argument and let the second argument be the control input.\n    x1, x2 = x\n    dx1 = -a * x1 + w[1]\n    dx2 = -b * x2 + max(0.0, x1)^n\n    return [dx1, dx2]\nend\ndiscrete_dynamics = SeeToDee.Rk4(dynamics, Ts)\n# Measurement function (only observes x2)\nfunction measurement(x, w, p, t)\n    return [x[2]]\nend\n# Simulate the model\nt = 0:Ts:20 # Time vector\nx0 = [0.0; 0.0] # Initial state\nRandom.seed!(0) # For reproducibility\nres = map(1:10) do i\n    if i == 1\n        w = [(j==0)/Ts for j in t] # Pulse input for first sample\n    else\n        w = [randn(1) for j in t] # White noise input\n    end\n    x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, w)\n    reduce(hcat, measurement.(x[1:end-1], w, nothing, t))'\nend\nplot(t, res, title=\"One-sided random bumps\", lw=[5 ones(1,9)])\n\nNote how the samples are all nonnegative, achieved by the nonlinearity. The first sample is the impulse response of the system, and this is drawn with a greater linewidth.","category":"section"},{"location":"disturbance_gallery/#Observability","page":"Disturbance gallery","title":"Observability","text":"This is a nonlinear model, but it is piecewise linear and we may use linear observability tests to check if the system is observable in each mode.\n\nAp = [-a 0; 1 -b]\nAn = [-a 0; 0 -b]\nB = [1.0; 0]\nC = [0 1]\nsysp = ss(Ap, B, C, 0)\nsysn = ss(An, B, C, 0)\n\nobservability(sysp)\n\nWhen x_2 is positive, the system is observable, but when x_2 is negative\n\nobservability(sysn)\n\nwe have lost observability of the first state variable. This may pose a problem for, e.g., an ExtendedKalmanFilter, which performs linearization around the current state estimate. To mitigate the observability issue, we may change the nonlinearity to, e.g., a softplus function:\n\nsoftplus(x, hardness=10) = log(1 + exp(hardness*x))/hardness # A softer version of ReLU\n\nfunction dynamics(x, w, p, t) # We assume that the noise is coming in through the second argument here. When using this model with an UnscentedKalmanFilter, we may instead add w as the 5:th argument and let the second argument be the control input.\n    x1, x2 = x\n    dx1 = -a * x1 + w[1]\n    dx2 = -b * x2 + softplus(x1)^n\n    return [dx1, dx2]\nend\ndiscrete_dynamics = SeeToDee.Rk4(dynamics, Ts)\nRandom.seed!(0) # For reproducibility\n\nres = map(1:10) do i\n    w = [randn(1) for i in t] # White noise input\n    x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, w)\n    reduce(hcat, measurement.(x[1:end-1], w, nothing, t))'\nend\nplot(t, res, title=\"One-sided random bumps (softplus)\")\n\nThis produces a very similar result to the previous model, but adds a tunable hardness parameter that can trade off observability and tendency to output values that are closer to zero.\n\nnote: Tip\nThe function ControlSystemsBase.observability(f::AbstractKalmanFilter, x, u, p, t=0.0) is overloaded for nonlinear state estimators from this package.","category":"section"},{"location":"disturbance_gallery/#One-sided-periodic-bumps","page":"Disturbance gallery","title":"One sided periodic bumps","text":"This is similar to the previous model, but with a periodic disturbance driving the nonlinear integrator, causing the bumps to have a dominant period.","category":"section"},{"location":"disturbance_gallery/#Model-6","page":"Disturbance gallery","title":"Model","text":"Continuous time\n\nbeginaligned\ndotx = beginbmatrix\nx_2 \n-2 zeta omega_0 x_2 - omega_0^2 x_1 + w \n-b x_3 + max(0 x_1)^n\nendbmatrix \ny = x_3\nendaligned","category":"section"},{"location":"disturbance_gallery/#Samples-7","page":"Disturbance gallery","title":"Samples","text":"using SeeToDee, LowLevelParticleFilters, Plots\nperiod = 24.0\nÏ‰ = 2Ï€ / period # Resonance frequency [rad/s]\nÎ¶ = 0.1\nb = 0.9 # Bump decay (inverse) time constant\nn = 2 # Nonlinearity exponent\nTs = 0.1 # Sampling time\n\n# Define dynamics function\nfunction dynamics(x, w, p, t)\n    x1, x2, x3 = x\n    dx1 = x2\n    dx2 = -2 * Î¶ * Ï‰ * x2 - Ï‰^2 * x1 + w[1]\n    relu_x1 = max(0.0, x1)\n    dx3 = -b * x3 + relu_x1^n\n    return [dx1, dx2, dx3]\nend\n\ndiscrete_dynamics = SeeToDee.Rk4(dynamics, Ts)\n\n# Measurement function (only observes x3)\nfunction measurement(x, u, p, t)\n    return [x[3]]\nend\n\n# Simulate the model\nt = 0:Ts:120 # Time vector\nx0 = [0.0; 0.0; 0.0] # Initial state\n\nres = map(1:10) do i\n    if i == 1\n        w = [2*(j==0)/Ts for j in t] # Pulse input for first sample\n    else\n        w = [randn(1) for j in t] # White noise input\n    end\n    x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, w)\n    reduce(hcat, measurement.(x[1:end-1], w, nothing, t))'\nend\nplot(t, res, title=\"One sided periodic bumps\", lw=[5 ones(1,9)])\n\nThe first sample is one possible impulse response of the system (the system is nonlinear and does not have a single unique impulse response), and this is drawn with a greater linewidth.","category":"section"},{"location":"disturbance_gallery/#Useful-for","page":"Disturbance gallery","title":"Useful for","text":"One-sided periodic disturbances\nExample: Sunlight hitting a thermometer once per day, but only if it is sunny","category":"section"},{"location":"disturbance_gallery/#Deterministic-disturbances","page":"Disturbance gallery","title":"Deterministic disturbances","text":"If there is a deterministic aspect to the disturbance, we may use the fact that dynamics and measurement functions (as well as Kalman filter matrices) may depend on time. For exactly, the perfectly deterministic measurement disturbance disturbance sin(t) is easily modeled by including it in the measurement function. \n\nmeasurement(x, u, p, t) = ... + sin(t)","category":"section"},{"location":"disturbance_gallery/#Heteroschedastic-disturbances","page":"Disturbance gallery","title":"Heteroschedastic disturbances","text":"If the disturbance is heteroschedastic, i.e., the variance of the disturbance depends on time or on the state, we may easily indicate this to the state estimator by either\n\nLet the covariance matrix depend on time or state, applicable to all estimators.\nEncode varying the gain from disturbance to state/measurement in the corresponding dynamics/measurement function, applicable to nonlinear state estimators only.","category":"section"},{"location":"disturbance_gallery/#Non-Gaussian-driving-noise","page":"Disturbance gallery","title":"Non-Gaussian driving noise","text":"All Kalman-type estimators assume that the driving noise is Gaussian. Particle filters are not limited to this assumption and can generally be used with any distribution that can be sampled from, see Smoothing the track of a moving beetle for an example, where the mode is affected by Binomial noise.","category":"section"},{"location":"disturbance_gallery/#Dynamical-models-of-measurement-disturbance","page":"Disturbance gallery","title":"Dynamical models of measurement disturbance","text":"When using any of the dynamical models above to model measurement disturbances, the noise driving the disturbance dynamics must be sourced from the dynamics noise, e.g., for a Kalman filter for the model\n\nbeginaligned\nx = Ax + Bu + w \ny  = Cx + Du + e\nendaligned\n\nwe must let the dynamics noise w drive the disturbance model, and design C such that the estimated disturbance has the desired effect on the measurement. This model leaves no room to let the measurement noise e to pass through a dynamical system, and this is thus only useful (and required) to model white Gaussian measurement noise. See How to tune a Kalman filter for more insights.\n\nDynamical models of measurement disturbances are useful in a lot of situations, such as\n\nPeriodic measurement noise, such as 50Hz noise from the electrical grid.\nSlow sensor drift, such as gyroscopic drift.\nCalibration errors.\nSensor misalignment in rotating systems.\nComplimentary filtering for accelerometers and gyroscopes.\nSensor degradation, such as deposition of dust or algae growth.","category":"section"},{"location":"disturbance_gallery/#Continuous-vs.-discrete-time-covariance","page":"Disturbance gallery","title":"Continuous vs. discrete time covariance","text":"See Discretization: Covariance matrices.","category":"section"},{"location":"adaptive_kalmanfilter/#Noise-adaptive-Kalman-filter","page":"Kalman-filter tutorial with LowLevelParticleFilters","title":"Noise-adaptive Kalman filter","text":"In this tutorial we will consider filtering of a 1D position track, similar in spirit to what one could have obtained from a GPS device, but limited to 1D for easier visualization. We will use a constant-velocity model, i.e., use a double integrator,\n\nbeginaligned\nx_k+1 = beginbmatrix 1  T_s  0  1 endbmatrix x_k + beginbmatrix T_s^22  T_s endbmatrix w_k \ny_k = beginbmatrix 1  0 endbmatrix x_k + v_k\nendaligned\n\nwhere w_k sim mathcalN(0 Ïƒ_w) is the process noise, and v_k sim mathcalN(0 R_2) is the measurement noise, and illustrate how we can make use of an adaptive noise covariance to improve the filter performance.","category":"section"},{"location":"adaptive_kalmanfilter/#Data-generation","page":"Kalman-filter tutorial with LowLevelParticleFilters","title":"Data generation","text":"We start by generating some position data that we want to perform filtering on. The \"object\" we want to track is initially stationary, and transitions to moving with a constant velocity after a while. \n\nusing LowLevelParticleFilters, Plots, Random\nRandom.seed!(1)\n\n# Create a time series for filtering\nx = [zeros(50); 0:100]\nT = length(x)\nY = x + randn(T)\nplot([Y x], lab=[\"Measurement\" \"True state to be tracked\"], c=[1 :purple])","category":"section"},{"location":"adaptive_kalmanfilter/#Simple-Kalman-filtering","page":"Kalman-filter tutorial with LowLevelParticleFilters","title":"Simple Kalman filtering","text":"We will use a Kalman filter to perform the filtering. The model is a double integrator, i.e., a constant-acceleration model. The state vector is thus x = p v^T, where p is the position and v is the velocity. When designing a Kalman filter, we need to specify the noise covariances R_1 and R_2. While it's often easy to measure the covariance of the measurement noise, R_2, it can be quite difficult to know ahead of time what the dynamics noise covariance, R_1, should be. In this example, we will use an adaptive filter, where we will increase the dynamics noise covariance if the filter prediction error is too large. However, we first run the filter twice, once with a large R_1 and once with a small R_1 to illustrate the difference.\n\ny = [[y] for y in Y] # create a vector of vectors for the KF\nu = fill([], T) # No inputs in this example :(\n\n# Define the model\nTs = 1\nA = [1 Ts; 0 1]\nB = zeros(2, 0)\nC = [1 0]\nD = zeros(0, 0)\nR2 = [1;;]\n\nÏƒws = [1e-2, 1e-5] # Dynamics noise standard deviations\n\nfig = plot(Y, lab=\"Measurement\")\nfor Ïƒw in Ïƒws\n    R1 = Ïƒw*[Ts^3/3 Ts^2/2; Ts^2/2 Ts] # The dynamics noise covariance matrix is Ïƒw*Bw*Bw' where Bw = [Ts^2/2; Ts]\n    kf = KalmanFilter(A, B, C, D, R1, R2)\n    measure = LowLevelParticleFilters.measurement(kf)\n    yh = [measure(state(kf), u[1], nothing, 1)] \n    for t = 1:T # Main filter loop\n        kf(u[t], y[t]) # Performs both prediction and correction\n        xh = state(kf)\n        yht = measure(xh, u[t], nothing, t)\n        push!(yh, yht)\n    end\n\n    Yh = reduce(hcat, yh)\n    plot!(Yh', lab=\"Estimate \\$Ïƒ_w\\$ = $Ïƒw\")\nend\nfig\n\nWhen R_1 is small (controlled by Ïƒ_w), we get a nice and smooth filter estimate, but this estimate clearly lags behind the true state. When R_1 is large, the filter estimate is much more responsive, but it also has a lot of noise.","category":"section"},{"location":"adaptive_kalmanfilter/#Adaptive-noise-covariance","page":"Kalman-filter tutorial with LowLevelParticleFilters","title":"Adaptive noise covariance","text":"Below, we will implement an adaptive filter, where we keep the dynamics noise covariance low by default, but increase it if the filter prediction error is too large. We will use a Z-score to determine if the prediction error is too large. The Z-score is defined as the number of standard deviations the prediction error is away from the estimated mean. This time around we use separate correct! and predict! calls, so that we can access the prediction error as well as the prior covariance of the prediction error, S. S (or the Cholesky factor Sáµª) will be used to compute the Z-score.\n\nWhen implementing behavior such as time varying covariance, we may either implement the filtering loop manually, like we do below, or make use of the callback functionality available in forward_trajectory, which we do in the next code snippet.\n\nÏƒw = 1e-5 # Set the covariance to a low value by default\nR1 = Ïƒw*[Ts^3/3 Ts^2/2; Ts^2/2 Ts]\nkf = KalmanFilter(A, B, C, D, R1, R2)\nmeasure = LowLevelParticleFilters.measurement(kf)\n\n# Some arrays to store simulation data\nyh = []\nes = Float64[]\nÏƒs = Float64[]\nfor t = 1:T # Main filter loop\n    ll, e, S, Sáµª = correct!(kf, u[t], y[t], nothing, t) # Manually call the prediction step\n    xh = state(kf)\n    yht = measure(xh, u[t], nothing, t)\n\n    Ïƒ = âˆš(e'*(Sáµª\\e)) # Compute the Z-score\n    push!(es, e[]) # Save for plotting\n    push!(Ïƒs, Ïƒ)\n    if Ïƒ > 3 # If the Z-score is too high\n        # we temporarily increase the dynamics noise covariance by 1000x to adapt faster\n        predict!(kf, u[t], nothing, t; R1 = 1000kf.R1) \n    else\n        predict!(kf, u[t], nothing, t)\n    end\n\n    push!(yh, yht)\nend\n\nYh = reduce(hcat, yh)\nplot([Y Yh'], lab=[\"Measurement\" \"Adaptive estimate\"])\n\nNot too bad! This time the filter estimate is much more responsive during the transition, but exhibits favorable noise properties during the stationary phases. We can also plot the prediction error and the Z-score to see how the filter adapts to the dynamics noise covariance.\n\nplot([es Ïƒs], lab=[\"Prediction error\" \"Z-score\"])\n\nNotice how the prediction errors, that should ideally be centered around zero, remain predominantly negative for a long time interval after the transition. This can be attributed to an overshoot in the velocity state of the estimator, but the rapid decrease of the covariance after the transition makes the filter slow at correcting its overshoot. If we want, we could mitigate this and make the adaptation even more sophisticated by letting the covariance remain large for a while after a transition in operating mode has been detected. Below, we implement a simple version of this, where we use a multiplier Ïƒ_wt that defaults to 1, but is increase to a very large value of 1000 if a transition is detected. When no transition is detected, Ïƒ_wt is decreased exponentially back down to 1.\n\nAs mentioned above, in this code snippet we make use of the callback functionality of forward_trajectory rather than implementing the filtering loop manually, we thus add the logic for modifying the covariance in the pre_predict_cb callback function. \n\nÏƒw  = 1e-5 # Set the covariance to a low value by default\nÏƒwt = 1.0\nR1  = Ïƒw*[Ts^3/3 Ts^2/2; Ts^2/2 Ts]\nkf  = KalmanFilter(A, B, C, D, R1, R2)\nmeasure = LowLevelParticleFilters.measurement(kf)\n\nfunction pre_predict_cb(kf, u, y, p, t, ll, e, S, Sáµª)\n    Ïƒ = âˆš(e'*(Sáµª\\e)) # Compute the Z-score\n    global Ïƒwt\n    if Ïƒ > 3 # If the Z-score is too high\n        Ïƒwt = 1000.0 # Set the R1 multiplier to a very large value\n    else\n        Ïƒwt = max(0.9Ïƒwt, 1.0) # Decrease exponentially back to 1\n    end\n    push!(Ïƒs, Ïƒ)\n    push!(Ïƒwts, Ïƒwt)\n    Ïƒwt*kf.R1 # The pre_predict_cb may return either nothing (operate through side effects) or a modified R1 matrix to use for this particular time step. Here, we make use of both approaches.\nend\n\n# Some arrays to store simulation data\nÏƒs = Float64[]\nÏƒwts = Float64[]\n\nsol = forward_trajectory(kf, u, y; pre_predict_cb)\nes = reduce(vcat, sol.e) # Extract prediciton errors\nYh = reduce(hcat, measure.(sol.xt, sol.u, nothing, nothing)) # Extract predicted outputs\nplot([Y Yh'], lab=[\"Measurement\" \"Adaptive estimate\"])\n\nplot([es Ïƒs Ïƒwts], lab=[\"Prediction error\" \"Z-score\" \"\\$Ïƒ_{wt}\\$ multiplier\"], layout=2, sp=[1 1 2])\n\nThis time, the prediction errors look more like white noise centered around zero after the initial transient caused by the transition.","category":"section"},{"location":"adaptive_kalmanfilter/#Summary","page":"Kalman-filter tutorial with LowLevelParticleFilters","title":"Summary","text":"This tutorial demonstrated simple Kalman filtering for a double integrator without control inputs. We saw how the filtering estimate could be improved by playing around with the covariance matrices of the estimator, helping it catch up to fast changes in the behavior of the system without sacrificing steady-state noise properties.\n\nIn this case, we handled the modification of R_1 outside of the filter, implementing our own filtering loop. Some applications get away with instead providing time-varying matrices in the form of a 3-dimension array, where the third dimension corresponds to time, or instead of providing a matrix, providing a function R_1(x u p t) allows the matrix to be a function of state, input, parameters and time. These options apply to all matrices in the filter, including the dynamics matrices, ABCD.\n\nLastly, we mention the ability of the KalmanFilter to act like a recursive least-squares estimator, by setting the \"forgetting factor Î±1 when creating the KalmanFilter. Î±1 will cause the filter will exhibit exponential forgetting similar to an RLS estimator, in addition to the covariance inflation due to R1. It is thus possible to get a RLS-like algorithm by setting R_1 = 0 R_2 = 1Î± and Î±  1.","category":"section"},{"location":"adaptive_kalmanfilter/#Disturbance-modeling-and-noise-tuning","page":"Kalman-filter tutorial with LowLevelParticleFilters","title":"Disturbance modeling and noise tuning","text":"See this notebook for a blog post about disturbance modeling and noise tuning using LowLevelParticleFilter.jl","category":"section"},{"location":"neural_network/#Adaptive-Neural-Network-training","page":"Adaptive Neural-Network training","title":"Adaptive Neural-Network training","text":"In this example, we will demonstrate how we can take the estimation of time-varying parameters to the extreme, and use a nonlinear state estimator to estimate the weights in a neural-network model of a dynamical system. \n\nIn the tutorial Joint state and parameter estimation, we demonstrated how we can add a parameter as a state variable and let the state estimator estimate this alongside the state. In this example, we will try to learn an entire black-box model of the system dynamics using a neural network, and treat the network weights as time-varying parameters by adding them to the state.\n\nWe start by generating some data from a simple dynamical system, we will continue to use the quadruple-tank system from Joint state and parameter estimation.\n\nusing LowLevelParticleFilters, Lux, Random, SeeToDee, StaticArrays, Plots, LinearAlgebra, ComponentArrays, DifferentiationInterface, SparseMatrixColorings\nusing SparseConnectivityTracer: TracerSparsityDetector\nusing DisplayAs # hide\n\nusing LowLevelParticleFilters: SimpleMvNormal\n\nfunction quadtank(h,u,p,t)\n    kc = 0.5\n    k1, k2, g = 1.6, 1.6, 9.81\n    A1 = A3 = A2 = A4 = 4.9\n    a1, a3, a2, a4 = 0.03, 0.03, 0.03, 0.03\n    Î³1, Î³2 = 0.2, 0.2\n\n    if t > 2000\n        a1 *= 1.5 # Change the parameter at t = 2000\n    end\n\n    ssqrt(x) = âˆš(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n\n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     Î³1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     Î³2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-Î³2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-Î³1)*k1/A4 * u[1]\n    ]\nend\n\nTs = 30 # sample time\ndiscrete_dynamics = SeeToDee.Rk4(quadtank, Ts) # Discretize dynamics\nnu = 2 # number of control inputs\nnx = 4 # number of state variables\nny = 4 # number of measured outputs\n\nfunction generate_data()   \n    measurement(x,u,p,t) = x#SA[x[1], x[2]]\n    Tperiod = 200\n    t = 0:Ts:4000\n    u = vcat.((0.25 .* sign.(sin.(2pi/Tperiod .* t)) .+ 0.25) .* sqrt.(rand.()))\n    u = SVector{nu, Float32}.(vcat.(u,u))\n    x0 = Float32[2,2,3,3]\n    x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u)[1:end-1]\n    y = measurement.(x, u, 0, 0)\n    y = [Float32.(y .+ 0.01.*randn.()) for y in y] # Add some noise to the measurement\n\n    (; x, u, y, nx, nu, ny, Ts)\nend\n\nrng = Random.default_rng()\nRandom.seed!(rng, 1)\ndata = generate_data()\nnothing # hide","category":"section"},{"location":"neural_network/#Neural-network-dynamics","page":"Adaptive Neural-Network training","title":"Neural network dynamics","text":"Our neural network will be a small feedforward network built using the package Lux.jl. \n\nni = ny + nu\nnhidden = 8\nconst model_ = Chain(Dense(ni, nhidden, tanh), Dense(nhidden, nhidden, tanh), Dense(nhidden, ny))\n\nSince the network is rather small, we will train on the CPU only, this will be fast enough for this use case. We may extract the parameters of the network using the function Lux.setup, and convert them to a ComponentArray to make it easier to refer to different parts of the combined state vector.\n\ndev = cpu_device()\nps, st = Lux.setup(rng, model_) |> dev\nparr = ComponentArray(ps)\nnothing # hide\n\nThe dynamics of our black-box model will call the neural network to predict the next state given the current state and input. We bias the dynamics towards low frequencies by adding a multiple of the current state to the prediction of the next state, 0.95*x (motivated in Tangent-Space Regularization for Neural-Network Models of Dynamical Systems). We also add a small amount of weight decay to the parameters of the neural network for regularization, 0.995*p.\n\nfunction dynamics(out0, xp0, u, _, t)\n    xp = ComponentArray(xp0, getaxes(s0))\n    out = ComponentArray(out0, getaxes(s0))\n    x = xp.x\n    p = xp.p\n    xp, _ = Lux.apply(model_, [x; u], p, st)\n    @. out.x = 0.95f0*x+xp\n    @. out.p = 0.995f0*p\n    nothing\nend\n\n@views measurement(out, x, _, _, _) = out .= x[1:nx] # Assume measurement of the full state vector\nnothing # hide\n\nFor simplicity, we have assumed here that we have access to measurements of the entire state vector of the original process. This is many times unrealistic, and if we do not have such access, we may instead augment the measured signals with delayed versions of themselves (sometimes called a delay embedding). This is a common technique in discrete-time system identification, used in e.g., ControlSystemIdentification.arx and subspaceid.\n\nThe initial state of the process x0 and the initial parameters of the neural network parr can now be concatenated to form the initial augmented state s0.\n\nx0 = Float32[2; 2; 3; 3]\ns0 = ComponentVector(; x=x0, p=parr)\nnothing # hide","category":"section"},{"location":"neural_network/#Kalman-filter-setup","page":"Adaptive Neural-Network training","title":"Kalman filter setup","text":"We will estimate the parameters using two different nonlinear Kalman filters, the ExtendedKalmanFilter and the UnscentedKalmanFilter. The covariance matrices for the filters, R1, R2, may be tuned such that we get the desired learning speed of the weights, where larger covariance for the network weights will allow for faster learning, but also more noise in the estimates. \n\nR1 = Diagonal([0.1ones(nx); 0.01ones(length(parr))]) .|> Float32\nR2 = Diagonal((1e-2)^2 * ones(ny)) .|> Float32\nnothing # hide\n\nThe ExtendedKalmanFilter uses Jacobians of the dynamics and measurement model, and if we do not provide those functions they will be automatically computed using ForwardDiff.jl. Since our Jacobians will be relatively large but sparse in this example, we will make use of the sparsity-aware features of DifferentiationInterface.jl in order to get efficient Jacobian computations. \n\nfunction Ajacfun(x,u,p,t) # Function that returns a function for the Jacobian of the dynamics\n    # For large neural networks, it might be faster to use an OOP formulation with Zygote instead of ForwardDiff. Zygote does not handle the in-place version\n    backend = AutoSparse(\n        AutoForwardDiff(),\n        # AutoZygote(),\n        sparsity_detector=TracerSparsityDetector(),\n        coloring_algorithm=GreedyColoringAlgorithm(),\n    )\n    out = similar(getdata(x))\n    inner = (out,x)->dynamics(out,x,u,p,t)\n    prep = prepare_jacobian(inner, out, backend, getdata(x))\n    jac = one(eltype(x)) .* sparsity_pattern(prep)\n    function (x,u,p,t)\n        inner2 = (out,x)->dynamics(out,x,u,p,t)\n        DifferentiationInterface.jacobian!(inner2, out, jac, prep, backend, x)\n    end\nend\n\nAjac = Ajacfun(s0, data.u[1], nothing, 0)\n\nconst CJ_ = [I(nx) zeros(Float32, nx, length(parr))] # The jacobian of the measurement model is constant\nCjac(x,u,p,t) = CJ_\nnothing # hide","category":"section"},{"location":"neural_network/#Estimation","page":"Adaptive Neural-Network training","title":"Estimation","text":"We may now initialize our filters and perform the estimation. Here, we use the function forward_trajectory to perform filtering along the entire data trajectory at once, but we may use this in a streaming fashion as well, as more data becomes available in real time.\n\nWe plot the one-step ahead prediction of the outputs and compare to the \"measured\" data.\n\nekf = ExtendedKalmanFilter(dynamics, measurement, R1, R2, SimpleMvNormal(s0, 100R1); nu, check=false, Ajac, Cjac, Ts)\nukf = UnscentedKalmanFilter(dynamics, measurement, R1, R2, SimpleMvNormal(s0, 100R1); nu, ny, Ts)\n\n@time sole = forward_trajectory(ekf, data.u, data.x)\n@time solu = forward_trajectory(ukf, data.u, data.x)\n\nkwargs = (plotx=false, plotxt=false, plotyh=true, plotyht=false, plotu=false, plote=true)\nplot(sole;  name=\"EKF\", layout=(nx, 1), size=(1200, 1500), kwargs...)\nplot!(solu; name=\"UKF\", ploty=false, kwargs...)\nDisplayAs.PNG(Plots.current()) # hide\n\nWe see that prediction errors, e, are large in the beginning when the network weights are randomly initialized, but after about half the trajectory the errors are significantly reduced. Just like in the tutorial Joint state and parameter estimation, we modified the true dynamics after some time, at t=2000, and we see that the filters are able to adapt to this change after a transient increase in prediction error variance.\n\nWe may also plot the evolution of the neural-network weights over time, and see how the filters adapt to the changing dynamics of the system.\n\nplot(\n    plot(0:Ts:4000, reduce(hcat, sole.xt)'[:, nx+1:end], title=\"EKF parameters\"),\n    plot(0:Ts:4000, reduce(hcat, solu.xt)'[:, nx+1:end], title=\"UKF parameters\"),\n    legend = false,\n)\nDisplayAs.PNG(Plots.current()) # hide","category":"section"},{"location":"neural_network/#Smoothing","page":"Adaptive Neural-Network training","title":"Smoothing","text":"@time xTe,RTe = smooth(sole, ekf)\n@time xTu,RTu = smooth(solu, ukf)\nplot(\n    plot(0:Ts:4000, reduce(hcat, xTe)'[:, nx+1:end], title=\"EKF parameters\", c=1, alpha=0.2),\n    plot(0:Ts:4000, reduce(hcat, xTu)'[:, nx+1:end], title=\"UKF parameters\", c=1, alpha=0.2),\n    legend = false,\n)","category":"section"},{"location":"neural_network/#Benchmarking","page":"Adaptive Neural-Network training","title":"Benchmarking","text":"The neural network used in this example has\n\nlength(parr)\n\nparameters, and the length of the data is\n\nlength(data.u)\n\nPerforming the estimation using the Extended Kalman Filter took\n\nusing BenchmarkTools\n@btime forward_trajectory(ekf, data.u, data.x);\n  # 46.034 ms (77872 allocations: 123.45 MiB)\n\nand with the Unscented Kalman Filter\n\n@btime forward_trajectory(ukf, data.u, data.x);\n  # 142.608 ms (2134370 allocations: 224.82 MiB)\n\nThe EKF is a bit faster, which is to be expected. Both methods are very fast from a neural-network training perspective, but the performance will not scale favorably to very large network sizes.","category":"section"},{"location":"neural_network/#Closing-remarks","page":"Adaptive Neural-Network training","title":"Closing remarks","text":"We have seen how to estimate train a black-box neural network dynamics model by treating the parameter estimation as a state-estimation problem. This example is very simple and leaves a lot of room for improvement, such as\n\nWe assumed very little prior knowledge of the dynamics. In practice, we may want to model as much as possible from first principles and add a neural network to capture only the residuals that our first-principles model cannot capture.\nWe started the training of the network weights directly from a random initialization. In practice, we may want to pre-train the network on a large offline dataset before updating the weights adaptively in real-time.\nWe used forward-mode AD to compute the Jacobian. The Jacobian of the dynamics has dense rows, which means that it's theoretically favorable to use reverse-mode AD to compute it. This is possible using Zygote.jl, but Zygote does not handle array mutation, and one must thus avoid the in-place version of the dynamics. Since the number of parameters in this example is small, sparse forward mode AD ended up being slightly faster.","category":"section"},{"location":"thermal_nn_example/#Learning-a-disturbance-model-using-SciML","page":"SciML: Learning a sunshine disturbance model","title":"Learning a disturbance model using SciML","text":"In this example we will attempt to learn how an unknown and stochastic input, sun shining in through a window, influences a dynamical system, the temperature in a house. How the sun is shining on a house on a cloud-free day, absent any surrounding trees or buildings can be readily simulated. However, the real world offers a number of challenges that influence the effect this has on the inside temperature\n\nSurrounding trees and buildings may cast shadows on the house at certain parts of the day.\nThe sun shining in through a window has much greater effect than if it's shining on a wall.\nCloud cover modulates the effect of the sun.\nAs a vendor of, e.g., HVAC equipment with interesting control systems, you may not want to model each individual site in detail, including the location and size of windows and surrounding shading elements. Even if these are static, they are thus to be considered unknown.\n\nWe can model this as some deterministic parts and some stochastic parts, some known and some unknown. The path of the sun across the sky is deterministic and periodic, with one daily and one yearly component. The surroundings, like trees and buildings, are for the most part static, but the influence these have on the insolation is unknown, and so is the exact location of windows on the house. However, the cloud cover is stochastic. We can thus model insolation by\n\nTreating the current cloud cover as a stochastic variable C_cloud in 0 1 to be estimated continuously. We achieve this by including the cloud cover as a state variable in our system.\nTreating the insolation when there is no cloud cover as a deterministic function of the time of day (we ignore the yearly component here for simplicity). This function will be modeled as a basis-function expansion that will be learned from data.\nThe effective insolation at any point in time is thus I_solar = (1 - C_cloud) I_solar clear, that is, the cloud-free insolation is modulated by the current cloud cover.","category":"section"},{"location":"thermal_nn_example/#System-Description","page":"SciML: Learning a sunshine disturbance model","title":"System Description","text":"We consider a simplified thermal model of a single-room house:\n\nState variable: room temperature T\nControl input: heater power P_heater\nDisturbances: external temperature T_ext and solar insolation through windows\n\nThe heat transfer dynamics follow Newton's law of cooling with additional terms for heating and solar gains:\n\nC_thermal á¹ª = -k_loss  (T - T_ext) + Î·  P_heater + A_window I_solar\n\nwhere:\n\nC_thermal: thermal capacity of the room\nk_loss: heat loss coefficient\nÎ·: heater efficiency\nA_window: effective window area\nI_solar: solar insolation (W/mÂ²)","category":"section"},{"location":"thermal_nn_example/#Data-Generation","page":"SciML: Learning a sunshine disturbance model","title":"Data Generation","text":"First, let's generate realistic thermal data with time-varying external conditions:\n\nusing LowLevelParticleFilters, Random, SeeToDee, StaticArrays, Plots, LinearAlgebra, Statistics\nusing LowLevelParticleFilters: SimpleMvNormal\nusing Optim\nusing DisplayAs # hide\n\n# System parameters\nconst C_thermal = 10.0f0      # Thermal capacity (kWh/Â°C)\nconst k_loss = 0.5f0          # Heat loss coefficient (kW/Â°C)\nconst Î· = 0.95f0              # Heater efficiency\nconst A_window = 20.0f0       # Effective window area factor\n\n# Time constants\nconst hours_per_day = 24.0f0\nconst Ts = 0.25f0            # Sample time (15 minutes)\n\n# Helper function for time of day (0-24 hours)\ntime_of_day(t) = mod(t, hours_per_day)\n\n# External temperature (sinusoidal daily variation)\nfunction external_temp(t)\n    tod = time_of_day(t)\n    T_mean = 10.0f0  # Mean temperature (Â°C)\n    T_amplitude = 5.0f0  # Daily variation amplitude\n    T_mean + T_amplitude * sin(2Ï€ * (tod - 6) / hours_per_day)  # Peak at 12:00\nend\n\n# True solar insolation pattern (W/mÂ²)\nfunction true_insolation(t, cloud_cover)\n    tod = time_of_day(t)\n    # Cropped sinusoid\n    base_insolation = max(500.0f0 * (0.2 + sin(Ï€ * (tod - 6) / 12)), 0)\n    return base_insolation * (1 - cloud_cover)\nend\n\n# Plot the daily patterns\nt_plot = 0:0.1:48  # Two days for visualization\nplot(t_plot, external_temp.(t_plot), label=\"External Temperature (Â°C)\", lw=2)\nplot!(t_plot, true_insolation.(t_plot, 0) ./ 100, label=\"Clear Sky Insolation (Ã—100 W/mÂ²)\", lw=2)\nplot!(t_plot, true_insolation.(t_plot, 0.5) ./ 100, label=\"50% Cloud Cover (Ã—100 W/mÂ²)\", lw=2, ls=:dash)\nxlabel!(\"Time (hours)\")\ntitle!(\"Daily Environmental Patterns\")\n\nNow let's define the true system dynamics and generate training data:\n\n# True system dynamics with time-varying cloud cover\nfunction thermal_dynamics_true(x, u, p, t)\n    T_room, cloud_cover = x\n    P_heater = u[1]\n    \n    # External conditions\n    T_ext = external_temp(t)\n    I_solar = true_insolation(t, cloud_cover)\n    \n    # Heat balance\n    dT_dt = (-k_loss * (T_room - T_ext) + Î· * P_heater + A_window * I_solar / 1000) / C_thermal\n    \n    # Cloud cover changes slowly (random walk)\n    dcloud_dt = 0.0f0  # Driven by process noise, zero deterministic dynamics\n    \n    SA[dT_dt, dcloud_dt]\nend\n\n# Discretize the dynamics\ndiscrete_dynamics_true = SeeToDee.Rk4(thermal_dynamics_true, Ts)\n\n# Generate training data\nfunction generate_thermal_data(; days=7, measure_cloud_cover=true)\n    rng = Random.default_rng()\n    Random.seed!(rng, 123)\n    \n    t = 0:Ts:(days * hours_per_day)\n    N = length(t)\n    \n    # Generate control inputs (varied heating patterns)\n    u = Vector{SVector{1, Float32}}(undef, N)\n    for (i, t) in enumerate(t)\n        tod = time_of_day(t)\n        # Different heating strategies throughout the day\n        if 6 <= tod < 8 || 17 <= tod < 22  # Morning and evening comfort\n            u[i] = SA[3.0f0 + 0.5f0 * randn(rng)]  # Higher heating\n        elseif 22 <= tod || tod < 6  # Night setback\n            u[i] = SA[1.0f0 + 0.2f0 * randn(rng)]  # Lower heating\n        else  # Day time\n            u[i] = SA[2.0f0 + 0.3f0 * randn(rng)]  # Moderate heating\n        end\n        u[i] = SA[clamp(u[i][1], 0.0f0, 5.0f0)]  # Heater power limits\n    end\n    \n    # Initial conditions\n    x0 = SA[20.0f0, 0.3f0]  # Initial room temp and cloud cover\n    \n    # Simulate with slowly varying cloud cover\n    x = Vector{SVector{2, Float32}}(undef, N)\n    x[1] = x0\n    for i in 2:N\n        # Process noise (small for temperature, larger for cloud cover)\n        w = SA[0.01f0 * randn(rng), 0.06f0 * randn(rng)]\n        x_next = discrete_dynamics_true(x[i-1], u[i-1], nothing, t[i-1])\n        x[i] = x_next + w\n        # Keep cloud cover in [0, 1]\n        x[i] = SA[x[i][1], clamp(x[i][2]*0.999, 0.0f0, 1.0f0)]\n    end\n    \n    # Measurements - optionally include cloud cover\n    if measure_cloud_cover\n        y = [SA[x_i[1] + 0.1f0 * randn(rng), x_i[2] + 0.01f0 * randn(rng)] for x_i in x]\n        ny = 2\n    else\n        y = [SA[x_i[1] + 0.1f0 * randn(rng)] for x_i in x]\n        ny = 1\n    end\n    \n    (; x, u, y, t, N, Ts, ny, measure_cloud_cover)\nend\n\n# Generate data (with cloud cover measurements by default)\nmeasure_cloud_cover = false  # Set to false to exclude cloud cover measurements\ndata = generate_thermal_data(; days=14, measure_cloud_cover)\n\n# Visualize the generated data\np1 = plot(data.t, [x[1] for x in data.x], label=\"Room Temperature\", ylabel=\"Temperature (Â°C)\")\nplot!(data.t, [external_temp(t) for t in data.t], label=\"External Temperature\", ls=:dash, alpha=0.7)\n\np2 = plot(data.t, [x[2] for x in data.x], label=\"Cloud Cover\", ylabel=\"Cloud Cover (0-1)\", color=:orange)\np3 = plot(data.t, [u[1] for u in data.u], label=\"Heater Power\", ylabel=\"Power (kW)\", color=:red)\n\nplot(p1, p2, p3, layout=(3,1), size=(900, 600), xlabel=\"Time (hours)\")","category":"section"},{"location":"thermal_nn_example/#Radial-Basis-Function-Model","page":"SciML: Learning a sunshine disturbance model","title":"Radial Basis Function Model","text":"We'll use a radial basis function expansion to learn the solar insolation pattern. This provides a more interpretable model than a neural network, with basis functions centered during daylight hours:\n\n# Initialize RBF weights (parameters to be learned)\nrng = Random.default_rng()\nRandom.seed!(rng, 456)\nconst n_basis = 8  # Number of basis functions\n# Initialize with positive weights since insolation is always positive (\"negative insolation\" could model things like someone always opening a window in the morning letting cold air in)\nrbf_weights = 100.0f0 * rand(Float32, n_basis)  # Random positive initialization\n\nfunction basis_functions(t)\n    tod = time_of_day(t)\n    centers = LinRange(7.0f0, 17.0f0, n_basis) # Centers spread from 9 AM to 5 PM\n    width = 1.5f0  # Width of each Gaussian basis function (in hours)\n    @. exp(-((tod - centers) / width)^2)\nend\n\n# RBF evaluation function\nfunction compute_nn_insolation(t, weights)\n    return weights'basis_functions(t) # Linear combination of basis functions\nend\n\nnothing # hide","category":"section"},{"location":"thermal_nn_example/#Hybrid-Dynamics-for-Estimation","page":"SciML: Learning a sunshine disturbance model","title":"Hybrid Dynamics for Estimation","text":"Define the dynamics model that uses the neural network for insolation estimation. Since our measurement is linear (we directly observe parts of the state), we can use a LinearMeasurementModel for improved efficiency:\n\n# Linear measurement model - more efficient than nonlinear for direct state measurements\nif data.measure_cloud_cover\n    C = SA[1.0f0 0.0f0; 0.0f0 1.0f0]  # Measure both temperature and cloud cover\nelse\n    C = SA[1.0f0 0.0f0]  # Only measure temperature\nend\nmeasurement_model = LinearMeasurementModel(C, 0, data.measure_cloud_cover ? Diagonal([0.1f0^2, 0.01f0^2]) : Diagonal([0.1f0^2]); ny=data.ny)\n\n# Hybrid dynamics with neural network and cloud cover state\nfunction thermal_dynamics_hybrid(x, u, p, t)\n    T_room, cloud_cover = x\n    P_heater = u[1]\n    \n    # External temperature (known)\n    T_ext = external_temp(t)\n    \n    # Solar insolation from neural network\n    I_base = compute_nn_insolation(t, p)\n    I_solar = I_base * (1 - cloud_cover)\n    \n    # Heat balance\n    dT_dt = (-k_loss * (T_room - T_ext) + Î· * P_heater + A_window * I_solar / 1000) / C_thermal\n    \n    # Cloud cover changes slowly\n    dcloud_dt = 0.0001f0*(0.5f0 - cloud_cover)  # Driven by process noise, assume we know mean cloud cover over time\n    \n    SA[dT_dt, dcloud_dt]\nend\n\n# Discretize hybrid dynamics\nconst discrete_dynamics_hybrid = SeeToDee.ForwardEuler(thermal_dynamics_hybrid, Ts)\n\nfunction clamped_dynamics(x,u,p,t)\n    xp = discrete_dynamics_hybrid(x,u,p,t)\n    SA[xp[1], clamp(xp[2], 0.0f0, 1.0f0)]\nend\n\n# System dimensions for the filter\nnx = 2  # State: [temperature, cloud_cover]\nnu = 1  # Input: heater power\nny = data.ny  # Output dimension depends on whether cloud cover is measured\nnothing # hide","category":"section"},{"location":"thermal_nn_example/#Parameter-Estimation","page":"SciML: Learning a sunshine disturbance model","title":"Parameter Estimation","text":"Now we'll set up the state estimator and the optimization problem using a quasi-Newton method:\n\n# Process and measurement noise for the filter\nR1 = SMatrix{nx, nx}(Diagonal([0.01f0, 0.06f0]))  # Process noise\nif data.measure_cloud_cover\n    R2 = SMatrix{ny, ny}(Diagonal([0.1f0^2, 0.01f0^2]))  # Temperature and cloud cover noise\nelse\n    R2 = SMatrix{ny, ny}(Diagonal([0.1f0^2]))  # Only temperature noise\nend\n\n# Initial state estimate\nx0 = SA[20.0f0, 0.5f0]  # Initial temperature and cloud cover guess\n\n# Cost function for optimization (sum of squared errors)\nfunction cost(Î¸)\n    T = eltype(Î¸)\n    \n    # Create filter with current parameters and linear measurement model\n    kf = UnscentedKalmanFilter(\n        clamped_dynamics, \n        measurement_model,  # Use the linear measurement model\n        R1, \n        SimpleMvNormal(T.(x0), T.(2*R1));\n        ny, nu, Ts,\n    )\n    \n    # Compute sum of squared prediction errors\n    LowLevelParticleFilters.sse(kf, data.u, data.y, Î¸)\nend\n\n# Initial parameters from the neural network initialization\nÎ¸_init = copy(rbf_weights)\n\n# Define optimization options once for reuse\nopt_options = Optim.Options(\n    show_trace = false,\n    store_trace = true,\n    iterations = 200,\n    g_tol = 1e-12,\n)\n\nresult = Optim.optimize(\n    cost,\n    Î¸_init,\n    BFGS(),\n    opt_options;\n    autodiff = :forward,  # Use forward-mode AD for gradients\n)\n\nparams_opt = result.minimizer\n\n@info \"Optimization complete. Converged: $(Optim.converged(result)), Iterations: $(Optim.iterations(result))\"\n@info \"Final cost: $(Optim.minimum(result))\"\n\n# Plot convergence history\n# plot(getfield.(result.trace, :value), #yscale=:log10, \n#      xlabel=\"Iteration\", ylabel=\"Cost (SSE)\",\n#      title=\"Convergence\", lw=2)","category":"section"},{"location":"thermal_nn_example/#Results-Analysis","page":"SciML: Learning a sunshine disturbance model","title":"Results Analysis","text":"Let's analyze the results by running the filter with optimized parameters:\n\n# Run filter with optimized parameters and linear measurement model\nkf_final = UnscentedKalmanFilter(\n    clamped_dynamics,\n    measurement_model,  # Use the linear measurement model\n    R1,\n    SimpleMvNormal(x0, R1);\n    p = params_opt,\n    ny, nu, Ts\n)\n\nsol = forward_trajectory(kf_final, data.u, data.y)\n\n# Extract estimated states\nT_est = [sol.xt[i][1] for i in 1:length(sol.xt)]\ncloud_est = [sol.xt[i][2] for i in 1:length(sol.xt)]\nT_true = [data.x[i][1] for i in 1:length(data.x)]\ncloud_true = [data.x[i][2] for i in 1:length(data.x)]\n\n# Only compute cloud RMSE when sun is above horizon\nsun_up_mask = [true_insolation(data.t[i], 0.0f0) > 0 for i in 1:length(data.t)]\ncloud_error = sqrt(mean(abs2, cloud_true[sun_up_mask] .- cloud_est[sun_up_mask]))\n\n# Plot temperature estimation\np1 = plot(data.t, T_true, label=\"True Temperature\", lw=2, color=:blue)\nplot!(data.t, T_est, label=\"Estimated Temperature\", lw=2, ls=:dash, color=:red)\nplot!(data.t, [y[1] for y in data.y], label=\"Measurements\", alpha=0.3, seriestype=:scatter, ms=1, color=:gray)\nylabel!(\"Temperature (Â°C)\")\ntitle!(\"Temperature Estimation\")\n\n# Plot cloud cover estimation\np2 = plot(data.t, cloud_true, label=\"True Cloud Cover\", lw=2, color=:blue)\nplot!(data.t, cloud_est, label=\"Estimated Cloud Cover\", lw=2, ls=:dash, color=:red)\nylabel!(\"Cloud Cover\")\nxlabel!(\"Time (hours)\")\ntitle!(\"Cloud Cover Estimation\")\n\nplot(p1, p2, layout=(2,1), size=(1200, 800))\n\nAs we can see, it's easy to estimate the internal temperature, after all, we measure this directly. Estimating the cloud cover is significantly harder, notice in particular how the estimation drifts to 0.5 each night when there is no sun. This is expected since it is impossible to observe (in the estimation-theoretical sense) the cloud cover when there is no sun, since when there is no sun there is no effect of the cloud cover on the variable we do measure, the temperature. The fact that it drifts to 0.5 in particular can be explained by the growing estimated covariance during night combined with the clamping of the estimated cloud cover variable between 0 and 1.","category":"section"},{"location":"thermal_nn_example/#Learned-vs-True-Insolation-Pattern","page":"SciML: Learning a sunshine disturbance model","title":"Learned vs True Insolation Pattern","text":"We now have a look at the function we learned for the effect of insolation on the internal temperature, absent of clouds. Since this is a simulated example, we have access to the true function to compare with:\n\n# Generate time points for one day\ntod_test = LinRange(0.0f0, 24.0f0, 100)\n\n# Compute true insolation (without clouds)\nI_true = [true_insolation(t, 0.0f0) for t in tod_test]\n\n# Compute learned insolation\nI_learned = [compute_nn_insolation(t, params_opt) for t in tod_test]\n\n# Plot comparison\nplot(tod_test, I_true, label=\"True Insolation\", lw=3, color=:blue)\nplot!(tod_test, I_learned, label=\"Learned Insolation\", lw=2, ls=:dash, color=:red)\nxlabel!(\"Time of Day (hours)\")\nylabel!(\"Insolation (W/mÂ²)\")\ntitle!(\"Learned Solar Insolation Pattern\")\n\nHopefully, we see that the estimation has captured the general shape of the true insolation pattern, but perhaps not perfectly, since this function is \"hidden\" behind an unknown and noisy estimate of the cloud cover.","category":"section"},{"location":"thermal_nn_example/#Discussion","page":"SciML: Learning a sunshine disturbance model","title":"Discussion","text":"This example demonstrates a classical SciML workflow, the combination of physics-based thermal dynamics with a data-driven model to capture unknown solar patterns. During the day, we were able to roughly estimate the cloud cover despite not being directly measured, by leveraging its effect on the temperature dynamics, but during night our estimator has no fighting chance of doing a good job here, a limitation inherent to the unobservability of the cloud cover in the absence of sunlight.","category":"section"},{"location":"thermal_nn_example/#Diving-deeper:-How-to-handle-constraints","page":"SciML: Learning a sunshine disturbance model","title":"Diving deeper: How to handle constraints","text":"The variable cloud cover is constrained to be between 0 and 1. The Kalman-filtering framework does not handle such a constraint natively, but there are several different more or less heuristic methods available to handle it. Above, we simply clamped the estimated value to be between 0 and 1, simple but effective. Can we do any better? This section compares a number of different methods\n\nThe clamping method\nReformulating the dynamics to use an unconstrained variable that is projected onto the constraint set using a sigmoid function\nProjection implemented as a \"perfect measurement\": We may treat the projection as a fictitious measurement update, imagining that we have obtained a zero-variance measurement that the constrained variable is at the constraint boundary. This is similar to the naive clamping above, but also updates the covariance. We perform this projection using the function LowLevelParticleFilters.project_bound and make use of a callback in order to apply it during the estimation.\nSigma-point rejection, when we use an UnscentedKalmanFilter, we may reject sigma points that fall outside of the feasible region.\n\n# Evaluation function to compare methods\nfunction evaluate_solution(sol, data, params)\n    # Extract estimated states\n    T_est = [sol.xt[i][1] for i in 1:length(sol.xt)]\n    cloud_est = [sol.xt[i][2] for i in 1:length(sol.xt)]\n    T_true = [data.x[i][1] for i in 1:length(data.x)]\n    cloud_true = [data.x[i][2] for i in 1:length(data.x)]\n    \n    # Compute errors\n    temp_rmse = sqrt(mean(abs2, T_true .- T_est))\n    # Only compute cloud RMSE when sun is above horizon (true insolation > 0)\n    sun_up_mask = [true_insolation(data.t[i], 0.0f0) > 0 for i in 1:length(data.t)]\n    cloud_rmse = sqrt(mean(abs2, cloud_true[sun_up_mask] .- cloud_est[sun_up_mask]))\n    \n    # Compute learned insolation vs true\n    tod_test = LinRange(0.0f0, 24.0f0, 100)\n    I_true = [true_insolation(t, 0.0f0) for t in tod_test]\n    I_learned = [compute_nn_insolation(t, params) for t in tod_test]\n    insolation_rmse = sqrt(mean(abs2, I_true .- I_learned))\n    \n    return (;\n        temp_rmse,\n        cloud_rmse,\n        insolation_rmse,\n        T_est,\n        cloud_est,\n        I_learned\n    )\nend\n\n# Evaluate the clamping method (already optimized)\neval_clamping = evaluate_solution(sol, data, params_opt)\n@info \"Clamping method - Temperature RMSE: $(round(eval_clamping.temp_rmse, digits=3))Â°C, Cloud RMSE: $(round(eval_clamping.cloud_rmse, digits=3))\"","category":"section"},{"location":"thermal_nn_example/#Comparison-of-Constraint-Handling-Methods","page":"SciML: Learning a sunshine disturbance model","title":"Comparison of Constraint Handling Methods","text":"The cloud cover state must be constrained to lie in the interval [0, 1]. We have explored several different methods to handle this constraint:\n\nClamping: Directly clamp the cloud cover after each dynamics update\nSigmoid transformation: Transform the state through a sigmoid function  \nProjection: Project the state back to the constraint set after filter updates\nSigma-point rejection: Reject sigma points that violate constraints\nTruncated moment matching: Use truncated normal distribution moments\n\nLet's compare these approaches:","category":"section"},{"location":"thermal_nn_example/#Method-1:-Clamping-(Already-Implemented)","page":"SciML: Learning a sunshine disturbance model","title":"Method 1: Clamping (Already Implemented)","text":"The clamping method was used in the main tutorial above. It simply clips the cloud cover to [0, 1] after each dynamics step:\n\nfunction clamped_dynamics(x,u,p,t)\n    xp = discrete_dynamics_hybrid(x,u,p,t)\n    SA[xp[1], clamp(xp[2], 0.0f0, 1.0f0)]\nend","category":"section"},{"location":"thermal_nn_example/#Method-2:-Sigmoid-Transformation","page":"SciML: Learning a sunshine disturbance model","title":"Method 2: Sigmoid Transformation","text":"# Sigmoid transformation method\nsigmoid(x) = 1 / (1 + exp(-x))\nsigmoid_inv(y) = log(y / (1 - y))\n\nfunction thermal_dynamics_sigmoid(x, u, p, t)\n    T_room, log_cloud_cover = x\n    cloud_cover = sigmoid(log_cloud_cover)\n    P_heater = u[1]\n    \n    # External temperature (known)\n    T_ext = external_temp(t)\n    \n    # Solar insolation from RBF model\n    I_base = compute_nn_insolation(t, p)\n    I_solar = I_base * (1 - cloud_cover)\n    \n    # Heat balance\n    dT_dt = (-k_loss * (T_room - T_ext) + Î· * P_heater + A_window * I_solar / 1000) / C_thermal\n    \n    # Cloud cover changes slowly (in transformed space)\n    dlogcloud_dt = 0.0001f0*(sigmoid_inv(0.5f0) - log_cloud_cover)\n    \n    SA[dT_dt, dlogcloud_dt]\nend\n\n# Discretize sigmoid dynamics\ndiscrete_dynamics_sigmoid = SeeToDee.ForwardEuler(thermal_dynamics_sigmoid, Ts)\n\n# Measurement model for sigmoid method\nmeasurement_sigmoid = if data.measure_cloud_cover\n    (x, u, p, t) -> SA[x[1], sigmoid(x[2])]\nelse\n    (x, u, p, t) -> SA[x[1]]\nend\n\n# Optimize sigmoid method\nfunction cost_sigmoid(Î¸)\n    T = eltype(Î¸)\n    x0_sigmoid = SA[20.0f0, sigmoid_inv(0.5f0)]\n    \n    kf = UnscentedKalmanFilter(\n        discrete_dynamics_sigmoid,\n        measurement_sigmoid,\n        R1,\n        R2,\n        SimpleMvNormal(T.(x0_sigmoid), T.(2*R1));\n        ny, nu, Ts,\n    )\n    \n    LowLevelParticleFilters.sse(kf, data.u, data.y, Î¸)\nend\n\n# Run optimization for sigmoid method\n@info \"Optimizing sigmoid method...\"\nresult_sigmoid = Optim.optimize(\n    cost_sigmoid,\n    Î¸_init,\n    BFGS(),\n    opt_options;\n    autodiff = :forward,\n)\n\nparams_sigmoid = result_sigmoid.minimizer\n\n# Evaluate sigmoid method\nx0_sigmoid = SA[20.0f0, sigmoid_inv(0.5f0)]\nkf_sigmoid = UnscentedKalmanFilter(\n    discrete_dynamics_sigmoid,\n    measurement_sigmoid,\n    R1,\n    R2,\n    SimpleMvNormal(x0_sigmoid, R1);\n    p = params_sigmoid,\n    ny, nu, Ts\n)\n\nsol_sigmoid = forward_trajectory(kf_sigmoid, data.u, data.y)\n\n# Transform cloud estimates back from log space\nsol_sigmoid_transformed = deepcopy(sol_sigmoid)\nfor i in 1:length(sol_sigmoid_transformed.xt)\n    x = sol_sigmoid_transformed.xt[i]\n    sol_sigmoid_transformed.xt[i] = SA[x[1], sigmoid(x[2])]\nend\n\neval_sigmoid = evaluate_solution(sol_sigmoid_transformed, data, params_sigmoid)\n@info \"Sigmoid method - Temperature RMSE: $(round(eval_sigmoid.temp_rmse, digits=3))Â°C, Cloud RMSE: $(round(eval_sigmoid.cloud_rmse, digits=3))\"","category":"section"},{"location":"thermal_nn_example/#Method-3:-Projection","page":"SciML: Learning a sunshine disturbance model","title":"Method 3: Projection","text":"# Projection method - uses standard dynamics but projects after updates\n\nfunction post_update_cb(kf, u, y, p, ll, e)\n    if !(0 <= kf.x[2] <= 1)\n        xn, Rn = LowLevelParticleFilters.project_bound(kf.x, kf.R, 2; lower=0, upper=1, tol=1e-9)\n        kf.x = xn\n        kf.R = Rn\n    end\n    nothing\nend\n\n# Use original unclamped dynamics for projection method\ndiscrete_dynamics_unclamped = discrete_dynamics_hybrid\n\n# Optimize projection method\nfunction cost_projection(Î¸)\n    T = eltype(Î¸)\n    \n    kf = UnscentedKalmanFilter(\n        discrete_dynamics_unclamped,\n        measurement_model,  # Use the linear measurement model\n        R1,\n        SimpleMvNormal(T.(x0), T.(2*R1));\n        ny, nu, Ts,\n    )\n    \n    LowLevelParticleFilters.sse(kf, data.u, data.y, Î¸; post_update_cb)\nend\n\n# Run optimization for projection method\n@info \"Optimizing projection method...\"\nresult_projection = Optim.optimize(\n    cost_projection,\n    Î¸_init,\n    BFGS(),\n    opt_options;\n    autodiff = :forward,\n)\n\nparams_projection = result_projection.minimizer\n\n# Evaluate projection method\nkf_projection = UnscentedKalmanFilter(\n    discrete_dynamics_unclamped,\n    measurement_model,  # Use the linear measurement model\n    R1,\n    SimpleMvNormal(x0, R1);\n    p = params_projection,\n    ny, nu, Ts\n)\n\npost_predict_cb(kf, p, args...) = post_update_cb(kf, 0, 0, p, 0, 0)\nsol_projection = forward_trajectory(kf_projection, data.u, data.y; post_predict_cb, post_correct_cb=post_predict_cb)\n\neval_projection = evaluate_solution(sol_projection, data, params_projection)\n@info \"Projection method - Temperature RMSE: $(round(eval_projection.temp_rmse, digits=3))Â°C, Cloud RMSE: $(round(eval_projection.cloud_rmse, digits=3))\"","category":"section"},{"location":"thermal_nn_example/#Method-4:-Sigma-point-rejection","page":"SciML: Learning a sunshine disturbance model","title":"Method 4: Sigma-point rejection","text":"The UKF provides a mechanism to reject sigma points that violate constraints. When a sigma point falls outside [0,1] for cloud cover, we can reject it and replace it with the mean point:\n\n# Sigma-point rejection method\nfunction reject_sigma_point(x)\n    # Reject if cloud cover is outside [0, 1]\n    return !(0.0f0 <= x[2] <= 1.0f0)\nend\n\n# Use unclamped dynamics for rejection method\ndiscrete_dynamics_rejection = discrete_dynamics_hybrid\n\n# Optimize with sigma-point rejection\nfunction cost_rejection(Î¸)\n    T = eltype(Î¸)\n    \n    kf = UnscentedKalmanFilter(\n        discrete_dynamics_rejection,\n        measurement_model,  # Use the linear measurement model\n        R1,\n        SimpleMvNormal(T.(x0), T.(2*R1));\n        ny, nu, Ts,\n        reject = reject_sigma_point  # Add rejection function\n    )\n    \n    LowLevelParticleFilters.sse(kf, data.u, data.y, Î¸)\nend\n\n# Run optimization for rejection method\n@info \"Optimizing sigma-point rejection method...\"\nresult_rejection = Optim.optimize(\n    cost_rejection,\n    Î¸_init,\n    BFGS(),\n    opt_options;\n    autodiff = :forward,\n)\n\nparams_rejection = result_rejection.minimizer\n\n# Evaluate rejection method\nkf_rejection = UnscentedKalmanFilter(\n    discrete_dynamics_rejection,\n    measurement_model,  # Use the linear measurement model\n    R1,\n    SimpleMvNormal(x0, R1);\n    p = params_rejection,\n    ny, nu, Ts,\n    reject = reject_sigma_point\n)\n\nsol_rejection = forward_trajectory(kf_rejection, data.u, data.y)\n\neval_rejection = evaluate_solution(sol_rejection, data, params_rejection)\n@info \"Rejection method - Temperature RMSE: $(round(eval_rejection.temp_rmse, digits=3))Â°C, Cloud RMSE: $(round(eval_rejection.cloud_rmse, digits=3))\"","category":"section"},{"location":"thermal_nn_example/#Method-5:-Truncated-Moment-Matching","page":"SciML: Learning a sunshine disturbance model","title":"Method 5: Truncated Moment Matching","text":"This method uses truncated normal distribution moments to handle the constraint, providing a statistically principled approach:\n\n# Truncated moment matching method - uses standard dynamics but applies moment matching after updates\nfunction post_update_tmm(kf, u, y, p, ll, e)\n    if !(0 <= kf.x[2] <= 1)\n        xn, Rn = LowLevelParticleFilters.truncated_moment_match(kf.x, kf.R, 2; lower=0, upper=1, tol=1e-9)\n        kf.x = xn\n        kf.R = Rn\n    end\n    nothing\nend\n\n# Use original unclamped dynamics for truncated moment matching\ndiscrete_dynamics_tmm = discrete_dynamics_hybrid\n\n# Optimize truncated moment matching method\nfunction cost_tmm(Î¸)\n    T = eltype(Î¸)\n    \n    kf = UnscentedKalmanFilter(\n        discrete_dynamics_tmm,\n        measurement_model,  # Use the linear measurement model\n        R1,\n        SimpleMvNormal(T.(x0), T.(2*R1));\n        ny, nu, Ts,\n    )\n    \n    LowLevelParticleFilters.sse(kf, data.u, data.y, Î¸; post_update_cb=post_update_tmm)\nend\n\n# Run optimization for truncated moment matching\n@info \"Optimizing truncated moment matching method...\"\nresult_tmm = Optim.optimize(\n    cost_tmm,\n    Î¸_init,\n    BFGS(),\n    opt_options;\n    autodiff = :forward,\n)\n\nparams_tmm = result_tmm.minimizer\n\n# Evaluate truncated moment matching method\nkf_tmm = UnscentedKalmanFilter(\n    discrete_dynamics_tmm,\n    measurement_model,  # Use the linear measurement model\n    R1,\n    SimpleMvNormal(x0, R1);\n    p = params_tmm,\n    ny, nu, Ts\n)\n\npost_predict_tmm(kf, p, args...) = post_update_tmm(kf, 0, 0, p, 0, 0)\nsol_tmm = forward_trajectory(kf_tmm, data.u, data.y; post_predict_cb=post_predict_tmm, post_correct_cb=post_predict_tmm)\n\neval_tmm = evaluate_solution(sol_tmm, data, params_tmm)\n@info \"Truncated moment matching - Temperature RMSE: $(round(eval_tmm.temp_rmse, digits=3))Â°C, Cloud RMSE: $(round(eval_tmm.cloud_rmse, digits=3))\"","category":"section"},{"location":"thermal_nn_example/#Comparison-Results","page":"SciML: Learning a sunshine disturbance model","title":"Comparison Results","text":"# Plot comparison of all methods\np1 = plot(data.t, [data.x[i][2] for i in 1:length(data.x)], \n    label=\"True Cloud Cover\", lw=3, color=:black, alpha=0.7)\nplot!(data.t, eval_clamping.cloud_est, label=\"Clamping\", lw=2, color=:blue)\nplot!(data.t, eval_sigmoid.cloud_est, label=\"Sigmoid\", lw=2, color=:red, ls=:dash)\nplot!(data.t, eval_projection.cloud_est, label=\"Projection\", lw=2, color=:green, ls=:dot)\nplot!(data.t, eval_rejection.cloud_est, label=\"Rejection\", lw=2, color=:purple, ls=:dashdot)\nplot!(data.t, eval_tmm.cloud_est, label=\"Truncated MM\", lw=2, color=:orange, ls=:dashdotdot)\nylabel!(\"Cloud Cover\")\nxlabel!(\"Time (hours)\")\ntitle!(\"Cloud Cover Estimation - Method Comparison\")\n\n# Compare learned insolation patterns\ntod_test = LinRange(0.0f0, 24.0f0, 100)\nI_true_plot = [true_insolation(t, 0.0f0) for t in tod_test]\n\np2 = plot(tod_test, I_true_plot, label=\"True\", lw=3, color=:black, alpha=0.7)\nplot!(tod_test, eval_clamping.I_learned, label=\"Clamping\", lw=2, color=:blue)\nplot!(tod_test, eval_sigmoid.I_learned, label=\"Sigmoid\", lw=2, color=:red, ls=:dash)\nplot!(tod_test, eval_projection.I_learned, label=\"Projection\", lw=2, color=:green, ls=:dot)\nplot!(tod_test, eval_rejection.I_learned, label=\"Rejection\", lw=2, color=:purple, ls=:dashdot)\nplot!(tod_test, eval_tmm.I_learned, label=\"Truncated MM\", lw=2, color=:orange, ls=:dashdotdot)\nxlabel!(\"Time of Day (hours)\")\nylabel!(\"Insolation (W/mÂ²)\")\ntitle!(\"Learned Insolation Patterns\")\n\nplot(p1, p2, layout=(2,1), size=(1200, 800))","category":"section"},{"location":"thermal_nn_example/#Summary-table","page":"SciML: Learning a sunshine disturbance model","title":"Summary table","text":"println(\"\\n=== Method Comparison Summary ===\")\nprintln(\"Method        | Temp RMSE | Cloud RMSE | Insolation RMSE\")\nprintln(\"------------- | --------- | ---------- | ---------------\")\nprintln(\"Clamping      | $(round(eval_clamping.temp_rmse, digits=3))     | $(round(eval_clamping.cloud_rmse, digits=3))      | $(round(eval_clamping.insolation_rmse, digits=1))\")\nprintln(\"Sigmoid       | $(round(eval_sigmoid.temp_rmse, digits=3))     | $(round(eval_sigmoid.cloud_rmse, digits=3))      | $(round(eval_sigmoid.insolation_rmse, digits=1))\")\nprintln(\"Projection    | $(round(eval_projection.temp_rmse, digits=3))     | $(round(eval_projection.cloud_rmse, digits=3))      | $(round(eval_projection.insolation_rmse, digits=1))\")\nprintln(\"Rejection     | $(round(eval_rejection.temp_rmse, digits=3))     | $(round(eval_rejection.cloud_rmse, digits=3))      | $(round(eval_rejection.insolation_rmse, digits=1))\")\nprintln(\"Truncated MM  | $(round(eval_tmm.temp_rmse, digits=3))     | $(round(eval_tmm.cloud_rmse, digits=3))      | $(round(eval_tmm.insolation_rmse, digits=1))\")","category":"section"},{"location":"thermal_nn_example/#Discussion-of-Constraint-Methods","page":"SciML: Learning a sunshine disturbance model","title":"Discussion of Constraint Methods","text":"Each method has different trade-offs:\n\nClamping: Simple and computationally efficient, but creates discontinuities in the dynamics that some filters may not like.\nSigmoid: Smooth transformation that naturally keeps variables bounded, but changes the noise characteristics and may introduce \"stickyness\" at the boundaries.\nProjection: Similar to clamping, but takes correlation between variables into account, updating also non-clamped variables and covariance.\nSigma-point Rejection: Simple method that often introduces large bias.\nTruncated Moment Matching: Provides a statistically principled approach by computing the exact moments of the truncated normal distribution. May be slightly computationally expensive.\n\nThe results show that the sigmoidal transformation and the truncated moment matching appear to perform best on this particular problem. We didn't use all that much data, so there is bound to be some randomness in these findings. I did try with 10x more data and the findings were quite similar.","category":"section"},{"location":"dae/#State-estimation-for-high-index-DAEs","page":"State estimation for DAE systems","title":"State estimation for high-index DAEs","text":"This tutorial is hosted as a notebook.","category":"section"},{"location":"ut/#Unscented-transform","page":"Unscented transform","title":"Unscented transform","text":"In this section, we demonstrate how the unscented transform, used in the UnscentedKalmanFilter, propagates a normal distribution through a nonlinear function. ","category":"section"},{"location":"ut/#Covariance-propagation-through-nonlinear-functions","page":"Unscented transform","title":"Covariance propagation through nonlinear functions","text":"The propagation of a Gaussian distribution through an affine (or linear) function f(x) = Ax+b is trivial, the distribution N(Î¼ Î£) is transformed into N(AÎ¼ + b AÎ£A^T), i.e., it remains Gaussian. This fact is what makes the standard KalmanFilter so computationally efficient. However, when the function is nonlinear, the transformation is not as straightforward and the posterior is generally not Gaussian. The unscented transform (UT) is a method to approximate the transformation of a Gaussian distribution through a nonlinear function. The UT is based on the idea of propagating a set of sigma points through the function and then computing the mean and covariance of the resulting distribution. Below, we demonstrate how a normal distribution is transformed through a number of nonlinear functions.\n\nFor comparison, we also show how the ExtendedKalmanFilter and ParticleFilter propagate the covariance. EKF uses linearization while particle filters propagate a large number of samples. We load the ForwardDiff package to compute the Jacobian of the function.\n\nusing DisplayAs # hide\nusing LowLevelParticleFilters, Plots\nusing LowLevelParticleFilters: sigmapoints\nusing ForwardDiff, Distributions\nPlots.default(fillalpha=0.3) # This makes the covariance ellipse more transparent\nkwargs = (; markersize=4, markeralpha=0.7, markerstrokewidth=0)\n\nfunction ekf_propagate_plot(f, Î¼, Î£; kwargs...)\n    x = Î¼\n    A = ForwardDiff.jacobian(f, x)\n    Î¼ = f(x)\n    Î£ = A * Î£ * A'\n    covplot!(Î¼, Î£; kwargs...)\nend\n\nfunction sample_propagate_plot(f, Î¼, Î£; kwargs...)\n    xpart = rand(MvNormal(Î¼, Î£), 10000)\n    ypart = f.(eachcol(xpart))\n    scatter!(first.(ypart), last.(ypart); markerstrokealpha=0, markerstrokewidth=0, markeralpha=0.15, markersize=1, kwargs..., lab=\"\")\n    ym = mean(ypart)\n    yS = cov(ypart)\n    covplot!(ym, yS; kwargs...)\n    scatter!([ym[1]], [ym[2]]; markersize=4, markershape=:x, kwargs..., lab=\"\")\nend\n\nÎ¼ = [1.0, 2.0]\nÎ£ = [1.0 0.5; 0.5 1.0]\nx = sigmapoints(Î¼, Î£, TrivialParams())\nn = length(x)\nf1(x) = [x[1]^2+1, sin(x[2])]\ny = f1.(x)\nunscentedplot(x; lab=\"Input\", c=:blue, fillalpha=0.1, kwargs...)\nunscentedplot!(y; lab=\"Output UKF\", c=:red, kwargs...)\nekf_propagate_plot(f1, Î¼, Î£; lab=\"Output EKF\", c=:orange)\nsample_propagate_plot(f1, Î¼, Î£; lab=\"Output particles\", c=:green)\n# Plot lines from each input point to each output point\nplot!([first.(x)'; first.(y)'; fill(Inf, 1, n)][:], [last.(x)'; last.(y)'; fill(Inf, 1, n)][:], c=:black, alpha=0.5, primary=false)\nDisplayAs.PNG(Plots.current()) # hide\n\nFor this first function, f_1(x) = x_1^2+1 sin(x_2), the UT and linearization-based propagation produce somewhat similar results, but the posterior distribution of the UT is much closer to the particle distribution than the EKF.\n\nf2(x) = [x[1]*x[2], x[1]+x[2]]\ny = f2.(x)\nunscentedplot(x; lab=\"Input\", c=:blue, fillalpha=0.1, kwargs...)\nunscentedplot!(y; lab=\"Output UKF\", c=:red, kwargs...)\nekf_propagate_plot(f2, Î¼, Î£; lab=\"Output EKF\", c=:orange)\nsample_propagate_plot(f2, Î¼, Î£; lab=\"Output particles\", c=:green)\nplot!([first.(x)'; first.(y)'; fill(Inf, 1, n)][:], [last.(x)'; last.(y)'; fill(Inf, 1, n)][:], c=:black, alpha=0.5, primary=false, xlims=(-5, 12))\nDisplayAs.PNG(Plots.current()) # hide\n\nFor the second function, f_2(x) = x_1 x_2 x_1+x_2, the posterior distribution is highly non-Gaussian. Both the UT and EKF style propagation do reasonable jobs capturing the posterior mean, but the UT does a better, although far from perfect, job at capturing the posterior covariance.\n\nf3((x,y)) = [sqrt((1 - x)^2 + (0.1 - y)^2), atan(0.9 - y, 1.0 - x)] # Robot localization measurement model\ny = f3.(x)\nunscentedplot(x; lab=\"Input\", c=:blue, fillalpha=0.1, kwargs...)\nunscentedplot!(y; lab=\"Output UKF\", c=:red, kwargs...)\nekf_propagate_plot(f3, Î¼, Î£; lab=\"Output EKF\", c=:orange)\nsample_propagate_plot(f3, Î¼, Î£; lab=\"Output particles\", c=:green)\nplot!([first.(x)'; first.(y)'; fill(Inf, 1, n)][:], [last.(x)'; last.(y)'; fill(Inf, 1, n)][:], c=:black, alpha=0.5, primary=false)\nDisplayAs.PNG(Plots.current()) # hide\n\nFor the function f_3(x) = sqrt(1 - x)^2 + (01 - y)^2 arctan(09 - y 10 - x), the posterior distribution is once again highly non-Gaussian. The EKF misses to place any significant output probability mass in the region around the input, which the UT does by placing one sigma point in this region. When the particle distribution is approximated by a Gaussian, neither the UT or EKF does very well approximating this Gaussian.","category":"section"},{"location":"ut/#Tuning-parameters","page":"Unscented transform","title":"Tuning parameters","text":"The unscented transform that underpins the UnscentedKalmanFilter may be tuned to adjust the spread of the points. By default, TrivialParams are used, but one may also opt for the WikiParams or MerweParams which are more commonly used in the literature.\n\nThe code snippets below demonstrate how to create different sets of parameters and visualizes the sigma points generated by each set of parameters for a trivial normal 2D distribution, as well has how the points propagate through a simple function.\n\nWe start by visualizing the sigma points generated by the different parameters sets using their default parameters.\n\nÎ¼ = [0.0, 0.0]\nÎ£ = [1.0 0.0; 0.0 1.0]\nwpars = WikiParams(Î± = 1.0, Î² = 0.0, Îº = 1)\nwxs = sigmapoints(Î¼, Î£, wpars)\n\nmpars = MerweParams(Î± = 1.0, Î² = 2.0, Îº = 0.0)\nmxs = sigmapoints(Î¼, Î£, mpars)\n\ntpars = TrivialParams()\ntxs = sigmapoints(Î¼, Î£, tpars)\n\nunscentedplot(wxs, wpars; lab=\"Wiki\", c=:green, kwargs...)\nunscentedplot!(mxs, mpars; lab=\"Merwe\", c=:red, kwargs...)\nunscentedplot!(txs, tpars; lab=\"Trivial\", c=:blue, kwargs...)\n\nIn this plot, we don't see the Merwe points because they are all behind the Trivial points. The Wiki points are less spread out. They all represent exactly the same distribution though, all their covariance ellipses overlap. Different sets of points can represent the same probability distribution by means of different weights that are assigned to each point.\n\nBelow, we demonstrate how the points propagate through a simple function. We use the function f(x) = max(0 x1) x2 which is a simple function that forces the first state component to be positive.\n\nf(x) = [max(zero(x[1]), x[1]), x[2]]\nwxs2 = f.(wxs) # Propagate the points through the function\nmxs2 = f.(mxs)\ntxs2 = f.(txs)\nunscentedplot(wxs2, wpars; lab=\"Wiki\", c=:green ,kwargs...)\nunscentedplot!(mxs2, mpars; lab=\"Merwe\", c=:red ,kwargs...)\nunscentedplot!(txs2, tpars; lab=\"Trivial\", c=:blue ,kwargs...)\n\nWe now see that the Merwe points resulted in a large covariance of the output. We see that the posterior mean is skewed positively due to the clamping of f, but the mean is skewed less for the trivial parameters than the Wiki parameters, with Merwe somewhere inbetween.\n\nBy tweaking the parameters, we can obtain different behavior, below we show the spread of the points for different values of Î± Î² Îº\n\nwpars = WikiParams(Î± = 1, Î² = -3.0, Îº = 10)\nwxs = sigmapoints(Î¼, Î£, wpars)\n\nmpars = MerweParams(Î± = 1, Î² = -3.0, Îº = 10)\nmxs = sigmapoints(Î¼, Î£, mpars)\n\nunscentedplot(wxs, wpars; lab=\"Wiki\", c=:green, kwargs...)\nunscentedplot!(mxs, mpars; lab=\"Merwe\", c=:red, kwargs...)\nunscentedplot!(txs, tpars; lab=\"Trivial\", c=:blue, kwargs...)\n\nThis time, the Wiki and Merwe parameters are much more spread out than the Trivial parameters. When we propagate these points through the function:\n\nwxs2 = f.(wxs)\nmxs2 = f.(mxs)\ntxs2 = f.(txs)\nunscentedplot(wxs2, wpars; lab=\"Wiki\", c=:green, kwargs...)\nunscentedplot!(mxs2, mpars; lab=\"Merwe\", c=:red, kwargs...)\nunscentedplot!(txs2, tpars; lab=\"Trivial\", c=:blue, kwargs...)\n\nwe see that the Wiki and Merwe parameters produced a posterior mean close to zero, while the Trivial parameters are more positively skewed.","category":"section"},{"location":"measurement_models/#measurement_models","page":"Multiple measurement models","title":"Measurement models","text":"The Kalman-type filters\n\nKalmanFilter\nExtendedKalmanFilter\nUnscentedKalmanFilter\n\neach come with their own built-in measurement model, e.g., the standard KalmanFilter uses the linear measurement model y = Cx + Du + e, while the ExtendedKalmanFilter and UnscentedKalmanFilter use the nonlinear measurement model y = h(xupt) + e or y = h(xupte). For covariance propagation, the ExtendedKalmanFilter uses linearization to approximate the nonlinear measurement model, while the UnscentedKalmanFilter uses the unscented transform.\n\nIt is sometimes useful to mix and match dynamics and measurement models. For example, using the unscented transform from the UKF for the dynamics update (predict!), but the linear measurement model from the standard KalmanFilter for the measurement update (correct!) if the measurement model is linear.\n\nThis is possible by constructing a filter with an explicitly created measurement model. The available measurement models are\n\nLinearMeasurementModel performs linear propagation of covariance (as is done in KalmanFilter).\nEKFMeasurementModel uses linearization to propagate covariance (as is done in ExtendedKalmanFilter).\nIEKFMeasurementModel uses iterated linearization to propagate covariance (as is done in IteratedExtendedKalmanFilter).\nUKFMeasurementModel uses the unscented transform to propagate covariance (as is done in UnscentedKalmanFilter).\nCompositeMeasurementModel combines multiple measurement models.","category":"section"},{"location":"measurement_models/#Constructing-a-filter-with-a-custom-measurement-model","page":"Multiple measurement models","title":"Constructing a filter with a custom measurement model","text":"Constructing a Kalman-type filter automatically creates a measurement model of the corresponding type, given the functions/matrices passed to the filter constructor. To construct a filter with a non-standard measurement model, e.g., and UKF with a KF measurement model, manually create the desired measurement model and pass it as the second argument to the constructor. For example, to construct an UKF with a linear measurement model, we do\n\nusing LowLevelParticleFilters, LinearAlgebra\nnx = 100    # Dimension of state\nnu = 2      # Dimension of input\nny = 90     # Dimension of measurements\n\n# Define linear state-space system\nconst __A = 0.1*randn(nx, nx)\nconst __B = randn(nx, nu)\nconst __C = randn(ny,nx)\nfunction dynamics_ip(dx,x,u,p,t)\n    # __A*x .+ __B*u\n    mul!(dx, __A, x)\n    mul!(dx, __B, u, 1.0, 1.0)\n    nothing\nend\nfunction measurement_ip(y,x,u,p,t)\n    # __C*x\n    mul!(y, __C, x)\n    nothing\nend\n\nR1 = I(nx)\nR2 = I(ny)\n\nmm_kf = LinearMeasurementModel(__C, 0, R2; nx, ny)\nukf = UnscentedKalmanFilter(dynamics_ip, mm_kf, R1; ny, nu)\n\nWhen we create the filter with the custom measurement model, we do not pass the arguments that are associated with the measurement model to the filter constructor, i.e., we do not pass any measurement function, and not the measurement covariance matrix R_2.","category":"section"},{"location":"measurement_models/#Sensor-fusion:-Using-several-different-measurement-models","page":"Multiple measurement models","title":"Sensor fusion: Using several different measurement models","text":"Above we constructed a filter with a custom measurement model, we can also pass a custom measurement model when we call correct!. This may be useful when, e.g., performing sensor fusion with sensors operating at different sample rates, or when parts of the measurement model are linear, and other parts are nonlinear.\n\nThe following example instantiates three different filters and three different measurement models. Each filter is updated with each measurement model, demonstrating that any combination of filter and measurement model can be used together.\n\nusing LowLevelParticleFilters, LinearAlgebra\nnx = 10    # Dimension of state\nnu = 2     # Dimension of input\nny = 9     # Dimension of measurements\n\n# Define linear state-space system\nconst __A = 0.1*randn(nx, nx)\nconst __B = randn(nx, nu)\nconst __C = randn(ny,nx)\nfunction dynamics_ip(dx,x,u,p,t)\n    # __A*x .+ __B*u\n    mul!(dx, __A, x)\n    mul!(dx, __B, u, 1.0, 1.0)\n    nothing\nend\nfunction measurement_ip(y,x,u,p,t)\n    # __C*x\n    mul!(y, __C, x)\n    nothing\nend\n\nR1 = I(nx) # Covariance matrices\nR2 = I(ny)\n\n# Construct three different filters\nkf  = KalmanFilter(__A, __B, __C, 0, R1, R2)\nukf = UnscentedKalmanFilter(dynamics_ip, measurement_ip, R1, R2; ny, nu)\nekf = ExtendedKalmanFilter(dynamics_ip, measurement_ip, R1, R2; nu)\n\n# Simulate some data\nT    = 200 # Number of time steps\nU = [randn(nu) for _ in 1:T]\nx,u,y = LowLevelParticleFilters.simulate(kf, U) # Simulate trajectory using the model in the filter\n\n# Construct three different measurement models\nmm_kf = LinearMeasurementModel(__C, 0, R2; nx, ny)\nmm_ekf = EKFMeasurementModel{Float64, true}(measurement_ip, R2; nx, ny)\nmm_ukf = UKFMeasurementModel{Float64, true, false}(measurement_ip, R2; nx, ny)\n\n\nmms = [mm_kf, mm_ekf, mm_ukf]\nfilters = [kf, ekf, ukf]\n\nfor mm in mms, filter in filters\n    @info \"Updating $(nameof(typeof(filter))) with measurement model $(nameof(typeof(mm)))\"\n    correct!(filter, mm, u[1], y[1]) # Pass the measurement model as the second argument to the correct! function if not using the measurement model built into the filter\nend\nnothing # hide\n\nSince the dynamics in this particular example is in fact linear, we should get identical results for all three filters.\n\nusing Test\n@test kf.x â‰ˆ ekf.x â‰ˆ ukf.x\n@test kf.R â‰ˆ ekf.R â‰ˆ ukf.R","category":"section"},{"location":"measurement_models/#Video-tutorial","page":"Multiple measurement models","title":"Video tutorial","text":"A video demonstrating the use of multiple measurement models in a sensor-fusion context is available on YouTube:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/BLsJrW5XXcg?si=bkob76-uJj27-S80\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"section"},{"location":"api/#Exported-functions-and-types","page":"API","title":"Exported functions and types","text":"","category":"section"},{"location":"api/#Index","page":"API","title":"Index","text":"","category":"section"},{"location":"api/#LowLevelParticleFilters.AdvancedParticleFilter-Tuple{Integer, Function, Function, Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.AdvancedParticleFilter","text":"AdvancedParticleFilter(N::Integer, dynamics::Function, measurement::Function, measurement_likelihood, dynamics_density, initial_density; p = NullParameters(), threads = false, kwargs...)\n\nThis type represents a standard particle filter but affords extra flexibility compared to the ParticleFilter type, e.g., non-additive noise in the dynamics and measurement functions.\n\nSee the docs for more information: https://baggepinnen.github.io/LowLevelParticleFilters.jl/stable/#AdvancedParticleFilter-1\n\nArguments:\n\nN: Number of particles\ndynamics: A discrete-time dynamics function (x, u, p, t, noise=false) -> xâº. It's important that the noise argument defaults to false.\nmeasurement: A measurement function (x, u, p, t, noise=false) -> y. It's important that the noise argument defaults to false.\nmeasurement_likelihood: A function (x, u, y, p, t)->logl to evaluate the log-likelihood of a measurement.\ndynamics_density: This field is not used by the advanced filter and can be set to nothing.\ninitial_density: The distribution of the initial state.\nthreads: use threads to propagate particles in parallel. Only activate this if your dynamics is thread-safe. SeeToDee.SimpleColloc is not thread-safe by default due to the use of internal caches, but SeeToDee.Rk4 is.\n\nExtended help\n\nMultiple measurement models\n\nThe measurement_likelihood function is used to evaluate the likelihood of a measurement. If you have multiple sensors and want to perform individual correct! steps for each, call correct!(..., g = custom_likelihood_function).\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.AuxiliaryParticleFilter-Tuple","page":"API","title":"LowLevelParticleFilters.AuxiliaryParticleFilter","text":"AuxiliaryParticleFilter(args...; kwargs...)\n\nTakes exactly the same arguments as ParticleFilter, or an instance of ParticleFilter.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.CompositeMeasurementModel-Tuple{Any, Vararg{Any}}","page":"API","title":"LowLevelParticleFilters.CompositeMeasurementModel","text":"CompositeMeasurementModel(model1, model2, ...)\n\nA composite measurement model that combines multiple measurement models. This model acts as all component models concatenated. The tuple returned from correct! will be\n\nll: The sum of the log-likelihood of all component models\ne: The concatenated innovation vector\nS: A vector of the innovation covariance matrices of the component models\nSáµª: A vector of the Cholesky factorizations of the innovation covariance matrices of the component models\nK: A vector of the Kalman gains of the component models\n\nIf all sensors operate on at the same rate, and all measurement models are of the same type, it's more efficient to use a single measurement model with a vector-valued measurement function.\n\nFields:\n\nmodels: A tuple of measurement models\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.EKFMeasurementModel-Union{Tuple{IPM}, NTuple{4, Any}, NTuple{5, Any}, NTuple{6, Any}} where IPM","page":"API","title":"LowLevelParticleFilters.EKFMeasurementModel","text":"EKFMeasurementModel{IPM}(measurement, R2, ny, Cjac, R12 = nothing, cache = nothing)\n\nA measurement model for the Extended Kalman Filter.\n\nArguments:\n\nIPM: A boolean indicating if the measurement function is inplace\nmeasurement: The measurement function y = h(x, u, p, t)\nR2: The measurement noise covariance matrix\nny: The number of measurement variables\nCjac: The Jacobian of the measurement function Cjac(x, u, p, t). If none is provided, ForwardDiff will be used.\nR12: Cross-covariance between dynamics noise at step k and measurement noise at step k+1. See Simon, D.: \"Optimal state estimation: Kalman, H Infinity, and nonlinear approaches\" sec. 7.1\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.EKFMeasurementModel-Union{Tuple{M}, Tuple{IPM}, Tuple{T}, Tuple{M, Any}} where {T, IPM, M}","page":"API","title":"LowLevelParticleFilters.EKFMeasurementModel","text":"EKFMeasurementModel{T,IPM}(measurement::M, R2; nx, ny, Cjac = nothing, R12 = nothing)\n\nT is the element type used for arrays\nIPM is a boolean indicating if the measurement function is inplace\nR12 is the cross-covariance between dynamics noise and measurement noise\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.EnsembleKalmanFilter","page":"API","title":"LowLevelParticleFilters.EnsembleKalmanFilter","text":"EnsembleKalmanFilter(dynamics, measurement, R1, R2, d0, N; kwargs...)\n\nAn Ensemble Kalman Filter (EnKF) that uses an ensemble of states instead of explicitly tracking the covariance matrix. This makes it suitable for high-dimensional systems where covariance matrices become intractable.\n\nThis implementation uses the Stochastic EnKF formulation with perturbed observations.\n\nArguments\n\ndynamics: Dynamics function f(x, u, p, t) -> xâº\nmeasurement: Measurement function h(x, u, p, t) -> y\nR1: Process noise covariance matrix\nR2: Measurement noise covariance matrix\nd0: Initial state distribution (must support rand and have fields Î¼ and Î£)\nN::Int: Number of ensemble members\n\nKeyword Arguments\n\nnu::Int: Number of inputs (required)\nny::Int = size(R2, 1): Number of outputs\np = NullParameters(): Parameters passed to dynamics and measurement functions\nTs = 1.0: Sample time\ninflation = 1.0: Covariance inflation factor (â‰¥1.0). Values > 1.0 inflate the ensemble spread after each prediction step to prevent filter divergence.\nrng = Random.Xoshiro(): Random number generator\nnames = default_names(...): Signal names for plotting\n\nAlgorithm\n\nPredict Step\n\nFor each ensemble member i = 1:N:\n\nx_i^- = f(x_i u p t) + w_i quad textwhere  w_i sim mathcalN(0 R_1)\n\nCorrect Step (Stochastic EnKF)\n\nEnsemble mean: barx = frac1N sum_i x_i\nAnomaly matrix: X = x_1 - barx ldots x_N - barx\nPredicted measurements: y_i = h(x_i u p t), bary = frac1N sum_i y_i\nMeasurement anomalies: Y = y_1 - bary ldots y_N - bary\nKalman gain: K = X(Y)^T (Y(Y)^T  (N-1) + R_2)^-1\nPerturbed observations: y_i^pert = y + varepsilon_i where varepsilon_i sim mathcalN(0 R_2)\nUpdate: x_i^+ = x_i^- + K(y_i^pert - y_i)\n\nExample\n\nusing LowLevelParticleFilters, LinearAlgebra, Distributions\n\nnx, nu, ny = 2, 1, 1\nN = 100  # Number of ensemble members\n\n# Linear system\nA = [0.9 0.1; 0.0 0.95]\nB = [0.0; 1.0;;]\nC = [1.0 0.0]\n\ndynamics(x, u, p, t) = A*x + B*u\nmeasurement(x, u, p, t) = C*x\n\nR1 = 0.01*I(nx)\nR2 = 0.1*I(ny)\nd0 = MvNormal(zeros(nx), I(nx))\n\nenkf = EnsembleKalmanFilter(dynamics, measurement, R1, R2, d0, N; nu, ny)\n\n# Use like other filters\nu, y = [randn(nu)], [randn(ny)]\nenkf(u[1], y[1])  # One filtering step\nxÌ‚ = state(enkf)  # Ensemble mean\nP = covariance(enkf)  # Sample covariance\n\nSee also UnscentedKalmanFilter, ParticleFilter\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.ExtendedKalmanFilter","page":"API","title":"LowLevelParticleFilters.ExtendedKalmanFilter","text":"ExtendedKalmanFilter(kf, dynamics, measurement; Ajac, Cjac)\nExtendedKalmanFilter(dynamics, measurement, R1,R2,d0=MvNormal(Matrix(R1)); nu::Int, p = NullParameters(), Î± = 1.0, check = true)\n\nA nonlinear state estimator propagating uncertainty using linearization.\n\nThe constructor to the extended Kalman filter takes dynamics and measurement functions, and either covariance matrices, or a KalmanFilter. If the former constructor is used, the number of inputs to the system dynamics, nu, must be explicitly provided with a keyword argument.\n\nBy default, the filter will internally linearize the dynamics using ForwardDiff. User provided Jacobian functions can be provided as keyword arguments Ajac and Cjac. These functions should have the signature (x,u,p,t)::AbstractMatrix where x is the state, u is the input, p is the parameters, and t is the time.\n\nThe dynamics and measurement function are on the following form\n\nx(t+1) = dynamics(x, u, p, t) + w\ny      = measurement(x, u, p, t) + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nThe matrices R1, R2 can be time varying such that, e.g., R1[:, :, t] contains the R_1 matrix at time index t. They can also be given as functions on the form\n\nRfun(x, u, p, t) -> R\n\nThis allows for, e.g., handling functions where the dynamics disturbance w is an input argument to the function, by linearizing the dynamics w.r.t. the disturbance input in a function for R_1, like this (assuming the dynamics have the function signalture f(x, u, p, t, w)):\n\nfunction R1fun(x,u,p,t)\n    Bw = ForwardDiff.jacobian(w->f(x, u, p, t, w), zeros(length(w)))\n    Bw * R1 * Bw'\nend\n\nWhen providing functions, the dimensions of the state, input and output, nx, nu, ny must be provided as keyword arguments to the ExtendedKalmanFilter constructor since these cannot be inferred from the function signature. For maximum performance, provide statically sized matrices from StaticArrays.jl\n\nSee also UnscentedKalmanFilter which is typically more accurate than ExtendedKalmanFilter. See KalmanFilter for detailed instructions on how to set up a Kalman filter kf.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.IEKFMeasurementModel-Union{Tuple{IPM}, NTuple{4, Any}, NTuple{5, Any}, NTuple{6, Any}, NTuple{7, Any}, NTuple{8, Any}, NTuple{9, Any}} where IPM","page":"API","title":"LowLevelParticleFilters.IEKFMeasurementModel","text":"IEKFMeasurementModel{IPM}(measurement, R2, ny, Cjac, R12 = nothing, step = 1.0, maxiters = 10, epsilon = 1e-8, cache = nothing)\n\nA measurement model for the Iterated Extended Kalman Filter.\n\nArguments:\n\nIPM: A boolean indicating if the measurement function is inplace\nmeasurement: The measurement function y = h(x, u, p, t)\nR2: The measurement noise covariance matrix\nny: The number of measurement variables\nCjac: The Jacobian of the measurement function Cjac(x, u, p, t). If none is provided, ForwardDiff will be used.\nR12: Cross-covariance between dynamics noise at step k and measurement noise at step k+1. See Simon, D.: \"Optimal state estimation: Kalman, H Infinity, and nonlinear approaches\" sec. 7.1\nstep: The step size in the Gauss-Newton method. Should be Float64 between 0 and 1.\nmaxiters: The maximum number of iterations of the Gauss-Newton method inside the IEKF\nepsilon: The convergence criterion for the Gauss-Newton method inside the IEKF\ncache: A cache for the Jacobian\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.IEKFMeasurementModel-Union{Tuple{M}, Tuple{IPM}, Tuple{T}, Tuple{M, Any}} where {T, IPM, M}","page":"API","title":"LowLevelParticleFilters.IEKFMeasurementModel","text":"IEKFMeasurementModel{T,IPM}(measurement::M, R2; nx, ny, Cjac = nothing, R12 = nothing, step = 1.0, maxiters = 10, epsilon = 1e-8)\n\nT is the element type used for arrays\nIPM is a boolean indicating if the measurement function is inplace\nR12 is the cross-covariance between dynamics noise and measurement noise\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.IMM-Tuple{Any, AbstractMatrix, AbstractVector}","page":"API","title":"LowLevelParticleFilters.IMM","text":"IMM(models, P, Î¼; check = true, p = NullParameters(), interact = true)\n\nInteracting Multiple Model (IMM) filter. This filter is a combination of multiple Kalman-type filters, each with its own state and covariance. The IMM filter is a probabilistically weighted average of the states and covariances of the individual filters. The weights are determined by the probability matrix P and the mixing probabilities Î¼.\n\nThis implmentation allows for any combination of Kalman-type estimators to be used in the internal ensemble of models, and is not limited to linear estimators. This class of models encompasses others, such as \n\nJump Markov Linear Systems (JMLS)\nMultiple-model filters (interactivity can be turned off by setting interact=false)\nMultiple Hypothesis Tracking (MHT)\n\nwarning: Experimental\nThis filter is currently considered experimental and the user interface may change in the future without respecting semantic versioning.\n\nIn addition to the predict! and correct! steps, the IMM filter has an interact! method that updates the states and covariances of the individual filters based on the mixing probabilities. The combine! method combines the states and covariances of the individual filters into a single state and covariance. These four functions are typically called in either of the orders\n\ncorrect!, combine!, interact!, predict! (as is done in update!)\ninteract!, predict!, correct!, combine! (as is done in the reference cited below)\n\nThese two orders are cyclic permutations of each other, and the order used in update! is chosen to align with the order used in the other filters, where the initial condition is corrected using the first measurement, i.e., we assume the first measurement updates x(0-1) to x(00).\n\nThe initial (combined) state and covariance of the IMM filter is made up of the weighted average of the states and covariances of the individual filters. The weights are the initial mixing probabilities Î¼.\n\nRef: \"Interacting multiple model methods in target tracking: a survey\", E. Mazor; A. Averbuch; Y. Bar-Shalom; J. Dayan\n\nArguments:\n\nmodels: An array of Kalman-type filters, such as KalmanFilter, ExtendedKalmanFilter, UnscentedKalmanFilter, etc. The state of each model must have the same meaning, such that forming a weighted average makes sense.\nP: The mode-transition probability matrix. P[i,j] is the probability of transitioning from mode i to mode j (each row must sum to one).\nÎ¼: The initial mixing probabilities. Î¼[i] is the probability of being in mode i at the initial contidion (must sum to one).\ncheck: If true, check that the inputs are valid. If false, skip the checks.\np: Parameters for the filter. NOTE: this p is shared among all internal filters. The internal p of each filter will be overridden by this one.\ninteract: If true, the filter will run the interaction as part of update! and forward_trajectory. If false, the filter will not run the interaction step. This choice can be overridden by passing the keyword argument interact to the respective functions.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.IndexingMatrix","page":"API","title":"LowLevelParticleFilters.IndexingMatrix","text":"IndexingMatrix{N, VT} <: AbstractMatrix{Bool}\n\nA sparse representation of a matrix containing only 0s and 1s, where each row contains exactly one 1. This is stored efficiently as a vector of column indices.\n\nType Parameters\n\nN::Int: Number of columns in the matrix\nVT: Type of the indices vector\n\nFields\n\nindices::VT: Column indices where the 1s appear for each row\n\nExample\n\n# Represents the matrix:\n# [0 1 0\n#  0 0 1\n#  1 0 0]\nI = IndexingMatrix([2, 3, 1], 3)\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.IndexingMatrix-Tuple{AbstractMatrix}","page":"API","title":"LowLevelParticleFilters.IndexingMatrix","text":"IndexingMatrix(M::AbstractMatrix)\n\nConvert a valid indexing matrix to an IndexingMatrix type. Throws an error if M is not a valid indexing matrix.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.KalmanFilter","page":"API","title":"LowLevelParticleFilters.KalmanFilter","text":"KalmanFilter(A,B,C,D,R1,R2,d0=MvNormal(R1); p = NullParameters(), Î±=1, check=true)\n\nThe matrices A,B,C,D define the dynamics\n\nx' = Ax + Bu + w\ny  = Cx + Du + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nThe matrices can be time varying such that, e.g., A[:, :, t] contains the A matrix at time index t. They can also be given as functions on the form\n\nAfun(x, u, p, t) -> A\n\nWhen providing functions, the dimensions of the state, input and output, nx, nu, ny must be provided as keyword arguments to the KalmanFilter constructor since these cannot be inferred from the function signature. For maximum performance, provide statically sized matrices from StaticArrays.jl\n\nÎ± is an optional \"forgetting factor\", if this is set to a value > 1, such as 1.01-1.2, the filter will, in addition to the covariance inflation due to R_1, exhibit \"exponential forgetting\" similar to a Recursive Least-Squares (RLS) estimator. It is thus possible to get a RLS-like algorithm by setting R_1=0 R_2 = 1Î± and Î±  1 (Î± is the inverse of the traditional RLS parameter Î± = 1Î»). The exact form of the covariance update is\n\nR(t+1t) = Î± AR(t)A^T + R_1\n\nIf check = true (default) the function will check that the eigenvalues of A are less than 2 in absolute value. Large eigenvalues may be an indication that the system matrices are representing a continuous-time system and the user has forgotten to discretize it. Turn off this check by setting check = false.\n\nTutorials on Kalman filtering\n\nThe tutorial \"How to tune a Kalman filter\" details how to figure out appropriate covariance matrices for the Kalman filter, as well as how to add disturbance models to the system model. See also the tutorial in the documentation\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.KalmanFilteringSolution","page":"API","title":"LowLevelParticleFilters.KalmanFilteringSolution","text":"KalmanFilteringSolution <: AbstractKalmanFilteringSolution\n\nFields\n\nx: predictions x(t+1t) (plotted if plotx=true)\nxt: filtered estimates x(tt) (plotted if plotxt=true)\nR: predicted covariance matrices R(t+1t) (plotted if plotR=true)\nRt: filter covariances R(tt) (plotted if plotRt=true)\nll: loglikelihood\ne: prediction errors e(tt-1) = y - y(tt-1) (plotted if plote=true)\nK: Kalman gain\nS: Cholesky factorization of innovation covariance\n\nPlot\n\nThe solution object can be plotted\n\nplot(sol, plotx=true, plotxt=true, plotR=true, plotRt=true, plote=true, plotu=true, ploty=true, plotyh=true, plotyht=true, plotSt=false, name=\"\")\n\nwhere\n\nplotx: Plot the predictions x(t|t-1)\nplotxt: Plot the filtered estimates x(t|t)\nplotR: Plot the predicted covariances R(t|t-1) as ribbons at Â±2Ïƒ (1.96 Ïƒ to be precise)\nplotRt: Plot the filter covariances R(t|t) as ribbons at Â±2Ïƒ (1.96 Ïƒ to be precise)\nplote: Plot the prediction errors e(t|t-1) = y - yÌ‚(t|t-1)\nplotu: Plot the input\nploty: Plot the measurements\nplotyh: Plot the predicted measurements yÌ‚(t|t-1)\nplotyht: Plot the filtered measurements yÌ‚(t|t)\nplotS: Plot the innovation covariances S(t|t-1) as ribbons at Â±2Ïƒ on predicted measurements Å·(t|t-1) (requires plotyh=true)\nplotSt: Plot the filtered output covariances St = C*Rt*C' as ribbons at Â±2Ïƒ on filtered measurements Å·(t|t) (requires plotyht=true, not supported for UnscentedKalmanFilter)\nname: a string that is prepended to the labels of the plots, which is useful when plotting multiple solutions in the same plot.\nÏƒ = 1.96 The number of standard deviations covered by covariance ribbons\n\nTo modify the signal names used in legend entries, construct an instance of SignalNames and pass this to the filter (or directly to the plot command) using the names keyword argument.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.KalmanSmoothingSolution","page":"API","title":"LowLevelParticleFilters.KalmanSmoothingSolution","text":"struct KalmanSmoothingSolution\n\nA structure representing the solution to a Kalman smoothing problem.\n\nFields\n\nsol: A solution object containing the results of the filtering process.\nxT: The smoothed state estimate.\nRT: The smoothed state covariance.\n\nThe solution object can be plotted\n\nplot(sol; plotxT=true, plotRT=true, plotyhT=false, plotST=false, kwargs...)\n\nwhere\n\nplotxT: Plot the smoothed estimates x(t|T)\nplotRT: Plot the smoothed covariances R(t|T) as ribbons at Â±2Ïƒ (1.96 Ïƒ to be precise)\nplotyhT: Plot the smoothed output estimates Å·(t|T) = C*x(t|T)\nplotST: Plot the smoothed output covariances ST = C*RT*C' as ribbons at Â±2Ïƒ on smoothed measurements Å·(t|T) (requires plotyhT=true, not supported for UnscentedKalmanFilter)\nThe rest of the keyword arguments are the same as for KalmanFilteringSolution\n\nWhen plotting a smoothing solution, the filtering solution is also plotted. The same keyword arguments as for KalmanFilteringSolution may be used to control which signals are plotted\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.LinearMeasurementModel","page":"API","title":"LowLevelParticleFilters.LinearMeasurementModel","text":"LinearMeasurementModel(C, D, R2; R12 = nothing)\n\nA linear measurement model y = C*x + D*u + e.\n\nFields:\n\nC\nD\nR2: The measurement noise covariance matrix\nny: The number of measurement variables\nR12: Cross-covariance between dynamics noise at step k and measurement noise at step k+1. See Simon, D.: \"Optimal state estimation: Kalman, H Infinity, and nonlinear approaches\" sec. 7.1\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.MUKF","page":"API","title":"LowLevelParticleFilters.MUKF","text":"MUKF(; dynamics, nl_measurement_model::RBMeasurementModel, A, Cl, R1, d0, nxn, nu, ny, Ts=1.0, p=NullParameters(), weight_params=MerweParams(), names=default_names(length(d0.Î¼), nu, ny, \"MUKF\"))\n\nMarginalized Unscented Kalman Filter for mixed linear/nonlinear state-space models.\n\nwarning: Experimental\nThis filter is currently considered experimental and the user interface may change in the future without respecting semantic versioning.\n\nThis filter combines the Unscented Kalman Filter (UKF) for the nonlinear substate with a standard Kalman filters for the linear substate. This approach provides improved accuracy compared to linearization-based methods while remaining more efficient than standard UKF. This filter is sometimes referred to as a Rao-Blackwellized Unscented Kalman Filter, similar to the RBPF.\n\nRef: Morelande, M.R. & Moran, Bill. (2007). An Unscented Transformation for Conditionally Linear Models\n\nModel structure\n\nThe filter assumes dynamics on the form:\n\nbeginaligned\nx_t+1^n = d_n(x_t^n u p t) + A_n(x_t^n u p t) x_t^l + w_t^n \nx_t+1^l = d_l(x_t^n u p t) + A_l(x_t^n u p t) x_t^l + w_t^l \nw_t = beginbmatrix w_t^n  w_t^l endbmatrix sim mathcalN(0 R_1) \ny_t = g(x_t^n u p t) + C_l(x_t^n u p t) x_t^l + e_t quad e_t sim mathcalN(0 R_2)\nendaligned\n\nwhere x^n is the nonlinear substate and x^l is the linear substate. This is the conditionally linear form from Morelande & Moran (2007), that is, given x^n, the dynamics and measurement models are linear in x^l.\n\nArguments\n\ndynamics: Function returning nonlinear contribution to the dynamics [dn(xn, u, p, t); dl(xn, u, p, t)]. Control input dependence can be encoded directly in both dn and dl.\nnl_measurement_model: An instance of RBMeasurementModel containing g and R_2\nA: Combined coupling and dynamics matrix/function [An(xn); Al(xn)] (nx Ã— nxl). The first nxn rows (An) couple the linear state to the nonlinear state dynamics, and the last nxl rows (Al) define the linear state dynamics matrix.\nCl: Measurement matrix/function Cl(xn, u, p, t) for the linear substate\nR1: Full process noise covariance matrix (nx Ã— nx) for the combined state xn; xl\nd0: Initial normal distribution for the full state xn; xl\nnxn: Dimension of the nonlinear substate\nnu: Number of inputs\nny: Number of measurements\nTs: Sampling time (default: 1.0)\np: Parameters (default: NullParameters())\nweight_params: Unscented transform parameters (default: MerweParams())\nnames: Signal names for plotting\nn_inds: Optional index vector for nonlinear state elements in full state vector (default: 1:nxn). Allows arbitrary state ordering.\nl_inds: Optional index vector for linear state elements in full state vector (default: nxn+1:nx). Must be provided together with n_inds.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.MerweParams","page":"API","title":"LowLevelParticleFilters.MerweParams","text":"MerweParams(; Î± = 1.0, Î² = 2.0, Îº = 0.0)\nMerweParams(; Î±Îº = 1.0, Î² = 2.0) # Simplified interface with only one parameter for Î±Îº\n\nUnscented transform parameters suggested by van der Merwe et al.\n\nÎ±: Scaling parameter (0,1] for the spread of the sigma points. Reduce Î± to reduce the spread.\nÎ²: Incorporates prior knowledge of the distribution of the state.\nÎº: Secondary scaling parameter that is usually set to 0. Increase Îº to increase the spread of the sigma points.\n\nIf Î±^2 (L + Îº)  L where L is the dimension of the sigma points, the center mean weight is negative. This is allowed, but may in some cases lead to an indefinite covariance matrix.\n\nThe spread of the points are Î±^2 (L + Îº) where L is the dimension of each point. Visualize the spread by\n\nusing Plots\nÎ¼ = [0.0, 0.0]\nÎ£ = [1.0 0.0; 0.0 1.0]\npars = LowLevelParticleFilters.MerweParams(Î± = 1e-3, Î² = 2.0, Îº = 0.0)\nxs = LowLevelParticleFilters.sigmapoints(Î¼, Î£, pars)\nunscentedplot(xs, pars)\n\nA simplified tuning rule \n\nIf a decrease in the spread of the sigma points is desired, use Îº = 0 and Î±  1.\nIf an increase in the spread of the sigma points is desired, use Îº  0 and Î± = 1.\n\nThis rule may be used when using the interface with only a single function argument Î±Îº. See Nielsen, K. et al., 2021, \"UKF Parameter Tuning for Local Variation Smoothing\" for more details.\n\nSee also WikiParams and TrivialParams\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.ParticleFilter-Tuple{Integer, Any, Function, Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.ParticleFilter","text":"ParticleFilter(N::Integer, dynamics, measurement, dynamics_density, measurement_density, initial_density; threads = false, p = NullParameters(), kwargs...)\n\nSee the docs for more information: https://baggepinnen.github.io/LowLevelParticleFilters.jl/stable/#Particle-filter-1\n\nArguments:\n\nN: Number of particles\ndynamics: A discrete-time dynamics function (x, u, p, t) -> xâº\nmeasurement: A measurement function (x, u, p, t) -> y\ndynamics_density: A probability-density function for additive noise in the dynamics. Use AdvancedParticleFilter for non-additive noise.\nmeasurement_density: A probability-density function for additive measurement noise. Use AdvancedParticleFilter for non-additive noise.\ninitial_density: Distribution of the initial state.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.ParticleFilteringSolution","page":"API","title":"LowLevelParticleFilters.ParticleFilteringSolution","text":"ParticleFilteringSolution{F, Tu, Ty, Tx, Tw, Twe, Tll} <: AbstractFilteringSolution\n\nFields:\n\nf: The filter used to produce the solution.\nu: Input\ny: Output / measurements\nx: Particles, the size of this array is (N,T), where N is the number of particles and T is the number of time steps. Each element represents a weighted state hypothesis with weight given by we.\nw: Weights (log space). These are used for internal computations.\nwe: Weights (exponentiated / original space). These are the ones to use to compute weighted means etc., they sum to one for each time step.\nll: Log likelihood\n\nPlot\n\nThe solution object can be plotted\n\nplot(sol; nbinsy=30, xreal=nothing, dim=nothing, ploty=true, q=nothing)\n\nBy default, a weighted 2D histogram is plotted, one for each state variable. If a vector of quantiles are provided in q, the quantiles are plotted instead of the histogram. If xreal is provided, the true state is plotted as a scatter plot on top of the histogram. If dim is provided, only the specified dimension is plotted. If ploty is true, the measurements are plotted as well.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.RBMeasurementModel","page":"API","title":"LowLevelParticleFilters.RBMeasurementModel","text":"RBMeasurementModel{IPM}(measurement, R2, ny)\n\nA measurement model for the Rao-Blackwellized particle filter.\n\nFields:\n\nmeasurement: The contribution from the nonlinar state to the output, g in y = g(x^n u p t) + C x^l + e\nR2: The probability distribution of the measurement noise. If C == 0, this may be any distribution, otherwise it must be an instance of MvNormal or SimpleMvNormal.\nny: The number of outputs\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.RBPF-Union{Tuple{AUGD}, Tuple{IPM}, Tuple{IPD}, Tuple{Int64, Any, Any, LowLevelParticleFilters.AbstractMeasurementModel, Any, Any}} where {IPD, IPM, AUGD}","page":"API","title":"LowLevelParticleFilters.RBPF","text":"RBPF{IPD,IPM,AUGD}(N::Int, kf, dynamics, nl_measurement_model::AbstractMeasurementModel, R1n, d0n; An, nu::Int, Ts=1.0, p=NullParameters(), names, rng = Xoshiro(), resample_threshold=0.1)\n\nRao-Blackwellized particle filter, also called \"Marginalized particle filter\". The filter is effectively a particle filter where each particle is a Kalman filter that is responsible for the estimation of a linear sub structure.\n\nwarning: Experimental\nThis filter is currently considered experimental and the user interface may change in the future without respecting semantic versioning.\n\nThe filter assumes that the dynamics follow \"model 2\" in the reference below, i.e., the dynamics is described by\n\n beginalign\n     x_t+1^n = f_n(x_t^n u p t) + A_n(x_t^n u p t) x_t^l + w_t^n quad w_t^n sim mathcalN(0 R_1^n) \n     x_t+1^l = A() x_t^l + Bu + w_t^l quad w_t^l sim mathcalN(0 R_1^l) \n     y_t = g(x_t^n u p t) + C() x_t^l + e_t quad e_t sim mathcalN(0 R_2)\n endalign\n\nwhere x^n is a subset of the state that has nonlinear dynamics, and x^l is the linear part of the state. The entire state vector is represented by a special type RBParticle that behaves like the vector [xn; xl], but stores xn, xl and the covariance R or xl separately.\n\nN: Number of particles\nkf: The internal Kalman filter that will be used for the linear part. This encodes the dynamics of the linear subspace. The matrices A B C D R_1^l of the Kalman filter may be functions of x, u, p, t that return a matrix. The state x received by such functions is of type RBParticle with the fields xn and xl.\ndynamics: The nonlinear part f_n of the dynamics of the nonlinear substate f(xn, u, p, t)\nnl_measurement_model: An instance of RBMeasurementModel that stores g and the measurement noise distribution R_2.\nR1n: The noise distribution of the nonlinear state dynamics, this may be a covariance matrix or a distribution. If An = nothing, this may be any distribution, otherwise it must be an instance of MvNormal or SimpleMvNormal.\nd0n: The initial distribution of the nonlinear state x_0^n.\nAn: The matrix that describes the linear effect on the nonlinear state, i.e., A_n x^l. This may be a matrix or a function of x u p t that returns a matrix. Pass An = nothing if there is no linear effect on the nonlinear state. The x received by such a function is of type RBParticle with the fields xn and xl.\nnu: The number of control inputs\nTs: The sampling time\np: Parameters\nnames: Signal names, an instance of SignalNames\nrng: Random number generator\nresample_threshold: The threshold for resampling\n\nBased on the article \"Marginalized Particle Filters for Mixed Linear/Nonlinear State-space Models\" by Thomas SchÃ¶n, Fredrik Gustafsson, and Per-Johan Nordlund\n\nExtended help\n\nThe paper contains an even more general model, where the linear part is linearly affected by the nonlinear state. It further details a number of special cases in which possible simplifications arise. \n\nIf C == 0 and D == 0, the measurement is not used by the Kalman filter and we may thus have an arbitrary probability distribution for the measurement noise.\nIf An == 0, the nonlinear state is not affected by the linear state and we may have an arbitrary probability distribution for the nonlinear state noise R1n. Otherwise R1n must be Gaussian.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.RBParticle-Tuple{Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.RBParticle","text":"RBParticle(xn, xl, R) <: AbstractVector\n\nA struct that represents the state of a Rao-Blackwellized particle filter. The struct is an abstract vector, and when indexed like a vector it behaves as [xn; xl]. To access nonlinear or linear substate individually, access the fields xn and xl.\n\nArguments:\n\nxn: The nonlinear state vector\nxl: The linear state vector\nR: The covariance matrix for the linear state\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.SignalNames","page":"API","title":"LowLevelParticleFilters.SignalNames","text":"SignalNames(; x, u, y, name)\n\nA structure representing the names of the signals in a system.\n\nx::Vector{String}: Names of the state variables\nu::Vector{String}: Names of the input variables\ny::Vector{String}: Names of the output variables\nname::String: Name of the system\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.SignalNames-Tuple{SignalNames, Any}","page":"API","title":"LowLevelParticleFilters.SignalNames","text":"SignalNames(sn::SignalNames, name)\n\nCopy the SignalNames structure and change the name of the system.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.SqExtendedKalmanFilter","page":"API","title":"LowLevelParticleFilters.SqExtendedKalmanFilter","text":"SqExtendedKalmanFilter(kf, dynamics, measurement; Ajac, Cjac)\nSqExtendedKalmanFilter(dynamics, measurement, R1,R2,d0=MvNormal(Matrix(R1)); nu::Int, p = NullParameters(), Î± = 1.0, check = true)\n\nA nonlinear state estimator propagating uncertainty using linearization with square-root covariance representation.\n\nThis filter combines the Extended Kalman Filter's ability to handle nonlinear dynamics with the Square-root Kalman Filter's numerical stability. It maintains the covariance in Cholesky factorized form, ensuring positive definiteness and improved numerical conditioning.\n\nThe constructor takes dynamics and measurement functions, and either covariance matrices or a SqKalmanFilter. If the former constructor is used, the number of inputs to the system dynamics, nu, must be explicitly provided.\n\nBy default, the filter will internally linearize the dynamics using ForwardDiff. User provided Jacobian functions can be provided as keyword arguments Ajac and Cjac. These functions should have the signature (x,u,p,t)::AbstractMatrix where x is the state, u is the input, p is the parameters, and t is the time.\n\nThe dynamics and measurement function are on the following form:\n\nx(t+1) = dynamics(x, u, p, t) + w\ny      = measurement(x, u, p, t) + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nFor the square-root formulation, R1 and R2 can be provided as:\n\nRegular covariance matrices (will be converted to Cholesky factors internally)\nUpperTriangular matrices representing the Cholesky factors\n\nSee also ExtendedKalmanFilter for the standard formulation and SqKalmanFilter for the linear square-root filter.\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.SqKalmanFilter","page":"API","title":"LowLevelParticleFilters.SqKalmanFilter","text":"SqKalmanFilter(A,B,C,D,R1,R2,d0=MvNormal(R1); p = NullParameters(), Î±=1)\n\nA standard Kalman filter on square-root form. This filter may have better numerical performance when the covariance matrices are ill-conditioned.\n\nThe matrices A,B,C,D define the dynamics\n\nx' = Ax + Bu + w\ny  = Cx + Du + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nThe matrices can be time varying such that, e.g., A[:, :, t] contains the A matrix at time index t. They can also be given as functions on the form\n\nAfun(x, u, p, t) -> A\n\nThe covariance matrices R1 and R2 are the covariance matrices of the process noise and measurement noise, respectively. They can be provided as a matrix, as an UpperTriangular matrix representing the Cholesky factor. If R1 or R2 is a function, it must return the upper triangular Cholesky factor of the covariance matrix at the given time index.\n\nThe internal fields storing covariance matrices are for this filter storing the upper-triangular Cholesky factor.\n\nÎ± is an optional \"forgetting factor\", if this is set to a value > 1, such as 1.01-1.2, the filter will, in addition to the covariance inflation due to R_1, exhibit \"exponential forgetting\" similar to a Recursive Least-Squares (RLS) estimator. It is thus possible to get a RLS-like algorithm by setting R_1=0 R_2 = 1Î± and Î±  1 (Î± is the inverse of the traditional RLS parameter Î± = 1Î»). The form of the covariance update is\n\nR(t+1t) = Î± AR(t)A^T + R_1\n\nRef: \"A Square-Root Kalman Filter Using Only QR Decompositions\", Kevin Tracy https://arxiv.org/abs/2208.06452\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.TrivialParams","page":"API","title":"LowLevelParticleFilters.TrivialParams","text":"TrivialParams()\n\nUnscented transform parameters representing a trivial choice of weights, where all weights are equal.\n\nSee also WikiParams and MerweParams\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.UIKalmanFilter","page":"API","title":"LowLevelParticleFilters.UIKalmanFilter","text":"UIKalmanFilter(kf::KalmanFilter, G)\nUIKalmanFilter(A, B, C, D, G, R1, R2, d0; kwargs...)\n\nAn Unknown Input Kalman Filter for estimating both state and unknown inputs in linear systems.\n\nwarning: Experimental\nThis filter is currently considered experimental and the user interface may change in the future without respecting semantic versioning.\n\nThis filter implements the algorithm from Gillijns & De Moor (2007), \"Unbiased minimum-variance input and state estimation for linear discrete-time systems\", which provides optimal minimum-variance unbiased estimates of both the state x and unknown input d, without augmenting the state vector.\n\nThe system is assumed to be on the form:\n\nx(k+1) = A*x(k) + B*u(k) + G*d(k) + w(k)\ny(k)   = C*x(k) + D*u(k) + e(k)\n\nwhere d(k) is an unknown input vector, w ~ N(0, R1), and e ~ N(0, R2).\n\nArguments:\n\nkf::KalmanFilter: An existing Kalman filter containing A, B, C, D, R1, R2, and initial state\nG: Unknown input matrix (nx Ã— nd) or function G(x,u,p,t) returning such a matrix\nA, B, C, D, R1, R2, d0: Standard Kalman filter parameters (see KalmanFilter)\n\nRequirements:\n\nThe filter requires that rank(C*G) = size(G,2) (full column rank). This ensures that the unknown input can be uniquely estimated from the measurements. If this does not hold, consider an augmented state Kalman filter instead, for which a looser observability condition holds.\n\nReturns from correct!:\n\nIn addition to the standard Kalman filter outputs (ll, e, S, Sáµª, K), the correct! function also returns:\n\nd: The estimate of the unknown input d(k-1)\nM: The matrix M used for unknown input estimation (weighted least squares matrix)\n\nExample:\n\nsol = forward_trajectory(uikf, u, y)\nsol.extra.d # Estimated unknown inputs over time\n\nReference:\n\nGillijns, S., & De Moor, B. (2007). Unbiased minimum-variance input and state estimation for linear discrete-time systems. Automatica, 43(1), 111-116.\n\nSee also KalmanFilter, ExtendedKalmanFilter\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.UKFMeasurementModel-Union{Tuple{AUGM}, Tuple{IPM}, NTuple{8, Any}, NTuple{9, Any}, NTuple{10, Any}} where {IPM, AUGM}","page":"API","title":"LowLevelParticleFilters.UKFMeasurementModel","text":"UKFMeasurementModel{inplace_measurement,augmented_measurement}(measurement, R2, ny, ne, innovation, mean, cov, cross_cov, weight_params, cache = nothing)\n\nA measurement model for the Unscented Kalman Filter.\n\nArguments:\n\nmeasurement: The measurement function y = h(x, u, p, t)\nR2: The measurement noise covariance matrix\nny: The number of measurement variables\nne: If augmented_measurement is true, the number of measurement noise variables\ninnovation(y::AbstractVector, yh::AbstractVector) where the arguments represent (measured output, predicted output)\nmean(ys::AbstractVector{<:AbstractVector}): computes the mean of the vector of vectors of output sigma points.\ncov(ys::AbstractVector{<:AbstractVector}, y::AbstractVector): computes the covariance matrix of the output sigma points.\ncross_cov(xs::AbstractVector{<:AbstractVector}, x::AbstractVector, ys::AbstractVector{<:AbstractVector}, y::AbstractVector, W::UKFWeights) where the arguments represents (state sigma points, mean state, output sigma points, mean output, weights). The function should return the weighted cross-covariance matrix between the state and output sigma points.\nweight_params: A type that holds the parameters for the unscented-transform weights. See UnscentedKalmanFilter and Docs: Unscented transform for more information.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.UKFMeasurementModel-Union{Tuple{AUGM}, Tuple{IPM}, Tuple{T}, Tuple{Any, Any}} where {T, IPM, AUGM}","page":"API","title":"LowLevelParticleFilters.UKFMeasurementModel","text":"UKFMeasurementModel{T,IPM,AUGM}(measurement, R2; nx, ny, ne = nothing, innovation = -, mean = weighted_mean, cov = weighted_cov, cross_cov = cross_cov, static = nothing)\n\nT is the element type used for arrays\nIPM is a boolean indicating if the measurement function is inplace\nAUGM is a boolean indicating if the measurement model is augmented\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.UKFWeights","page":"API","title":"LowLevelParticleFilters.UKFWeights","text":"UKFWeights\n\nWeights for the Unscented Transform.\n\nSigmapoints are by convention ordered such that the center (mean) point is first.\n\nFields\n\nwm: center weight when computing mean\nwc: center weight when computing covariance\nwmi: off-center weight when computing mean\nwci: off-center weight when computing covariance\nW: Cholesky weight\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.UnscentedKalmanFilter-Union{Tuple{AUGM}, Tuple{AUGD}, Tuple{IPM}, Tuple{IPD}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any, Any}} where {IPD, IPM, AUGD, AUGM}","page":"API","title":"LowLevelParticleFilters.UnscentedKalmanFilter","text":"UnscentedKalmanFilter(dynamics, measurement, R1, R2, d0=MvNormal(Matrix(R1)); p = NullParameters(), ny, nu, weight_params)\nUnscentedKalmanFilter{IPD,IPM,AUGD,AUGM}(dynamics, measurement_model::AbstractMeasurementModel, R1, d0=SimpleMvNormal(R1); p=NullParameters(), nu, weight_params)\n\nA nonlinear state estimator propagating uncertainty using the unscented transform.\n\nThe dynamics and measurement function are on either of the following forms\n\nx' = dynamics(x, u, p, t) + w\ny  = measurement(x, u, p, t) + e\n\nx' = dynamics(x, u, p, t, w)\ny  = measurement(x, u, p, t, e)\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0. The former (default) assums that the noise is additive and added after the dynamics and measurement updates, while the latter assumes that the dynamics functions take an additional argument corresponding to the noise term. The latter form (sometimes refered to as the \"augmented\" form) is useful when the noise is multiplicative or when the noise is added before the dynamics and measurement updates. See \"Augmented UKF\" below for more details on how to use this form. In both cases should the noise be modeled as discrete-time white noise, see Discretization: Covariance matrices.\n\nThe matrices R1, R2 can be time varying such that, e.g., R1[:, :, t] contains the R_1 matrix at time index t. They can also be given as functions on the form\n\nRfun(x, u, p, t) -> R\n\nFor maximum performance, provide statically sized matrices from StaticArrays.jl\n\nny, nu indicate the number of outputs and inputs.\n\nCustom type of u\n\nThe input u may be of any type, e.g., a named tuple or a custom struct. The u provided in the input data is passed directly to the dynamics and measurement functions, so as long as the type is compatible with the dynamics it will work out. The one exception where this will not work is when calling simulate, which assumes that u is an array.\n\nAugmented UKF\n\nIf the noise is not additive, one may use the augmented form of the UKF. In this form, the dynamics functions take additional input arguments that correspond to the noise terms. To enable this form, the typed constructor\n\nUnscentedKalmanFilter{inplace_dynamics,inplace_measurement,augmented_dynamics,augmented_measurement}(...)\n\nis used, where the Boolean type parameters have the following meaning\n\ninplace_dynamics: If true, the dynamics function operates in-place, i.e., it modifies the first argument in dynamics(dx, x, u, p, t). Default is false.\ninplace_measurement: If true, the measurement function operates in-place, i.e., it modifies the first argument in measurement(y, x, u, p, t). Default is false.\naugmented_dynamics: If true the dynamics function is augmented with an additional noise input w, i.e., dynamics(x, u, p, t, w). Default is false.\naugmented_measurement: If true the measurement function is agumented with an additional noise input e, i.e., measurement(x, u, p, t, e). Default is false. (If the measurement noise has fewer degrees of freedom than the number of measurements, you may failure in Cholesky factorizations, see \"Custom Cholesky factorization\" below).\n\nUse of augmented dynamics incurs extra computational cost. The number of sigma points used is 2L+1 where L is the length of the augmented state vector. Without augmentation, L = nx, with augmentation L = nx + nw and L = nx + ne for dynamics and measurement, respectively.\n\nWeight tuning\n\nThe spread of the sigma points is controlled by weight_params::UTParams. See Docs: Unscented transform for a tutorial. The default is TrivialParams for unweighted sigma points, other options are WikiParams and MerweParams.\n\nSigma-point rejection\n\nFor problems with challenging dynamics, a mechanism for rejection of sigma points after the dynamics update is provided. A function reject(x) -> Bool can be provided through the keyword argument reject that returns true if a sigma point for x(t+1) should be rejected, e.g., if an instability or non-finite number is detected. A rejected point is replaced by the propagated mean point (the mean point cannot be rejected). This function may be provided either to the constructor of the UKF or passed to the predict! function.\n\nEnforcing contraints using sigma-point projection\n\nConstraints on the state (or output) may be enforced by projecting the sigma points onto the constraint set during the dynamics (or measurement) update. In general, two projections per update are required, one after the generation of the sigma points but before the dynamics is applied, and one after the dynamics update. No functionality for this is provided in this package, but the projection may be readibly implemented manually in the dynamics function, e.g.,\n\nfunction dynamics(x, u, p, t)\n    x  = project(x)  # Sigma points may have been generated outside the constraint set\n    xp = f(x, u, p, t)\n    xp = project(xp) # The dynamics may have moved the points outside the constraint set\n    return xp\nend\n\nEquality constraints can alternatively be handled by making use of a pseudo-measurement 0 = C_conx with close to zero covariance.\n\nCustom measurement models\n\nBy default, standard arithmetic mean and e(y, yh) = y - yh are used as mean and innovation functions.\n\nBy passing and explicitly created UKFMeasurementModel, one may provide custom functions that compute the mean, the covariance and the innovation. This is useful in situations where the state or a measurement lives on a manifold. One may further override the mean and covariance functions for the state sigma points by passing the keyword arguments state_mean and state_cov to the constructor.\n\nstate_mean(xs::AbstractVector{<:AbstractVector}, w::UKFWeights) computes the weighted mean of the vector of vectors of state sigma points.\nstate_cov(xs::AbstractVector{<:AbstractVector}, m, w::UKFWeights) where the first argument represent state sigma points and the second argument, represents the weighted mean of those points. The function should return the covariance matrix of the state sigma points weighted by w.\n\nSee UKFMeasurementModel for more details on how to set up a custom measurement model. Pass the custom measurement model as the second argument to the UKF constructor.\n\nCustom Cholesky factorization\n\nThe UnscentedKalmanFilter supports providing a custom function to compute the Cholesky factorization of the covariance matrices for use in sigma-point generation.\n\nIf either of the following conditions are met, you may experience failure in internal Cholesky factorizations:\n\nThe dynamics noise or measurement noise covariance matrices (R_1 R_2) are singular\nThe measurement is augmented and the measurement noise has fewer degrees of freedom than the number of measurements\n(Under specific technical conditions) The dynamics is augmented and the dynamics noise has fewer degrees of freedom than the number of state variables. The technical conditions are easiest to understand in the linear-systems case, where it corresponds to the Riccati equation associated with the Kalman gain not having a solution. This may happen when the pair (A R1) has uncontrollable modes on the unit circle, for example, when there are integrating modes that are not affected through the noise.\n\nThe error message may look like\n\nERROR: PosDefException: matrix is not positive definite; Factorization failed.\n\nIn such situations, it is advicable to reconsider the noise model and covariance matrices, alternatively, you may provide a custom Cholesky factorization function to the UKF constructor through the keyword argument cholesky!. The function should have the signature cholesky!(A::AbstractMatrix)::Cholesky. A useful alternative factorizaiton when covariance matrices are expected to be singular is cholesky! = R->cholesky!(Positive, Matrix(R)) where the \"positive\" Cholesky factorization is provided by the package PositiveFactorizations.jl, which must be manually installed and loaded by the user.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.WikiParams","page":"API","title":"LowLevelParticleFilters.WikiParams","text":"WikiParams(; Î± = 1.0, Î² = 0.0, Îº = 1.0)\nWikiParams(; Î±Îº = 1.0, Î² = 0.0) # Simplified interface with only one parameter for Î±Îº\n\nUnscented transform parameters suggested at Wiki: Kalmanfilter#Sigmapoints.\n\nÎ±: Scaling parameter (0,1] for the spread of the sigma points. Reduce Î± to reduce the spread.\nÎ²: Incorporates prior knowledge of the distribution of the state.\nÎº: Secondary scaling parameter that is usually set to 3nx/2 or 1. Increase Îº to increase the spread of the sigma points.\n\nIf Î±^2 Îº  L where L is the dimension ofthe sigma points, the center mean weight is negative. This is allowed, but may in some cases lead to an indefinite covariance matrix.\n\nThe spread of the points are Î±^2 Îº, that is, independent on the point dimension. Visualize the spread by\n\nusing Plots\nÎ¼ = [0.0, 0.0]\nÎ£ = [1.0 0.0; 0.0 1.0]\npars = LowLevelParticleFilters.WikiParams(Î± = 1.0, Î² = 0.0, Îº = 1.0)\nxs = LowLevelParticleFilters.sigmapoints(Î¼, Î£, pars)\nunscentedplot(xs, pars)\n\nA simplified tuning rule \n\nIf a decrease in the spread of the sigma points is desired, use Îº = 1 and Î±  1.\nIf an increase in the spread of the sigma points is desired, use Îº  1 and Î± = 1.\n\nThis rule may be used when using the interface with only a single function argument Î±Îº. See Nielsen, K. et al., 2021, \"UKF Parameter Tuning for Local Variation Smoothing\" for more details.\n\nSee also MerweParams and TrivialParams\n\n\n\n\n\n","category":"type"},{"location":"api/#LowLevelParticleFilters.IteratedExtendedKalmanFilter","page":"API","title":"LowLevelParticleFilters.IteratedExtendedKalmanFilter","text":"IteratedExtendedKalmanFilter(kf, dynamics, measurement; Ajac, Cjac, step, maxiters, epsilon)\nIteratedExtendedKalmanFilter(dynamics, measurement, R1,R2,d0=SimpleMvNormal(Matrix(R1)); nu::Int, ny=size(R2,1), Cjac = nothing, step = 1.0, maxiters=10, epsilon=1e-8)\n\nA nonlinear state estimator propagating uncertainty using linearization. Returns an ExtendedKalmanFilter object but with Gauss-Newton based iterating measurement correction step.\n\nThe constructor to the iterated version of extended Kalman filter takes dynamics and measurement functions, and either covariance matrices, or a KalmanFilter. If the former constructor is used, the number of inputs to the system dynamics, nu, must be explicitly provided with a keyword argument.\n\nBy default, the filter will internally linearize the dynamics using ForwardDiff. User provided Jacobian functions can be provided as keyword arguments Ajac and Cjac. These functions should have the signature (x,u,p,t)::AbstractMatrix where x is the state, u is the input, p is the parameters, and t is the time.\n\nThe dynamics and measurement function are of the following form\n\nx(t+1) = dynamics(x, u, p, t) + w\ny      = measurement(x, u, p, t) + e\n\nwhere w ~ N(0, R1), e ~ N(0, R2) and x(0) ~ d0\n\nstep is the step size for the Gauss-Newton iterations. Float between 0 and 1. Default is 1.0 which should be good enough for most applications. For more challenging applications, a smaller step size might be necessary.\nmaxiters is the maximum number of iterations. Default is 10. Usually a small number of iterations is needed. If higher number is needed, consider using UKF.\nepsilon is the convergence criterion. Default is 1e-8\n\nSee also UnscentedKalmanFilter which is more robust than IteratedExtendedKalmanFilter. See KalmanFilter for detailed instructions on how to set up a Kalman filter kf.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.autotune_covariances","page":"API","title":"LowLevelParticleFilters.autotune_covariances","text":"autotune_covariances(\n    sol::KalmanFilteringSolution;\n    diagonal = true,\n    optimize_x0 = false,\n    offset = 0.0,\n    optimizer = LevenbergMarquardt(),\n    show_trace = true,\n    show_every = 1,\n    autodiff = :forward,\n    v_R1 = nothing,\n    v_R2 = nothing,\n    kwargs...\n)\n\nAutomatically tune the covariance matrices R1 and R2 (and optionally x0) of a Kalman-style filter by maximizing the log-likelihood (MLE) or log-posterior (MAP) using Gauss-Newton optimization.\n\ninfo: Requires LeastSquaresOptim.jl\nThis function is available only if LeastSquaresOptim.jl is manually installed and loaded by the user. Install with: using Pkg; Pkg.add(\"LeastSquaresOptim\")\n\nArguments\n\nsol::KalmanFilteringSolution: Solution object from forward_trajectory\ndiagonal::Bool: If true (default), only optimize diagonal elements. If false, optimize full covariance matrices.\noptimize_x0::Bool: If true, also optimize the initial state estimate (default: false)\noffset::Real: Offset added to the log-likelihood residuals to ensure positive squared residuals (default: 0.0). If you encounter an error about negative squared residuals during optimization, try increasing this value by an amount slightly larger than what is indicated in the error message.\noptimizer: Optimization algorithm from LeastSquaresOptim (default: LevenbergMarquardt())\nshow_trace::Bool: Show optimization progress (default: true)\nshow_every::Int: Show progress every N iterations (default: 1)\nautodiff: Automatic differentiation method (default: :forward)\nv_R1::Union{Nothing,Real}: Degrees of freedom for Inverse-Wishart prior on R1 (default: nothing, no prior). Must be > nw-1 for proper prior, where nw = size(R1,1). The prior mean is automatically set to the initial R1 from the filter.\nv_R2::Union{Nothing,Real}: Degrees of freedom for Inverse-Wishart prior on R2 (default: nothing, no prior). Must be > ny-1 for proper prior. The prior mean is automatically set to the initial R2 from the filter.\nkwargs...: Additional keyword arguments passed to LeastSquaresOptim.optimize!\n\nReturns\n\nA named tuple containing:\n\nfilter: The filter with optimized covariance matrices (and x0 if applicable)\nresult: The optimization result from LeastSquaresOptim\nR1: The optimized process noise covariance\nR2: The optimized measurement noise covariance\nx0: The optimized initial state (if optimize_x0=true)\nsol_opt: The solution from running forward_trajectory with the optimized filter\n\nMaximum Likelihood Estimation (MLE)\n\nBy default (when v_R1 and v_R2 are nothing), performs maximum likelihood estimation:\n\nusing LeastSquaresOptim\n\nsol = forward_trajectory(kf, u, y)\nresult = autotune_covariances(sol)  # Pure MLE\n\nMaximum A Posteriori (MAP) Estimation\n\nUse Inverse-Wishart priors for Bayesian regularization. The Inverse-Wishart distribution is the conjugate prior for covariance matrices. For a covariance matrix Î£ with dimension n:\n\np(Î£) = InverseWishart(v, Î¨)\n\nwhere:\n\nv (degrees of freedom): Controls prior strength. Larger v = stronger prior. Must be > n-1.\nPrior mean is automatically set to the initial covariance matrices (R1orig and R2orig) from the filter.\nInternally, the scale matrix is computed as: Î¨ = (v - n - 1) * R_orig\n\nThe mean of the Inverse-Wishart prior is E[Î£] = Î¨/(v - n - 1) = R_orig.\n\nTypical choices for v:\n\nWeak prior: v = n + 2 (prior has low confidence, stays close to MLE)\nModerate prior: v = n + 5 to n + 10\nStrong prior: v = n + 20 or higher (high confidence, stays close to initial guess)\n\n# MAP with weak Inverse-Wishart prior on both R1 and R2\nnx, ny = 2, 2\nv1 = nx + 2  # Weak prior\nv2 = ny + 2\n\nresult = autotune_covariances(sol; v_R1=v1, v_R2=v2)\n\n# MAP with prior only on R1 (useful when measurement noise is well-known)\nresult = autotune_covariances(sol; v_R1=nx+5)\n\n# Strong prior to prevent overfitting with limited data\nv1_strong = nx + 20\nresult = autotune_covariances(sol; v_R1=v1_strong)\n\nNotes\n\nThe function uses log-likelihood optimization via prediction_errors! with loglik=true\nFor diagonal parametrization, log-diagonal elements are optimized to ensure positivity\nFor full parametrization, a triangular (Cholesky-like) parametrization is used\nMAP estimation adds Inverse-Wishart prior terms to the objective function\nThe prior mean is the initial covariance matrix from the filter, regularizing toward the initial guess\nThe offset parameter is passed to prediction_errors! and shifts the log-likelihood residuals\nWhen using MAP, the optimized covariances balance fit to data (likelihood) and prior belief (prior)\nx0 optimization uses MLE only (no prior on initial state)\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.combine!-Tuple{IMM}","page":"API","title":"LowLevelParticleFilters.combine!","text":"combine!(imm::IMM)\n\nCombine the models of the IMM filter into a single state imm.x and covariance imm.R. This is done by taking a weighted average of the states and covariances of the individual models, where the weights are the mixing probabilities Î¼.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.commandplot","page":"API","title":"LowLevelParticleFilters.commandplot","text":"commandplot(pf, u, y, p=parameters(pf); kwargs...)\n\nProduce a helpful plot. For customization options (kwargs...), see ?pplot. After each time step, a command from the user is requested.\n\nq: quit\ns n: step n steps\n\nnote: Note\nThis function requires using Plots to be called before it is used.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!","page":"API","title":"LowLevelParticleFilters.correct!","text":"ll, e = correct!(pf, u, y, p = parameters(f), t = index(f))\n\nUpdate state/weights based on measurement y,  returns log-likelihood and prediction error (the error is always 0 for particle filters).\n\nExtended help\n\nTo perform separate measurement updates for different sensors, see the \"Measurement models\" in the documentation. For AdvancedParticleFilter, this can be realized by passing a custom measurement_likelihood function as the keyword argument g to correct!, or by calling the lower-level function measurement_equation! with a custom measurement_likelihood.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!-2","page":"API","title":"LowLevelParticleFilters.correct!","text":"correct!(kf::SqKalmanFilter, u, y, p = parameters(kf), t::Real = index(kf); R2 = get_mat(kf.R2, kf.x, u, p, t))\n\nFor the square-root Kalman filter, a custom provided R2 must be the upper triangular Cholesky factor of the covariance matrix of the measurement noise.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!-3","page":"API","title":"LowLevelParticleFilters.correct!","text":"(; ll, e, S, Sáµª, K) = correct!(enkf::EnsembleKalmanFilter, u, y, p = parameters(enkf), t = index(enkf) * enkf.Ts; R2 = enkf.R2)\n\nPerform the Stochastic EnKF measurement update with perturbed observations.\n\nReturns log-likelihood ll, innovation e, innovation covariance S, its Cholesky factor Sáµª, and Kalman gain K.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!-4","page":"API","title":"LowLevelParticleFilters.correct!","text":"(; ll, e, S, Sáµª, K) = correct!(kf::AbstractKalmanFilter, u, y, p = parameters(kf), t::Integer = index(kf), R2)\n\nThe correct step for a Kalman filter returns not only the log likelihood ll and the prediction error e, but also the covariance of the output S, its Cholesky factor Sáµª and the Kalman gain K.\n\nIf R2 stored in kf is a function R2(x, u, p, t), this function is evaluated at the state before the correction is performed. The measurement noise covariance matrix R2 stored in the filter object can optionally be overridden by passing the argument R2, in this case R2 must be a matrix.\n\nExtended help\n\nTo perform separate measurement updates for different sensors, see the \"Measurement models\" in the documentation.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.correct!-Tuple{IMM, Any, Any, Vararg{Any}}","page":"API","title":"LowLevelParticleFilters.correct!","text":"ll, lls, rest = correct!(imm::IMM, u, y, args; kwargs)\n\nThe correct step of the IMM filter corrects each model with the measurements y and control input u. The mixing probabilities imm.Î¼ are updated based on the likelihood of each model given the measurements and the transition probability matrix P.\n\nThe returned tuple consists of the sum of the log-likelihood of all models, the vector of individual log-likelihoods and an array of the rest of the return values from the correct step of each model.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.correct!-Tuple{SqExtendedKalmanFilter, Any, Any, Any, Real}","page":"API","title":"LowLevelParticleFilters.correct!","text":"correct!(kf::SqExtendedKalmanFilter, u, y, p, t; R2)\n\nCorrection step for the Square-root Extended Kalman Filter. Linearizes the measurement and updates the state and Cholesky factor of covariance using QR decomposition.\n\nIf a custom R2 is provided, it must be the upper triangular Cholesky factor (of type UpperTriangular) of the covariance matrix of the measurement noise.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.correct!-Tuple{UnscentedKalmanFilter, Any, Any, Any, Real}","page":"API","title":"LowLevelParticleFilters.correct!","text":"correct!(ukf::UnscentedKalmanFilter{IPD, IPM, AUGD, AUGM}, u, y, p = parameters(ukf), t::Real = index(ukf) * ukf.Ts; R2 = get_mat(ukf.R2, ukf.x, u, p, t), mean, cross_cov, innovation)\n\nThe correction step for an UnscentedKalmanFilter allows the user to override, R2, mean, cross_cov, innovation.\n\nArguments:\n\nu: The input\ny: The measurement\np: The parameters\nt: The current time\nR2: The measurement noise covariance matrix, or a function that returns the covariance matrix (x,u,p,t)->R2.\nmean: The function that computes the weighted mean of the output sigma points.\ncross_cov: The function that computes the weighted cross-covariance of the state and output sigma points.\ninnovation: The function that computes the innovation between the measured output and the predicted output.\n\nExtended help\n\nTo perform separate measurement updates for different sensors, see the \"Measurement models\" in the documentation\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.covariance-Tuple{EnsembleKalmanFilter}","page":"API","title":"LowLevelParticleFilters.covariance","text":"covariance(enkf::EnsembleKalmanFilter)\n\nReturn the cached sample covariance computed from the ensemble.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.covplot","page":"API","title":"LowLevelParticleFilters.covplot","text":"covplot(Î¼, Î£; n_std = 2, dims=1:2)\ncovplot(kf; n_std = 2, dims=1:2)\n\nPlot the covariance ellipse of the state Î¼ and covariance Î£. dims indicate the two dimensions to plot, and defaults to the first two dimensions.\n\nIf a Kalman-type filter is passed, the state and covariance are extracted from the filter.\n\nSee also unscentedplot.\n\nnote: Note\nThis function requires using Plots to be called before it is used.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.debugplot","page":"API","title":"LowLevelParticleFilters.debugplot","text":"debugplot(pf, u, y, p=parameters(pf); runall=false, kwargs...)\n\nProduce a helpful plot. For customization options (kwargs...), see ?pplot.\n\nrunall=false: if true, runs all time steps befor displaying (faster), if false, displays the plot after each time step.\n\nThe generated plot becomes quite heavy. Initially, try limiting your input to 100 time steps to verify that it doesn't crash.\n\nnote: Note\nThis function requires using Plots to be called before it is used.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.densityplot","page":"API","title":"LowLevelParticleFilters.densityplot","text":"densityplot(x,[w])\n\nPlot (weighted) particles densities\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.double_integrator_covariance","page":"API","title":"LowLevelParticleFilters.double_integrator_covariance","text":"R = double_integrator_covariance(Ts, Ïƒ2=1)\n\nReturns the covariance matrix of a discrete-time integrator with piecewise constant stochastic force as input. Ts is the sample time. Ïƒ2 scales the covariance matrix with the variance of the noise.\n\nThe state is assumed to be [x; xÌ‡] and the dynamics\n\nx^+ = Ax + Bu + w\n\nwhere the noise input w has not been included in the discretization process.\n\nThis matrix is rank deficient and some applications might require a small increase in the diagonal to make it positive definite (or use double_integrator_covariance_smooth).\n\nSee also double_integrator_covariance_smooth for the version that does not assume piecewise constant noise, leading to a full-rank covariance matrix that results in sample-time invariant covariance dynamics (often favorable).\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.double_integrator_covariance_smooth","page":"API","title":"LowLevelParticleFilters.double_integrator_covariance_smooth","text":"R = double_integrator_covariance_smooth(Ts, Ïƒ2=1)\n\nReturns the covariance matrix of a discrete-time integrator with continuous noise as input. Assumes the state [x; xÌ‡]. Ts is the sample time. Ïƒ2 scales the covariance matrix with the variance of the noise.\n\nThis matrix is full rank, but can be well approximated by a rank-1 matrix as double_integrator_covariance(Ts, Ïƒ2) ./ Ts.\n\nTo make use of a single random number per step for augmented UKFs, but be have a resulting covariance dynamics that is approximately invariant to the sample interval, you can use the scalar noise Ïƒ2 / Ts instead of this function.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.forward_trajectory","page":"API","title":"LowLevelParticleFilters.forward_trajectory","text":"sol = forward_trajectory(pf, u::AbstractVector, y::AbstractVector, p=parameters(pf))\n\nRun the particle filter for a sequence of inputs and measurements (offline / batch filtering). Return a solution with x,w,we,ll = particles, weights, expweights and loglikelihood\n\nIf MonteCarloMeasurements.jl is loaded, you may transform the output particles to Matrix{MonteCarloMeasurements.Particles} using Particles(x,we). Internally, the particles are then resampled such that they all have unit weight. This is conventient for making use of the plotting facilities of MonteCarloMeasurements.jl.\n\nsol can be plotted\n\nplot(sol::ParticleFilteringSolution; nbinsy=30, xreal=nothing, dim=nothing)\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.forward_trajectory-2","page":"API","title":"LowLevelParticleFilters.forward_trajectory","text":"sol = forward_trajectory(kf::AbstractKalmanFilter, u::Vector, y::Vector, p=parameters(kf); debug=false)\n\nRun a Kalman filter forward to perform (offline / batch) filtering along an entire trajectory u, y.\n\nReturns a KalmanFilteringSolution: with the following\n\nx: predictions x(tt-1)\nxt: filtered estimates x(tt)\nR: predicted covariance matrices R(tt-1)\nRt: filter covariances R(tt)\nll: loglik\n\nsol can be plotted\n\nplot(sol::KalmanFilteringSolution; plotx = true, plotxt=true, plotu=true, ploty=true)\n\nSee KalmanFilteringSolution for more details.\n\nExtended help\n\nVery large systems\n\nIf your system is very large, i.e., the dimension of the state is very large, and the arrays u,y are long, this function may use a lot of memory to store all covariance matrices R, Rt. If you do not need all the information retained by this function, you may opt to call one of the functions\n\nloglik\nLowLevelParticleFilters.sse\nLowLevelParticleFilters.prediction_errors!\n\nThat store significantly less information. The amount of computation performed by all of these functions is identical, the only difference lies in what is stored and returned.\n\nCallbacks\n\nFor advanced usage, such as implementing conditional resetting and adaptive covariance, one may make use of the callback functions\n\npre_correct_cb(kf, u, y, p, t): called before the correction step, returns either nothing or a covariance matrix R2 to use in the correction step.\npre_predict_cb(kf, u, y, p, t, ll, e, S, Sáµª): called before the prediction step, returns either nothing or a covariance matrix R1 to use in the prediction step. The arguments to this callback are filter, input, measurement, parameters, time, loglikelihood, prediction error, innovation covariance and Cholesky factor of the innovation covariance, essentially all the information available after the correct step.\n\nThe filter loop consists of the following steps, in this order:\n\npre_correct_cb\ncorrect!\npost_correct_cb # This callback is considered internal, the signature is subject to change. This happens after correction, but before state and covariance is saved\npre_predict_cb\npredict!\npost_predict_cb # This happens after prediction, but before next iteration when the state and covariance is saved\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.forward_trajectory-3","page":"API","title":"LowLevelParticleFilters.forward_trajectory","text":"forward_trajectory(imm::IMM, u, y, p = parameters(imm); interact = true)\n\nWhen performing batch filtering using an IMM filter, one may\n\nOverride the interact parameter of the filter\nAccess the mode probabilities along the trajectory as the sol.extra field. This is a matrix of size (n_modes, T) where T is the length of the trajectory (length of u and y).\n\nThe returned solution object is of type KalmanFilteringSolution and has the following fields:\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.interact!-Tuple{IMM}","page":"API","title":"LowLevelParticleFilters.interact!","text":"interact!(imm::IMM)\n\nThe interaction step of the IMM filter updates the state and covariance of each internal model based on the mixing probabilities imm.Î¼ and the transition probability matrix imm.P.\n\nModels with small mixing probabilities will have their states and covariances updated more towards the states and covariances of models with higher mixing probabilities, and vice versa.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.is_indexing_matrix-Tuple{AbstractMatrix}","page":"API","title":"LowLevelParticleFilters.is_indexing_matrix","text":"is_indexing_matrix(M::AbstractMatrix)\n\nCheck if a matrix is a valid indexing matrix (contains only 0s and 1s with exactly one 1 per row).\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.log_likelihood_fun-Tuple{Any, AbstractVector, Vararg{Any}}","page":"API","title":"LowLevelParticleFilters.log_likelihood_fun","text":"ll(Î¸) = log_likelihood_fun(filter_from_parameters(Î¸::Vector)::Function, priors::Vector{Distribution}, u, y, p)\nll(Î¸) = log_likelihood_fun(filter_from_parameters(Î¸::Vector)::Function, priors::Vector{Distribution}, u, y, x, p)\n\nreturns function Î¸ -> p(y|Î¸)p(Î¸)\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.loglik","page":"API","title":"LowLevelParticleFilters.loglik","text":"ll = loglik(filter, u, y, p=parameters(filter))\n\nCalculate log-likelihood for entire sequences u,y.\n\nSee also loglik_x for Kalman-type filters when an accurate state sequence x is available.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.loglik_x","page":"API","title":"LowLevelParticleFilters.loglik_x","text":"ll = loglik_x(kf, u, y, x, p=parameters(kf))\n\nFor Kalman-type filters when an accurate state sequence x is available, such as when data is obtained from a simulation or in a lab setting, the log-likelihood can be calculated using the state prediction errors rather than the output prediction errors. In this case, logpdf(f.R, x-xÌ‚) is used rather than logpdf(S, y-yÌ‚).\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.logsumexp!","page":"API","title":"LowLevelParticleFilters.logsumexp!","text":"ll = logsumexp!(w, we [, maxw])\n\nNormalizes the weight vector w and returns the weighted log-likelihood\n\nhttps://arxiv.org/pdf/1412.8695.pdf eq 3.8 for p(y) https://discourse.julialang.org/t/fast-logsumexp/22827/7?u=baggepinnen for stable logsumexp\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.mean_trajectory","page":"API","title":"LowLevelParticleFilters.mean_trajectory","text":"x,ll = mean_trajectory(pf, u::Vector{Vector}, y::Vector{Vector}, p=parameters(pf))\n\nThis method resets the particle filter to the initial state distribution upon start\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.mean_trajectory-Tuple{ParticleFilteringSolution}","page":"API","title":"LowLevelParticleFilters.mean_trajectory","text":"mean_trajectory(sol::ParticleFilteringSolution)\nmean_trajectory(x::AbstractMatrix, we::AbstractMatrix)\n\nCompute the weighted mean along the trajectory of a particle-filter solution. Returns a matrix of size T Ã— nx. If x and we are supplied, the weights are expected to be in the original space (not log space).\n\nSee also mode_trajectory\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.metropolis","page":"API","title":"LowLevelParticleFilters.metropolis","text":"metropolis(ll::Function(Î¸), R::Int, Î¸â‚€::Vector, draw::Function(Î¸) = naive_sampler(Î¸â‚€))\n\nPerforms MCMC sampling using the marginal Metropolis (-Hastings) algorithm draw = Î¸ -> Î¸' samples a new parameter vector given an old parameter vector. The distribution must be symmetric, e.g., a Gaussian. R is the number of iterations. See log_likelihood_fun\n\nExample:\n\nfilter_from_parameters(Î¸) = ParticleFilter(N, dynamics, measurement, MvNormal(n,exp(Î¸[1])), MvNormal(p,exp(Î¸[2])), d0)\npriors = [Normal(0,0.1),Normal(0,0.1)]\nll     = log_likelihood_fun(filter_from_parameters,priors,u,y,1)\nÎ¸â‚€ = log.([1.,1.]) # Initial point\ndraw = Î¸ -> Î¸ .+ rand(MvNormal(0.1ones(2))) # Function that proposes new parameters (has to be symmetric)\nburnin = 200 # If using threaded call, provide number of burnin iterations\n# @time theta, lls = metropolis(ll, 2000, Î¸â‚€, draw) # Run single threaded\n# thetam = reduce(hcat, theta)'\n@time thetalls = LowLevelParticleFilters.metropolis_threaded(burnin, ll, 5000, Î¸â‚€, draw) # run on all threads, will provide (2000-burnin)*nthreads() samples\nhistogram(exp.(thetalls[:,1:2]), layout=3)\nplot!(thetalls[:,3], subplot=3) # if threaded call, log likelihoods are in the last column\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.mode_trajectory-Tuple{ParticleFilteringSolution}","page":"API","title":"LowLevelParticleFilters.mode_trajectory","text":"mode_trajectory(sol::ParticleFilteringSolution)\nmode_trajectory(x::AbstractMatrix, we::AbstractMatrix)\n\nCompute the mode (particle with largest weight) along the trajectory of a particle-filter solution. Returns a matrix of size T Ã— nx.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.n_integrator_covariance","page":"API","title":"LowLevelParticleFilters.n_integrator_covariance","text":"R = n_integrator_covariance(n, Ts, Ïƒ2=1)\n\nReturns the covariance matrix of a discrete-time n-integrator with piecewise constant stochastic (generalized) force as input.\n\nArguments\n\nn: Order of the integrator (state dimension)\nTs: Sample time\nÏƒ2: Variance of driving noise\n\nThe state is assumed to be x; áº‹; áº; ... and the dynamics follow\n\nx^+ = Ax + Bu + w\n\nwhere the noise input w has not been included in the discretization process.\n\nThis matrix is rank deficient and some applications might require a small increase in the diagonal to make it positive definite (or use n_integrator_covariance_smooth).\n\nExample\n\nR = n_integrator_covariance(3, 0.1)  # 3rd order integrator with Ts=0.1\n\nSee also n_integrator_covariance_smooth for the version that does not assume piecewise constant noise.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.n_integrator_covariance_smooth-Union{Tuple{n}, Tuple{Val{n}, Any}, Tuple{Val{n}, Any, Any}} where n","page":"API","title":"LowLevelParticleFilters.n_integrator_covariance_smooth","text":"R = n_integrator_covariance_smooth(n, Ts, Ïƒ2=1)\nR = n_integrator_covariance_smooth(Val(n), Ts, Ïƒ2=1)\n\nReturns the covariance matrix of a discrete-time n-integrator with continuous noise as input.\n\nArguments\n\nn: Order of the integrator (state dimension), can be provided as Int or Val{n}\nTs: Sample time  \nÏƒ2: Variance of driving noise (default: 1)\n\nThe state is assumed to be x; áº‹; áº; .... This assumes continuous white noise  driving the highest derivative, integrated over the sample interval.\n\nThis matrix is full rank, which is often favorable for numerical stability. The resulting  covariance dynamics are approximately invariant to the sample interval.\n\nFormally, R is the solution to the fixed-horizon Lyapunov equation with the dynamics given by an n-th order integrator.\n\nExample\n\nR = n_integrator_covariance_smooth(3, 0.1)  # 3rd order integrator with Ts=0.1\nR = n_integrator_covariance_smooth(Val(3), 0.1)  # Compile-time known dimension\n\nSee also n_integrator_covariance for the version that assumes piecewise constant noise.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.reset!-Tuple{EnsembleKalmanFilter}","page":"API","title":"LowLevelParticleFilters.reset!","text":"reset!(enkf::EnsembleKalmanFilter; x0 = nothing)\n\nReset the ensemble to the initial distribution. If x0 is provided, the ensemble is resampled around that mean.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.reset!-Tuple{LowLevelParticleFilters.AbstractKalmanFilter}","page":"API","title":"LowLevelParticleFilters.reset!","text":"reset!(kf::AbstractKalmanFilter; x0)\n\nReset the initial distribution of the state. Optionally, a new mean vector x0 can be provided.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.reset!-Tuple{LowLevelParticleFilters.AbstractParticleFilter}","page":"API","title":"LowLevelParticleFilters.reset!","text":"Reset the filter to initial state and covariance/distribution\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.reset!-Tuple{SqKalmanFilter}","page":"API","title":"LowLevelParticleFilters.reset!","text":"reset!(kf::SqKalmanFilter; x0)\n\nReset the initial distribution of the state. Optionally, a new mean vector x0 can be provided.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.sampleplot","page":"API","title":"LowLevelParticleFilters.sampleplot","text":"sampleplot(f, u, N; plotx=true, ploty=true, alpha=0.5, dynamics_noise=true, measurement_noise=true, sample_initial=true)\n\nPlot N draws from the prior distribution encoded by filter f using input trajectory u.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.simulate","page":"API","title":"LowLevelParticleFilters.simulate","text":"x,u,y = simulate(f::AbstractFilter, T::Int, du::Distribution, p=parameters(f), [N]; dynamics_noise=true, measurement_noise=true)\nx,u,y = simulate(f::AbstractFilter, u, p=parameters(f); dynamics_noise=true, measurement_noise=true)\n\nSimulate dynamical system forward in time T steps, or for the duration of u. Returns state sequence, inputs and measurements.\n\nu is an input-signal trajectory, alternatively, du is a distribution of random inputs.\n\nA simulation can be considered a draw from the prior distribution over the evolution of the system implied by the selected noise models. Such a simulation is useful in order to evaluate whether or not the noise models are reasonable.\n\nIf MonteCarloMeasurements.jl is loaded, the argument N::Int can be supplied, in which case N simulations are done and the result is returned in the form of Vector{MonteCarloMeasurements.Particles}.\n\nSee also sampleplot for a plot recipe that automatically performs many simulations.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smooth","page":"API","title":"LowLevelParticleFilters.smooth","text":"smooth(sol, kf::SqExtendedKalmanFilter, u, y, p)\n\nPerforms Rauch-Tung-Striebel smoothing for the Square-root Extended Kalman Filter. Returns smoothed states and covariance matrices (converted from Cholesky factors).\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smooth-2","page":"API","title":"LowLevelParticleFilters.smooth","text":"sol = smooth(filtersol)\nsol = smooth(kf::AbstractKalmanFilter, u::Vector, y::Vector, p=parameters(kf))\n\nReturns a KalmanSmoothingSolution with smoothed estimates of state xT and covariance RT given all input output data u,y or an existing filtering solution filtersol obtained from forward_trajectory.\n\nThe return smoothing can be plotted using plot(sol), see KalmanSmoothingSolution and KalmanFilteringSolution for details.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smooth-3","page":"API","title":"LowLevelParticleFilters.smooth","text":"xb,ll = smooth(pf, M, u, y, p=parameters(pf))\nxb,ll = smooth(pf, xf, wf, wef, ll, M, u, y, p=parameters(pf))\n\nPerform particle smoothing using forward-filtering, backward simulation. Return smoothed particles and loglikelihood. See also smoothed_trajs, smoothed_mean, smoothed_cov\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.smoothed_cov-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.smoothed_cov","text":"smoothed_cov(xb)\n\nHelper function to calculate the covariance of smoothed particle trajectories\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.smoothed_mean-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.smoothed_mean","text":"smoothed_mean(xb)\n\nHelper function to calculate the mean of smoothed particle trajectories\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.smoothed_trajs-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.smoothed_trajs","text":"smoothed_trajs(xb)\n\nHelper function to get particle trajectories as a 3-dimensions array (N,M,T) instead of matrix of vectors.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.state-Tuple{EnsembleKalmanFilter}","page":"API","title":"LowLevelParticleFilters.state","text":"state(enkf::EnsembleKalmanFilter)\n\nReturn the cached ensemble mean (state estimate).\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.unscentedplot","page":"API","title":"LowLevelParticleFilters.unscentedplot","text":"unscentedplot(ukf;          n_std = 2, N = 100, dims=1:2)\nunscentedplot(sigmapoints;  n_std = 2, N = 100, dims=1:2)\n\nPlot the sigma points and their corresponding covariance ellipse. dims indicate the two dimensions to plot, and defaults to the first two dimensions.\n\nIf an UKF is passed, the sigma points after the last dynamics update are extracted from the filter. To plot the sigma points of the output, pass those in manually, they are available as ukf.measurement_model.cache.x0 and ukf.measurement_model.cache.x1, denoting the input and output points of the measurement model.\n\nNote: The covariance of the sigma points does not in general equal the predicted covariance of the state, since the state covariance is updated as cov(sigmapoints) + R1. Only when AUGD = true (augmented dynamics), the covariance of the state is given by the first nx sigmapoints.\n\nSee also covplot.\n\nnote: Note\nThis function requires using Plots to be called before it is used.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.update!","page":"API","title":"LowLevelParticleFilters.update!","text":"update!(enkf::EnsembleKalmanFilter, u, y, p = parameters(enkf), t = index(enkf) * enkf.Ts)\n\nPerform one filtering step: correct followed by predict.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.update!-2","page":"API","title":"LowLevelParticleFilters.update!","text":"ll, e = update!(f::AbstractFilter, u, y, p = parameters(f), t = index(f))\n\nPerform one step of predict! and correct!, returns log-likelihood and prediction error\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.update!-Tuple{IMM, Any, Any, Vararg{Any}}","page":"API","title":"LowLevelParticleFilters.update!","text":"update!(imm::IMM, u, y, p, t; correct_kwargs = (;), predict_kwargs = (;), interact = true)\n\nThe combined udpate for an IMM filter performs the following steps:\n\nCorrect each model with the measurements y and control input u.\nCombine the models into a single state and covariance.\nInteract the models to update their respective state and covariance.\nPredict each model to the next time step.\n\nThis differs slightly from the udpate step of other filters, where at the end of an update the state of the filter is the one-step ahead predicted value, whereas here each individual filter has a predicted state, but the combine! step of the IMM filter hasn't been performed on the predictions yet. The state of the IMM filter is thus x(tt) and not x(t+1t) like it is for other filters, and each filter internal to the IMM.\n\nArguments:\n\ncorrect_kwargs: An optional named tuple of keyword arguments that are sent to correct!.\npredict_kwargs: An optional named tuple of keyword arguments that are sent to predict!.\ninteract: Whether or not to run the interaction step.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.validationplot","page":"API","title":"LowLevelParticleFilters.validationplot","text":"validationplot(sol::KalmanFilteringSolution)\n\nPerform statistical validation of Kalman filter performance by analyzing the innovation sequence.\n\nCreates a 4-subplot figure with the following diagnostics:\n\nRoot Mean Square (RMS) of Innovation: Shows the RMS value for each output dimension.\nLower values indicate better filter performance\nNormalized Innovation Squared (NIS): Plots NIS over time with 95% confidence bounds\nNIS = e(t) * S(t)Â¹ * e(t) where e is innovation and S is innovation covariance\nShould follow a chi-squared distribution with n_y degrees of freedom\nPoints consistently outside bounds indicate filter mistuning (wrong R1 or R2)\nAutocorrelation of Innovation: Shows autocorrelation vs lag with white noise bounds\nInnovations should be white (uncorrelated over time)\nAutocorrelation outside Â±1.96/âˆšT bounds indicates filter issues\nHigh autocorrelation suggests model mismatch or underestimated noise\nCross-correlation between Innovation and Past Inputs: Shows correlation vs lag\nShould be near zero at all lags (innovations independent of past inputs)\nCorrelation outside Â±1.96/âˆšT bounds indicates model errors\nNon-zero cross-correlation suggests incorrect system model\n\nUsage\n\nusing Plots, Distributions\nsol = forward_trajectory(kf, u, y)\nvalidationplot(sol)\n\nnote: Requires Distributions.jl\nThis function requires Distributions.jl to be manually installed and loaded.\n\n\n\n\n\n","category":"function"},{"location":"api/#LowLevelParticleFilters.weighted_cov-Tuple{Any, Any}","page":"API","title":"LowLevelParticleFilters.weighted_cov","text":"weighted_cov(x,we)\n\nSimilar to weighted_mean, but returns covariances\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.weighted_mean-Tuple{Any, AbstractVector}","page":"API","title":"LowLevelParticleFilters.weighted_mean","text":"xÌ‚ = weighted_mean(x,we)\n\nCalculated weighted mean of particle trajectories. we are expweights.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.weighted_mean-Tuple{Any}","page":"API","title":"LowLevelParticleFilters.weighted_mean","text":"xÌ‚ = weighted_mean(pf)\nxÌ‚ = weighted_mean(s::PFstate)\n\nSee also mean_trajectory\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.weighted_quantile-Tuple{Any, Any, Any}","page":"API","title":"LowLevelParticleFilters.weighted_quantile","text":"weighted_quantile(x,we,q)\nweighted_quantile(sol,q)\n\nCalculated weighted quantile q of particle trajectories. we are expweights. Returns a vector of length size(x, 2) where each entry has length nx. For a particle-filtering solution, this means the vector will be as long as the number of time steps in the solution.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict!","page":"API","title":"StatsAPI.predict!","text":"predict!(kf::AbstractKalmanFilter, u, p = parameters(kf), t::Integer = index(kf); R1, Î± = kf.Î±)\n\nPerform the prediction step (updating the state estimate to x(t+1t)). If R1 stored in kf is a function R1(x, u, p, t), this function is evaluated at the state before the prediction is performed. The dynamics noise covariance matrix R1 stored in kf can optionally be overridden by passing the argument R1, in this case R1 must be a matrix.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict!-2","page":"API","title":"StatsAPI.predict!","text":"predict!(f, u, p = parameters(f), t = index(f))\n\nMove filter state forward in time using dynamics equation and input vector u.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict!-3","page":"API","title":"StatsAPI.predict!","text":"predict!(kf::SqKalmanFilter, u, p = parameters(kf), t::Real = index(kf); R1 = get_mat(kf.R1, kf.x, u, p, t), Î± = kf.Î±)\n\nFor the square-root Kalman filter, a custom provided R1 must be the upper triangular Cholesky factor of the covariance matrix of the process noise.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict!-4","page":"API","title":"StatsAPI.predict!","text":"predict!(enkf::EnsembleKalmanFilter, u, p = parameters(enkf), t = index(enkf) * enkf.Ts; R1 = enkf.R1, inflation = enkf.inflation)\n\nPropagate each ensemble member through the dynamics with process noise.\n\n\n\n\n\n","category":"function"},{"location":"api/#StatsAPI.predict!-Union{Tuple{CF}, Tuple{MF}, Tuple{AUGM}, Tuple{AUGD}, Tuple{IPM}, Tuple{IPD}, Tuple{UnscentedKalmanFilter{IPD, IPM, AUGD, AUGM}, Any}, Tuple{UnscentedKalmanFilter{IPD, IPM, AUGD, AUGM}, Any, Any}, Tuple{UnscentedKalmanFilter{IPD, IPM, AUGD, AUGM}, Any, Any, Real}} where {IPD, IPM, AUGD, AUGM, MF, CF}","page":"API","title":"StatsAPI.predict!","text":"predict!(ukf::UnscentedKalmanFilter, u, p = parameters(ukf), t::Real = index(ukf) * ukf.Ts; R1 = get_mat(ukf.R1, ukf.x, u, p, t), reject, mean, cov, dynamics)\n\nThe prediction step for an UnscentedKalmanFilter allows the user to override, R1 and any of the functions, reject, mean, cov, dynamics`.\n\nArguments:\n\nu: The input\np: The parameters\nt: The current time\nR1: The dynamics noise covariance matrix, or a function that returns the covariance matrix.\nreject: A function that takes a sigma point and returns true if it should be rejected.\nmean: The function that computes the mean of the state sigma points.\ncov: The function that computes the covariance of the state sigma points.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.predict!-Union{Tuple{IPD}, Tuple{SqExtendedKalmanFilter{IPD}, Any}, Tuple{SqExtendedKalmanFilter{IPD}, Any, Any}, Tuple{SqExtendedKalmanFilter{IPD}, Any, Any, Real}} where IPD","page":"API","title":"StatsAPI.predict!","text":"predict!(kf::SqExtendedKalmanFilter, u, p, t; R1, Î±)\n\nPrediction step for the Square-root Extended Kalman Filter. Linearizes the dynamics and updates the state and Cholesky factor of covariance using QR decomposition.\n\nIf a custom R1 is provided, it must be the upper triangular Cholesky factor (of type UpperTriangular) of the covariance matrix of the process noise.\n\n\n\n\n\n","category":"method"},{"location":"api/#LowLevelParticleFilters.prediction_errors!","page":"API","title":"LowLevelParticleFilters.prediction_errors!","text":"prediction_errors!(res, f::AbstractFilter, u, y, p = parameters(f), Î» = 1; loglik = false)\n\nCalculate the prediction errors and store the result in res. Similar to sse, this function is useful for sum-of-squares optimization. In contrast to sse, this function returns the residuals themselves rather than their sum of squares. This is useful for Gauss-Newton style optimizers, such as LeastSquaresOptim.LevenbergMarquardt.\n\nArguments:\n\nres: A vector of length ny*length(y). Note, for each datapoint in u and u, there are ny outputs, and thus ny residuals. If loglik = true, the length of res must be length(y)*(ny+1), since an extra residual is added for the log-determinant term.\nf: Any Kalman type filter\nÎ»: A weighting factor to minimize dot(e, Î», e). A commonly used metric is Î» = Diagonal(1 ./ (mag.^2)), where mag is a vector of the \"typical magnitude\" of each output. Internally, the square root of W = sqrt(Î») is calculated so that the residuals stored in res are W*e.\nloglik: If true, the residuals are calculated as Sáµª\u001b, where Sáµª is the Cholesky factor of the innovation covariance. This turns least-squares optimization into maximum likelihood estimation. When this is true, the Î» argument is ignored and the length of res must be length(y)*(ny+1), where an extra residual per time step is added for the log-determinant term.\noffset: When using loglik = true, an offset may be added to the log-determinant term to avoid negative values inside the square root. The result of adding this offset is that the log-liklihood is shifted by a constant value, which does not affect optimization.\n\nSee example in Solving using Gauss-Newton optimization.\n\n\n\n\n\n","category":"function"},{"location":"param_est_mukf/#Joint-state-and-parameter-estimation-using-MUKF","page":"MUKF for parameter estimation","title":"Joint state and parameter estimation using MUKF","text":"The MUKF (Marginalized Unscented Kalman Filter) is an estimator particularily well suited to joint state and parameter estimation.  When parameters have linear time evolution and enter multiplicatively into the system dynamics, MUKF explicitly separates the nonlinear state variables from linearly-evolving variables, leading to:\n\nDeterministic estimation: No particle randomness like for particle filters, making it suitable for gradient-based optimization of hyperparameters\nComputational efficiency: Uses fewer sigma points than UKF for the same state dimension","category":"section"},{"location":"param_est_mukf/#Problem:-Quadrotor-with-Unknown-Mass-and-Drag","page":"MUKF for parameter estimation","title":"Problem: Quadrotor with Unknown Mass and Drag","text":"We consider a simplified quadrotor model where the mass and drag coefficient are unknown and time-varying. By cleverly partitioning the state using reparameterizations theta = 1m and varphi = theta C_d, we exploit a conditionally linear structure to achieve significant computational savings.\n\nThe system has 8 state dimensions total with the following partitioning:\n\nNonlinear substate (3D): velocities v_x v_y v_z\nLinear substate (5D): positions x y z, inverse mass theta = 1m, and mass-scaled drag varphi = theta C_d\n\nThe key insight is that positions evolve linearly given the velocities (dotx = v_x), and velocity dynamics depend linearly on both theta and varphi. This clever parameterization reduces sigma points from 17 (for full 8D UKF) to only 7 (for 3D nonlinear MUKF).\n\nThe physical dynamics are:\n\nbeginaligned\ndotx = v_x quad doty = v_y quad dotz = v_z \ndotv_x = fracF_x - C_d cdot v_x v_xm quad\ndotv_y = fracF_y - C_d cdot v_y v_ym quad\ndotv_z = fracF_z - C_d cdot v_z v_zm - g\nendaligned\n\nUsing the inverse mass parameterization theta = 1m and defining varphi = theta C_d, we can rewrite the velocity dynamics as:\n\nbeginaligned\ndotv_x = theta F_x - varphi v_x v_x quad\ndotv_y = theta F_y - varphi v_y v_y quad\ndotv_z = theta F_z - varphi v_z v_z - g\nendaligned\n\nThis reveals the conditionally linear structure: the velocity derivatives depend linearly on both theta and varphi, while positions evolve as dotx = v_x (linear dependence on velocities). The drag coefficient can be recovered as C_d = varphi  theta when needed. Since theta = 1m  0, this division is well defined as long as the estimate of theta is reasonable.\n\nusing LowLevelParticleFilters\nusing SeeToDee\nusing Distributions\nusing StaticArrays\nusing Plots, LinearAlgebra, Random\nRandom.seed!(0) # For reproducibility\n\n# System dimensions\nnxn = 3  # Nonlinear state: [vx, vy, vz] (velocities only)\nnxl = 5  # Linear state: [x, y, z, Î¸, Ï†] where Î¸ = 1/m, Ï† = Î¸*Cd\nnx = nxn + nxl\nnu = 3   # Control inputs: [Fx, Fy, Fz] (thrust forces)\nny = 6   # Measurements: [x, y, z, vx, vy, vz] (GPS + velocity)\n\n# Physical constants\ng = 9.81    # Gravity (m/sÂ²)\nTs = 0.02   # Sample time\n\nnothing # hide\n\nWe'll simulate a scenario where:\n\nMass decreases linearly from 1.0 to 0.85 kg (fuel drain)\nDrag increases abruptly at t=50s from 0.01 to 0.015 (damage/configuration change)","category":"section"},{"location":"param_est_mukf/#MUKF-Formulation-with-Conditionally-Linear-Structure","page":"MUKF for parameter estimation","title":"MUKF Formulation with Conditionally Linear Structure","text":"By using the parameterization theta = 1m and varphi = theta C_d, we exploit the conditionally linear structure from Morelande & Moran (2007), which has the form:\n\n$\n\n\\dot{x} = d(x^n) + A(x^n)x^l = \\begin{aligned} \\dot{x}^n &= dn(x^n) + An(x^n) x^l \\\n\\dot{x}^l &= dl(x^n) + Al(x^n) x^l \\end{aligned} $\n\nwhere x^n = v_x v_y v_z and x^l = x y z theta varphi. The coupling matrix A_n(x^n) is 3 times 5 and captures how theta scales the thrust forces and varphi scales the drag forces. The term d_l(x^n) = v_x v_y v_z 0 0 captures how positions depend on velocities.\n\nThis clever parameterization reduces the number of sigma points from 17 (for a full 8D UKF with 2nx+1 = 2Ã—8+1) to only 7 (for a 3D nonlinear MUKF with 2Ã—3+1), a 59% reduction. Unscented Kalman filters internally perform a Cholesky factorization of the covariance matrix (to compute sigma points), which scales roughly cubically with state dimension, but the MUKF gets away with factorizing only the part of the covariance corresponding to the nonlinear substate, leading to further computational savings.\n\n# Nonlinear dynamics function returns [dn; dl] where:\n# - dn: uncoupled part of nonlinear state dynamics\n# - dl: part of linear state dynamics that depends on nonlinear state\nfunction quadrotor_nonlinear_dynamics(xn, u, p, t)\n    vx, vy, vz = xn\n    Fx, Fy, Fz = u\n\n    # Nonlinear state dynamics (uncoupled part)\n    # vÌ‡ = dn + An*xl where xl = [x,y,z,Î¸,Ï†]\n    dn = SA[\n        0.0,     # vÌ‡x base (thrust/drag coupling through An)\n        0.0,     # vÌ‡y base\n        -g       # vÌ‡z base (gravity is independent of Î¸ and Ï†)\n    ]\n\n    # Linear state dynamics (part depending on xn)\n    # áº‹, áº, Å¼ = velocities, Î¸Ì‡ = 0, Ï†Ì‡ = 0\n    dl = SA[vx, vy, vz, 0.0, 0.0]\n\n    return [dn; dl]  # Return 8D vector\nend\n\n# Coupling matrix An: how linear state [x,y,z,Î¸,Ï†] affects nonlinear state [vx,vy,vz]\n# Î¸ scales thrust forces, Ï† scales drag forces: vÌ‡ = Î¸*F - Ï†*v|v|\nfunction An_matrix(xn, u, p, t)\n    vx, vy, vz = xn\n    Fx, Fy, Fz = u\n\n    # 3Ã—5 matrix: positions don't couple, Î¸ and Ï† do\n    SA[\n        0.0  0.0  0.0  Fx        -vx*abs(vx)    # vÌ‡x = Î¸*Fx - Ï†*vx|vx|\n        0.0  0.0  0.0  Fy        -vy*abs(vy)    # vÌ‡y = Î¸*Fy - Ï†*vy|vy|\n        0.0  0.0  0.0  Fz        -vz*abs(vz)    # vÌ‡z = Î¸*Fz - Ï†*vz|vz| - g\n    ]\nend\n\n# Discrete coupling matrix (scaled by sampling time)\nAn_matrix_discrete(xn, u, p, t) = An_matrix(xn, u, p, t) * Ts\n\n# Linear state evolution for discrete-time filter\n# Al = I to carry over state from previous time step: xl[k+1] = xl[k] + Ts*dl(xn[k])\nAl_discrete = SMatrix{nxl, nxl}(I(nxl))\n\n# Combined A matrix for MUKF: A = [An; Al] (nx Ã— nxl)\nA_matrix_discrete(xn, u, p, t) = [An_matrix_discrete(xn, u, p, t); Al_discrete]\n\n# Measurement: we measure [x,y,z,vx,vy,vz]\n# This comes from d(xn) + Cl*xl where xl = [x,y,z,Î¸,Ï†]\nmeasurement(xn, u, p, t) = SA[0.0, 0.0, 0.0, xn[1], xn[2], xn[3]]  # [0,0,0,vx,vy,vz]\nCl = SA[\n    1.0  0.0  0.0  0.0  0.0    # x measurement\n    0.0  1.0  0.0  0.0  0.0    # y measurement\n    0.0  0.0  1.0  0.0  0.0    # z measurement\n    0.0  0.0  0.0  0.0  0.0    # vx measurement (from xn)\n    0.0  0.0  0.0  0.0  0.0    # vy measurement (from xn)\n    0.0  0.0  0.0  0.0  0.0    # vz measurement (from xn)\n]\n\n# Discretize the nonlinear dynamics for the MUKF\ndiscrete_nonlinear_dynamics(x,u,p,t) = [x; @SVector(zeros(5))] + Ts .* quadrotor_nonlinear_dynamics(x,u,p,t)\n\nnothing # hide","category":"section"},{"location":"param_est_mukf/#Simulation","page":"MUKF for parameter estimation","title":"Simulation","text":"We'll simulate a hovering scenario with small perturbations, where the mass decreases (fuel drain) and drag increases abruptly (damage).\n\nTf = 50  # 50 seconds at 0.01s sampling\nt_vec = range(0, stop=Tf, step=Ts)\nT = length(t_vec)\n\n# Control: hovering thrust with small variations\nm_nominal = 1.0\nF_hover = m_nominal * g\nu = [SA[F_hover + 0.1*randn(), F_hover + 0.1*randn(), F_hover + 0.1*randn()] for _ in eachindex(t_vec)]\n\n# True parameters (time-varying)\nm_true = [t < 25 ? 1.0 - 0.006*t : 0.85 for t in t_vec]  # Linear decrease\nÎ¸_true = 1.0 ./ m_true                                    # Inverse mass\nCd_true = [t < 25 ? 0.01 : 0.015 for t in t_vec]         # Abrupt increase\nÏ†_true = Î¸_true .* Cd_true                                 # Scaled drag Ï† = Î¸*Cd\n\n# Simulate true trajectory using known true parameters\nfunction simulate_quadrotor(u, Î¸_true, Cd_true)\n    # Define continuous dynamics with true parameters\n    function dynamics_true(x_state, u_inner, p_inner, t_inner)\n        Î¸_i, Cd_i = p_inner\n        vx_s, vy_s, vz_s, px_s, py_s, pz_s = x_state\n        Fx, Fy, Fz = u_inner\n        SA[\n            # Velocity derivatives: vÌ‡ = Î¸*(F - Cd*v|v|) - g_z\n            Î¸_i * (Fx - Cd_i * vx_s * abs(vx_s)),\n            Î¸_i * (Fy - Cd_i * vy_s * abs(vy_s)),\n            Î¸_i * (Fz - Cd_i * vz_s * abs(vz_s)) - g,\n            # Position derivatives: áº‹ = v\n            vx_s,\n            vy_s,\n            vz_s\n        ]\n    end\n    discrete_step = SeeToDee.Rk4(dynamics_true, Ts)\n\n    x = zeros(T, nx)  # Full state: [vx,vy,vz,x,y,z,Î¸,Ï†]\n    Ï†_0 = Î¸_true[1] * Cd_true[1]\n    x[1, :] = [0, 0, 0, 0, 0, 10, Î¸_true[1], Ï†_0]  # Start at 10m altitude, zero velocity\n\n    for i in 1:T-1\n        vx, vy, vz = x[i, 1], x[i, 2], x[i, 3]\n        pos_x, pos_y, pos_z = x[i, 4], x[i, 5], x[i, 6]\n\n        # Use true parameter values at this time step\n        Î¸_i = Î¸_true[i]\n        Cd_i = Cd_true[i]\n\n        p = [Î¸_i, Cd_i]\n        # Integrate 6D state [vx,vy,vz,x,y,z] with true parameters\n        state_6d = SA[vx, vy, vz, pos_x, pos_y, pos_z]\n        state_next = discrete_step(state_6d, u[i], p, 0)\n\n        # Store next state including parameters\n        Ï†_next = Î¸_true[i+1] * Cd_true[i+1]\n        x[i+1, :] = [state_next[1], state_next[2], state_next[3],  # vx,vy,vz\n                     state_next[4], state_next[5], state_next[6],  # x,y,z\n                     Î¸_true[i+1], Ï†_next]                           # Î¸,Ï†\n    end\n    return x\nend\n\nx_true = simulate_quadrotor(u, Î¸_true, Cd_true)\n\n# Extract measurement components: [x,y,z,vx,vy,vz] from state [vx,vy,vz,x,y,z,Î¸,Ï†]\ny_true = [SA[x_true[i, 4], x_true[i, 5], x_true[i, 6],  # x,y,z\n              x_true[i, 1], x_true[i, 2], x_true[i, 3]]  # vx,vy,vz\n          for i in eachindex(t_vec)]\n\n# Add measurement noise\ny = [y_true[i] .+ 0.01 .* @SVector(randn(ny)) for i in eachindex(t_vec)]\n\n# Plot true trajectory and parameters\np1 = plot(t_vec, x_true[:, 6], label=\"Altitude (z)\", xlabel=\"Time (s)\", ylabel=\"m\", legend=:topright)\np2 = plot(t_vec, m_true, label=\"Mass\", xlabel=\"Time (s)\", ylabel=\"kg\", legend=:topright, c=:blue)\np3 = plot(t_vec, Cd_true, label=\"Drag\", ylabel=\"kgÂ·s/m\", c=:red)\nplot(p1, p2, p3)","category":"section"},{"location":"param_est_mukf/#MUKF-Setup-and-Estimation","page":"MUKF for parameter estimation","title":"MUKF Setup and Estimation","text":"Now we set up the MUKF, which takes mostly the same configutation options as an UnscentedKalmanFilter\n\n# Noise covariances\nR1n = SMatrix{nxn,nxn}(Diagonal([0.01, 0.01, 0.01]))  # Process noise for [vx,vy,vz]\nR1l = SMatrix{nxl,nxl}(Diagonal([0.01, 0.01, 0.01, 0.0001, 0.000001]))   # Process noise for [x,y,z,Î¸,Ï†]\nR1 = [[R1n zeros(SMatrix{nxn,nxl})]; [zeros(SMatrix{nxl,nxn}) R1l]]\n\nR2 = SMatrix{ny,ny}(Diagonal([0.1, 0.1, 0.1, 0.05, 0.05, 0.05]))  # Measurement noise\n\n# Initial state estimate (slightly wrong)\nm_guess = 0.9  # Wrong mass guess\nÎ¸_guess = 1.0 / m_guess\nCd_guess = 0.008  # Wrong Cd guess\nÏ†_guess = Î¸_guess * Cd_guess  # Ï† = Î¸*Cd\nx0n = SA[0.0, 0.0, 0.0]  # [vx,vy,vz]\nx0l = SA[0.0, 0.0, 10.0, Î¸_guess, Ï†_guess]  # [x,y,z,Î¸,Ï†]\nx0_full = [x0n; x0l]\n\nR0n = SMatrix{nxn,nxn}(Diagonal([0.5, 0.5, 0.5]))  # Uncertainty in velocities\nR0l = SMatrix{nxl,nxl}(Diagonal([1.0, 1.0, 1.0, 0.01, 0.0001]))    # Uncertainty in positions, Î¸, and Ï†\nR0_full = [[R0n zeros(SMatrix{nxn,nxl})]; [zeros(SMatrix{nxl,nxn}) R0l]]\n\nd0 = LowLevelParticleFilters.SimpleMvNormal(x0_full, R0_full)\n\n# Create measurement model\nmm = RBMeasurementModel(measurement, R2, ny)\n\n# Create MUKF\nmukf = MUKF(;\n    dynamics = discrete_nonlinear_dynamics,  # Returns [dn; dl]\n    nl_measurement_model = mm,\n    A = A_matrix_discrete,    # Combined coupling and dynamics matrix [An; Al]\n    Cl,\n    R1,\n    d0,\n    nxn,\n    nu,\n    ny,\n    Ts,\n)\n\n# Run estimation\nsol_mukf = forward_trajectory(mukf, u, y)\n\n# Extract estimates\nx_est_mukf = reduce(hcat, sol_mukf.xt)'\nÎ¸_est_mukf = x_est_mukf[:, 7]  # Î¸ is the 7th state\nÏ†_est_mukf = x_est_mukf[:, 8]  # Ï† is the 8th state\nm_est_mukf = 1.0 ./ Î¸_est_mukf  # Convert back to mass\nCd_est_mukf = Ï†_est_mukf ./ Î¸_est_mukf  # Recover Cd = Ï†/Î¸\n\nnothing # hide","category":"section"},{"location":"param_est_mukf/#Results-and-Comparison","page":"MUKF for parameter estimation","title":"Results and Comparison","text":"Let's visualize the parameter estimation performance:\n\n# Plot parameter estimates\np1 = plot(t_vec, m_true, label=\"True mass\", lw=2, xlabel=\"Time (s)\", ylabel=\"Mass (kg)\",\n          legend=:topright, c=:black, ls=:dash)\nplot!(p1, t_vec, m_est_mukf, label=\"MUKF estimate\", lw=2, c=:blue)\n\np2 = plot(t_vec, Cd_true, label=\"True drag\", lw=2, xlabel=\"Time (s)\", ylabel=\"Drag coeff (kgÂ·s/m)\",\n          legend=:topleft, c=:black, ls=:dash)\nplot!(p2, t_vec, Cd_est_mukf, label=\"MUKF estimate\", lw=2, c=:blue)\n\nplot(p1, p2, layout=(2,1), size=(800,500))\n\nThe MUKF successfully tracks both parameters through the gradual mass decrease and the abrupt drag increase at t=50s. The estimation converges quickly from the initial guess.","category":"section"},{"location":"param_est_mukf/#Comparison-with-UKF-Approach","page":"MUKF for parameter estimation","title":"Comparison with UKF Approach","text":"For comparison, let's solve the same problem using a standard UKF with the full 8D state (no exploitation of conditionally linear structure):\n\n# For UKF, treat the entire 8D state uniformly (no structure exploitation)\nfunction quadrotor_dynamics_ukf(x_full, u, p, t)\n    xn = x_full[1:nxn]  # [vx,vy,vz]\n    xl = x_full[nxn+1:end]  # [x,y,z,Î¸,Ï†]\n\n    # Get dynamics and coupling\n    dyn = quadrotor_nonlinear_dynamics(xn, u, nothing, 0)\n    An = An_matrix(xn, u, nothing, 0)\n\n    # Full derivative\n    [dyn[1:nxn] + An * xl; dyn[nxn+1:end]]\nend\n\ndiscrete_dynamics_ukf = SeeToDee.Rk4(quadrotor_dynamics_ukf, Ts)\nmeasurement_ukf(x, u, p, t) = SA[x[4], x[5], x[6], x[1], x[2], x[3]]  # [x,y,z,vx,vy,vz]\n\nR1_ukf = Diagonal([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0001, 0.000001])\nR2_ukf = R2\n\nukf = UnscentedKalmanFilter(\n    discrete_dynamics_ukf,\n    measurement_ukf,\n    R1_ukf,\n    R2_ukf,\n    MvNormal(x0_full, R0_full);\n    ny = ny,\n    nu = nu,\n    Ts = Ts\n)\n\nsol_ukf = forward_trajectory(ukf, u, y)\n\n# Extract UKF estimates\nx_est_ukf = reduce(hcat, sol_ukf.xt)'\nÎ¸_est_ukf = x_est_ukf[:, 7]  # Î¸ is the 7th state\nÏ†_est_ukf = x_est_ukf[:, 8]  # Ï† is the 8th state\nm_est_ukf = 1.0 ./ Î¸_est_ukf  # Convert back to mass\nCd_est_ukf = Ï†_est_ukf ./ Î¸_est_ukf  # Recover Cd = Ï†/Î¸\n\n# Compare the two approaches\np1 = plot(t_vec, m_true, label=\"True\", lw=2, xlabel=\"Time (s)\", ylabel=\"Mass (kg)\",\n          legend=:topright, c=:black, ls=:dash, title=\"Mass Estimation\")\nplot!(p1, t_vec, m_est_mukf, label=\"MUKF\", lw=2, c=:blue, alpha=0.7)\nplot!(p1, t_vec, m_est_ukf, label=\"UKF\", lw=2, c=:green, alpha=0.7, ls=:dot)\n\np2 = plot(t_vec, Cd_true, label=\"True\", lw=2, xlabel=\"Time (s)\", ylabel=\"Drag coeff\",\n          legend=:topleft, c=:black, ls=:dash, title=\"Drag Estimation\")\nplot!(p2, t_vec, Cd_est_mukf, label=\"MUKF\", lw=2, c=:blue, alpha=0.7)\nplot!(p2, t_vec, Cd_est_ukf, label=\"UKF\", lw=2, c=:green, alpha=0.7, ls=:dot)\n\nplot(p1, p2, layout=(2,1), size=(800,500))","category":"section"},{"location":"param_est_mukf/#Performance-Analysis","page":"MUKF for parameter estimation","title":"Performance Analysis","text":"Let's quantify the estimation accuracy:\n\nusing Statistics\n\n# Compute RMSE for parameters (excluding initial transient)\ntransient = 500  # Exclude first 5 seconds\nrmse_m_mukf = sqrt(mean((m_true[transient:end] - m_est_mukf[transient:end]).^2))\nrmse_Cd_mukf = sqrt(mean((Cd_true[transient:end] - Cd_est_mukf[transient:end]).^2))\n\nrmse_m_ukf = sqrt(mean((m_true[transient:end] - m_est_ukf[transient:end]).^2))\nrmse_Cd_ukf = sqrt(mean((Cd_true[transient:end] - Cd_est_ukf[transient:end]).^2))\n\nprintln(\"MUKF - Mass RMSE: $(round(rmse_m_mukf, digits=4)) kg\")\nprintln(\"MUKF - Drag RMSE: $(round(rmse_Cd_mukf, digits=6)) kgÂ·s/m\")\nprintln()\nprintln(\"UKF  - Mass RMSE: $(round(rmse_m_ukf, digits=4)) kg\")\nprintln(\"UKF  - Drag RMSE: $(round(rmse_Cd_ukf, digits=6)) kgÂ·s/m\")\n\nBoth filters perform comparably in terms of accuracy. However, MUKF uses only 7 sigma points (2Ã—3+1 for 3D nonlinear state) compared to UKF's 17 sigma points (2Ã—8+1 for 8D full state), a 59% reduction illustrating the computational benefit of exploiting the conditionally linear structure with the Ï† = Î¸Â·Cd parameterization.\n\nWe should note here that we have performed slightly different discretizations of the dynamics for the UKF and the MUKF. With the standard UKF, we discretized the entire dynamics using an RK4 method, a very accurate integrator in this context. For the MUKF, we instead discretized the dynamics using a simple forward Euler discretization (by multiplying A_n and the output of quadrotor_nonlinear_dynamics by T_s). The reason for this discrepancy is that the conditional linearity that holds for this system in continuous time no longer holds after discretization, unless we use forward Euler discretization, which is the only scheme simple enough to not mess with the linearity. This primitive discretization is often sufficient for state estimation when sample intervals are short, which they tend to be when controlling quadrotors. See the note under Discretization for more comments regarding accuracy of integration for state estimation.\n\nIn special cases, more accurate integration is possible also for MUKF estimators. For example, when d_l(x^n) = 0, the linear state evolves purely linearly as x^l_k+1 = A_l x^l_k, and we can use the matrix exponential to compute a discretized A_l. When A_n = 0, the nonlinear state evolves purely nonlinearly as x^n_k+1 = f(x^n_k u_k), and we can use any accurate integrator for this part. Even when A_n neq 0, we could treat the linear part of the nonlinear state evolution A_n x^l as an additional input to the nonlinear dynamics and use an accurate integrator for this part, this is not yet implemented due to the added complexity it would bring.","category":"section"},{"location":"adaptive_control/#Adaptive-Estimation-and-Control","page":"Adaptive estimation and control","title":"Adaptive Estimation and Control","text":"This tutorial is hosted as a notebook.\n\nIt also has an associated video:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/Ip_prmA7QTU?si=Fat_srMTQw5JtW2d\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"section"},{"location":"param_est_ml/#Maximum-likelihood-and-MAP-estimation","page":"Maximum-likelihood and MAP","title":"Maximum-likelihood and MAP estimation","text":"Filters calculate the likelihood and prediction errors while performing filtering, this can be used to perform maximum likelihood estimation or prediction-error minimization. One can estimate all kinds of parameters using this method, in the example below, we will estimate the noise covariance. The tutorial on this page focuses on problems where the number of parameters is so small that we can visualize the likelihood function, for higher-dimensional problems, see Using an optimizer.\n\nWe start by generating some data by simulating a two-dimensional linear system with known dynamics parameters, where we will attempt to optimize the dynamics noise covariance using maximum likelihood and MAP estimation.","category":"section"},{"location":"param_est_ml/#Generate-data-by-simulation","page":"Maximum-likelihood and MAP","title":"Generate data by simulation","text":"This simulates the same linear system as on the index page of the documentation\n\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots\nnx = 2   # Dimension of state\nnu = 2   # Dimension of input\nny = 2   # Dimension of measurements\nN = 2000 # Number of particles\n\nconst dg = MvNormal(ny,1.0)          # Measurement noise Distribution\nconst df = MvNormal(nx,1.0)          # Dynamics noise Distribution\nconst d0 = MvNormal(@SVector(randn(nx)),2.0)   # Initial state Distribution\n\nconst A = SA[1 0.1; 0 1]\nconst B = @SMatrix [0.0 0.1; 1 0.1]\nconst C = @SMatrix [1.0 0; 0 1]\n\ndynamics(x,u,p,t) = A*x .+ B*u\nmeasurement(x,u,p,t) = C*x\nvecvec_to_mat(x) = copy(reduce(hcat, x)') # Helper function\npf = ParticleFilter(N, dynamics, measurement, df, dg, d0)\nxs,u,y = simulate(pf,300,df)","category":"section"},{"location":"param_est_ml/#Compute-likelihood-for-various-values-of-the-parameters","page":"Maximum-likelihood and MAP","title":"Compute likelihood for various values of the parameters","text":"Since this example looks for a single parameter only, we can plot the likelihood as a function of this parameter. If we had been looking for more than 2 parameters, we typically use an optimizer instead (see Using an optimizer).\n\np = nothing\nsvec = exp10.(LinRange(-0.8, 1.2, 60))\nllspf = map(svec) do s\n    df = MvNormal(nx,s)\n    pfs = ParticleFilter(N, dynamics, measurement, df, dg, d0)\n    loglik(pfs, u, y, p)\nend\nllspfaux = map(svec) do s\n    df = MvNormal(nx,s)\n    pfs = AuxiliaryParticleFilter(N, dynamics, measurement, df, dg, d0)\n    loglik(pfs, u, y, p)\nend\nplot( svec, llspf,\n    xscale = :log10,\n    title = \"Log-likelihood\",\n    xlabel = \"Dynamics noise standard deviation\",\n    lab = \"PF\",\n)\nplot!(svec, llspfaux, yscale=:identity, xscale=:log10, lab=\"AUX PF\", c=:green)\nvline!([svec[findmax(llspf)[2]]], l=(:dash,:blue), primary=false)\n\nthe correct value for the simulated data is 1 (the simulated system is the same as on the front page of the docs).\n\nWe can do the same with a Kalman filter, shown below. When using Kalman-type filters, one may also provide a known state sequence if one is available, such as when the data is obtained from a simulation or in an instrumented lab setting. If the state sequence is provided, state-prediction errors are used for log-likelihood estimation instead of output-prediction errors.\n\neye(n) = SMatrix{n,n}(1.0I(n))\nllskf = map(svec) do s\n    kfs = KalmanFilter(A, B, C, 0, s^2*eye(nx), eye(ny), d0)\n    loglik(kfs, u, y, p)\nend\nllskfx = map(svec) do s # Kalman filter with known state sequence, possible when data is simulated\n    kfs = KalmanFilter(A, B, C, 0, s^2*eye(nx), eye(ny), d0)\n    loglik_x(kfs, u, y, xs, p)\nend\nplot!(svec, llskf, yscale=:identity, xscale=:log10, lab=\"Kalman\", c=:red)\nvline!([svec[findmax(llskf)[2]]], l=(:dash,:red), primary=false)\nplot!(svec, llskfx, yscale=:identity, xscale=:log10, lab=\"Kalman with known state sequence\", c=:purple)\nvline!([svec[findmax(llskfx)[2]]], l=(:dash,:purple), primary=false)\n\nthe result can be quite noisy due to the stochastic nature of particle filtering. The particle filter likelihood agrees with the Kalman-filter estimate, which is optimal for the linear example system we are simulating here, apart for when the noise variance is small. Due to particle depletion, particle filters often struggle when dynamics-noise is too small. This problem is mitigated by using a greater number of particles, or simply by not using a too small covariance.","category":"section"},{"location":"param_est_ml/#MAP-estimation","page":"Maximum-likelihood and MAP","title":"MAP estimation","text":"Maximum a posteriori estimation (MAP) is similar to maximum likelihood (ML), but includes also prior knowledge of the distribution of the parameters in a way that is similar to parameter regularization. In this example, we will estimate the variance of the noises in the dynamics and the measurement functions.\n\nTo solve a MAP estimation problem, we need to define a function that takes a parameter vector and returns a filter, the parameters are used to construct the covariance matrices:\n\nfilter_from_parameters(Î¸, pf = nothing) = KalmanFilter(A, B, C, 0, exp(Î¸[1])^2*eye(nx), exp(Î¸[2])^2*eye(ny), d0) # Works with particle filters as well\nnothing # hide\n\nThe call to exp on the parameters is so that we can define log-normal priors\n\npriors = [Normal(0,2),Normal(0,2)]\n\nNow we call the function log_likelihood_fun that returns a function to be minimized\n\nll = log_likelihood_fun(filter_from_parameters, priors, u, y, p)\nnothing # hide\n\nSince this is once again a low-dimensional problem, we can plot the LL on a 2d-grid\n\nfunction meshgrid(a,b)\n    grid_a = [i for i in a, j in b]\n    grid_b = [j for i in a, j in b]\n    grid_a, grid_b\nend\nNv       = 20\nv        = LinRange(-0.7,1,Nv)\nllxy     = (x,y) -> ll([x;y])\nVGx, VGy = meshgrid(v,v)\nVGz      = llxy.(VGx, VGy)\nheatmap(\n    VGz,\n    xticks = (1:Nv, round.(v, digits = 2)),\n    yticks = (1:Nv, round.(v, digits = 2)),\n    xlabel = \"sigma v\",\n    ylabel = \"sigma w\",\n) # Yes, labels are reversed\n# Mark the maximum with a red dot\nmax_idx = argmax(VGz)\nscatter!([max_idx[1]], [max_idx[2]], c=:red, marker=:x, markersize=10, lab=\"Maximum\")\n\nFor higher-dimensional problems, we may estimate the parameters using an optimizer, e.g., Optim.jl. See Using an optimizer for examples, including how to maximize the log-likelihood using Gauss-Newton optimization.","category":"section"},{"location":"beetle_example/#Smoothing-the-track-of-a-moving-beetle","page":"Particle-filter tutorial","title":"Smoothing the track of a moving beetle","text":"This is an example of smoothing the 2-dimensional trajectory of a moving dung beetle. The example spurred off of this Discourse topic. For more information about the research behind this example, see Artificial light disrupts dung beetlesâ€™ sense of direction and A dung beetle that path integrates without the use of landmarks. Special thanks to Yakir Gagnon for providing this example.\n\nIn this example we will describe the position coordinates, x and y, of the beetle as functions of its velocity, v_t, and direction, Î¸_t:\n\nbeginaligned\nx_t+1 = x_t + cos(Î¸_t)v_t \ny_t+1 = y_t + sin(Î¸_t)v_t \nv_t+1 = v_t + e_t \nÎ¸_t+1 = Î¸_t + w_t\nendaligned\n\nwhere e_t  N(0Ïƒ_e) w_t  N(0Ïƒ_w) The beetle further has two \"modes\", one where it's moving towards a goal, and one where it's searching in a more erratic manner. Figuring out when this mode switch occurs is the goal of the filtering. The mode will be encoded as a state variable, and used to determine the amount of dynamic noise affecting the angle of the beetle, i.e., in the searching mode, the beetle has more angle noise. The mode switching is modeled as a stochastic process with a binomial distribution (coin flip) describing the likelihood of a switch from mode 0 (moving to goal) and mode 1 (searching). Once the beetle has started searching, it stays in that mode, i.e., the searching mode is \"sticky\" or \"terminal\".\n\nThe image below shows an example video from which the data is obtained (Image: Bettle)\n\nWe load a single experiment from file for the purpose of this example (in practice, there may be hundreds of experiments)\n\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots, Random\nusing DisplayAs # hide\nusing DelimitedFiles\npath = \"../track.csv\"\nxyt = readdlm(path)\ntosvec(y) = reinterpret(SVector{length(y[1]),Float64}, reduce(hcat,y))[:] |> copy # helper function\ny = tosvec(collect(eachrow(xyt[:,1:2])))\nnothing # hide\n\nWe then define some properties of the dynamics and the filter. We will use an AdvancedParticleFilter since we want to have fine-grained control over the noise sampling for the mode switch.\n\nN = 2000 # Number of particles in the particle filter\nn = 4 # Dimension of state: we have position (2D), speed and angle\np = 2 # Dimension of measurements, we can measure the x and the y\n@inline pos(s) = s[SVector(1,2)]\n@inline vel(s) = s[3]\n@inline Ï•(s) = s[4]\n@inline mode(s) = s[5]\nnothing # hide\n\nWe then define the probability distributions we need.\n\ndgÏƒ = 1 # the deviation of the measurement noise distribution\ndvÏƒ = 0.3 # the deviation of the dynamics noise distribution\nÏ•Ïƒ  = 0.5\nconst switch_prob = 0.03 # Probability of mode switch\nconst dg = MvNormal(@SVector(zeros(p)), dgÏƒ^2) # Measurement noise Distribution\nconst df = LowLevelParticleFilters.TupleProduct((Normal.(0,[1e-1, 1e-1, dvÏƒ, Ï•Ïƒ])...,Binomial(1,switch_prob)))\nd0 = MvNormal(SVector(y[1]..., 0.5, atan((y[2]-y[1])...), 0), [3.,3,2,2,0])\nconst noisevec = zeros(5) # cache vector\nnothing # hide\n\nWe now define the dynamics, since we use the advanced filter, we include the noise=false argument. The dynamics is directly defined in discrete time.\n\n@inline function dynamics(s,u,p,t,noise=false)\n    # current state\n    m = mode(s)\n    v = vel(s)\n    a = Ï•(s)\n    p = pos(s)\n    # get noise\n    if noise\n        y_noise, x_noise, v_noise, Ï•_noise,_ = rand!(df, noisevec)\n    else\n        y_noise, x_noise, v_noise, Ï•_noise = 0.,0.,0.,0.\n    end\n    # next state\n    vâº = max(0.999v + v_noise, 0.0)\n    mâº = Float64(m == 0 ? rand() < switch_prob : true)\n    aâº = a + (Ï•_noise*(1 + m*10))/(1 + vâº) # next state velocity is used here\n    pâº = p + SVector(y_noise, x_noise) + SVector(sincos(a))*vâº # current angle but next velocity\n    SVector{5,Float64}(pâº[1], pâº[2], vâº, aâº, mâº) # all next state\nend\nfunction measurement_likelihood(s,u,y,p,t)\n    logpdf(dg, pos(s)-y) # A simple linear measurement model with normal additive noise\nend\n@inline measurement(s,u,p,t,noise=false) = s[SVector(1,2)] + noise*rand(dg) # We observe the position coordinates with the measurement\nnothing # hide\n\nIn this example, we have no control inputs, we thus define a vector of only zeros. We then solve the forward filtering problem and plot the results.\n\nu = zeros(length(y))\npf = AuxiliaryParticleFilter(AdvancedParticleFilter(N, dynamics, measurement, measurement_likelihood, df, d0))\nT = length(y)\nsol = forward_trajectory(pf,u[1:T],y[1:T])\n(; x,w,we,ll) = sol\nplot(sol, markerstrokecolor=:auto, m=(2,0.5))\nDisplayAs.PNG(Plots.current()) # hide\n\nWe can clearly see when the beetle switched mode (state variable 5). This corresponds well to annotations provided by a biologist and is the fundamental question we want to answer with the filtering procedure.\n\nWe can plot the mean of the filtered trajectory as well\n\nxh = mean_trajectory(x,we)\n\n\"plotting helper function\"\nfunction to1series(x::AbstractVector, y)\n    r,c = size(y)\n    y2 = vec([y; fill(Inf, 1, c)])\n    x2 = repeat([x; Inf], c)\n    x2,y2\nend\nto1series(y) = to1series(1:size(y,1),y)\n\nfig1 = plot(xh[:,1],xh[:,2], c=:blue, lab=\"estimate\", legend=:bottomleft)\nplot!(xyt[:,1],xyt[:,2], c=:red, lab=\"measurement\")\n\nas well as the angle state variable (we subsample the particles to not get sluggish plots)\n\nfig2 = scatter(to1series(Ï•.(x)'[:,1:2:end])..., m=(:black, 0.03, 2), lab=\"\", size=(500,300))\nplot!(identity.(xh[:,4]), lab=\"Filtered angle\", legend=:topleft, ylims=(-30, 70))\nDisplayAs.PNG(fig2) # hide\n\nThe particle plot above indicate that the posterior is multimodal. This phenomenon arises due to the simple model that uses an angle that is allowed to leave the interval 0-2Ï€ rad. In this example, we are not interested in the angle, but rather when the beetle switches mode. The filtering distribution above gives a hint at when this happens, but we will not plot the mode trajectory until we have explored smoothing as well.","category":"section"},{"location":"beetle_example/#Smoothing","page":"Particle-filter tutorial","title":"Smoothing","text":"The filtering results above does not use all the available information when trying to figure out the state trajectory. To do this, we may call a smoother. We use a particle smoother and compute 10 smoothing trajectories.\n\nM = 10 # Number of smoothing trajectories, NOTE: if this is set higher, the result will be better at the expense of linear scaling of the computational cost.\nsb,ll = smooth(pf, M, u, y) # Sample smoothing particles (b for backward-trajectory)\nsbm = smoothed_mean(sb)     # Calculate the mean of smoothing trajectories\nsbt = smoothed_trajs(sb)    # Get smoothing trajectories\nplot!(fig1, sbm[1,:],sbm[2,:], lab=\"xs\")\n\nplot!(fig2, identity.(sbm'[:,4]), lab=\"smoothed\")\nDisplayAs.PNG(fig2) # hide\n\nWe see that the smoothed trajectory may look very different from the filter trajectory. This is an indication that it's hard to tell what state the beetle is currently in, but easier to look back and tell what state the beetle must have been in at a historical point. \n\nWe can also visualize the mode state\n\nplot(xh[:,5], lab=\"Filtering\")\nplot!(to1series(sbt[5,:,:]')..., lab=\"Smoothing\", title=\"Mode trajectories\", l=(:black,0.2))\n\nalso this state variable indicates that it's hard to tell what state the beetle is in during filtering, but obvious with hindsight (smoothing). The mode switch occurs when the filtering distribution of the angle becomes drastically wider, indicating that increased dynamics noise is required in order to describe the motion of the beetle.","category":"section"},{"location":"beetle_example/#Summary","page":"Particle-filter tutorial","title":"Summary","text":"This example has demonstrated filtering and smoothing in an advanced application that includes manual control over noise, mixed continuous and discrete state.","category":"section"},{"location":"beetle_example_imm/#Filtering-the-track-of-a-moving-beetle-using-IMM","page":"IMM-filter tutorial","title":"Filtering the track of a moving beetle using IMM","text":"This tutorial is very similar to Smoothing the track of a moving beetle, but uses an Interacting Multiple Models (IMM) filter to model the mode switching of the beetle. The IMM filter is a mixture model, in this case with internal Unscented Kalman filters, where each Kalman filter represents a different mode of the system. The IMM filter is able to switch between these modes based on the likelihood of the mode given the data.\n\nThis is an example of smoothing the 2-dimensional trajectory of a moving dung beetle. The example spurred off of this Discourse topic. For more information about the research behind this example, see Artificial light disrupts dung beetlesâ€™ sense of direction and A dung beetle that path integrates without the use of landmarks. Special thanks to Yakir Gagnon for providing this example.\n\nIn this example we will describe the position coordinates, x and y, of the beetle as functions of its velocity, v_t, and direction, Î¸_t:\n\nbeginaligned\nx_t+1 = x_t + cos(Î¸_t)v_t \ny_t+1 = y_t + sin(Î¸_t)v_t \nv_t+1 = v_t + e_t \nÎ¸_t+1 = Î¸_t + w_t\nendaligned\n\nwhere e_t  N(0Ïƒ_e) w_t  N(0Ïƒ_w) The beetle further has two \"modes\", one where it's moving towards a goal, and one where it's searching in a more erratic manner. Figuring out when this mode switch occurs is the goal of the filtering. The mode will be encoded as two different models, where the difference between the models lies in the amount of dynamic noise affecting the angle of the beetle, i.e., in the searching mode, the beetle has more angle noise. The mode switching is modeled as a stochastic process with a binomial distribution (coin flip) describing the likelihood of a switch from mode 0 (moving to goal) and mode 1 (searching). Once the beetle has started searching, it stays in that mode, i.e., the searching mode is \"sticky\" or \"terminal\".\n\nThe image below shows an example video from which the data is obtained (Image: Bettle)\n\nWe load a single experiment from file for the purpose of this example (in practice, there may be hundreds of experiments)\n\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots, Random\nusing DisplayAs # hide\nusing DelimitedFiles\ncd(@__DIR__)\npath = \"../track.csv\"\nxyt = readdlm(path)\ntosvec(y) = reinterpret(SVector{length(y[1]),Float64}, reduce(hcat,y))[:] |> copy # helper function\ny = tosvec(collect(eachrow(xyt[:,1:2])))\nnothing # hide\n\nWe then define some properties of the dynamics and the filter. We will use an AdvancedParticleFilter since we want to have fine-grained control over the noise sampling for the mode switch.\n\nnx = 4 # Dimension of state: we have position (2d), speed and angle\nny = 2 # Dimension of measurements, we can measure the x and the y\n@inline pos(s) = s[SVector(1,2)]\n@inline vel(s) = s[3]\n@inline Ï•(s) = s[4]\nnothing # hide\n\nWe then define the probability distributions we need. The IMM filter takes a transition-probability matrix, P, and an initial mixing probability, Î¼. P is a Markov (stochastic) matrix, where each row sums to one, and P[i, j] is the probability of switching from mode i to mode j. Î¼ is a vector of probabilities, where Î¼[i] is the probability of starting in mode i. We also define the noise distributions for the dynamics and the measurements. The dynamics noise is modeled as a Gaussian distribution with a standard deviation of dvÏƒ for the velocity and Ï•Ïƒ for the angle. The measurement noise is modeled as a Gaussian distribution with a standard deviation of dgÏƒ. The initial state is modeled as a Gaussian distribution with a mean at the first measurement and a standard deviation of d0.\n\ndgÏƒ = 1.0 # the deviation of the measurement noise distribution\ndvÏƒ = 0.3 # the deviation of the dynamics noise distribution\nÏ•Ïƒ  = 0.5\nP = [0.995 0.005; 0.0 1] # Transition probability matrix, we model the search mode as \"terminal\"\nÎ¼ = [1.0, 0.0] # Initial mixing probabilities\nR1 = Diagonal([1e-1, 1e-1, dvÏƒ, Ï•Ïƒ].^2)\nR2 = dgÏƒ^2*I(ny) # Measurement noise covariance matrix\nd0 = MvNormal(SVector(y[1]..., 0.5, atan((y[2]-y[1])...)), [3.,3,2,2])\nnothing # hide\n\nWe now define the dynamics, which is directly defined in discrete time. The third argument is a parameter we call modegain, which is used to scale the amount of noise in the angle of the beetle depending on the mode in which it is in. The last argument is a boolean that tells the dynamics function which mode it is in, we will close over this argument when defining the dynamics for the individual Kalman filters that are part of the IMM, one will use m = false and one will use m = true.\n\n@inline function dynamics(s,_,modegain,t,w,m)\n    # current state\n    v = vel(s)\n    a = Ï•(s)\n    p = pos(s)\n\n    y_noise, x_noise, v_noise, Ï•_noise = w\n\n    # next state\n    vâº = max(0.999v + v_noise, 0.0)\n    aâº = a + (Ï•_noise*(1 + m*modegain))/(1 + vâº) # next state velocity is used here\n    pâº = p + SVector(y_noise, x_noise) + SVector(sincos(a))*vâº # current angle but next velocity\n    SVector(pâº[1], pâº[2], vâº, aâº) # all next state\nend\n@inline measurement(s,u,p,t) = s[SVector(1,2)] # We observe the position coordinates with the measurement\nnothing # hide\n\nIn this example, we have no control inputs, we thus define a vector of only zeros. We then solve the forward filtering problem and plot the results.\n\nu = zeros(length(y)) # no control inputs\nkffalse = UnscentedKalmanFilter{false,false,true,false}((x,u,p,t,w)->dynamics(x,u,p,t,w,false), measurement, R1, R2, d0; ny, nu=0, p=10)\nkftrue = UnscentedKalmanFilter{false,false,true,false}((x,u,p,t,w)->dynamics(x,u,p,t,w,true), measurement, R1, R2, d0; ny, nu=0, p=10)\n\nimm = IMM([kffalse, kftrue], P, Î¼; p = 10)\n\nT = length(y)\nsol = forward_trajectory(imm, u, y, interact=true)\nfigx = plot(sol, plotu=false, plotRt=true)\nfigmode = plot(sol.extra', title=\"Mode\")\nplot(figx, figmode)\nDisplayAs.PNG(Plots.current()) # hide\n\nIf you have followed the particle filter tutorial Smoothing the track of a moving beetle, you will notice that the result here is much worse. We used noise parameters similar to in the particle-gilter example, but those were tuned fo the particle filter. Below, we will attempt to optimize the performance of the IMM filter.","category":"section"},{"location":"beetle_example_imm/#Tuning-by-optimization","page":"IMM-filter tutorial","title":"Tuning by optimization","text":"We will attempt to optimize the dynamics and measurement noise covariance matrices and the modegain parameter. We code this up in two functions, one that takes the parameter vector and returns an IMM filter, and one that calculates the loss given the filter. We will optimize the log-likelihood of the data given the filter.\n\nparams = [log10.(diag(R1)); log10(1); log10(10)]\n\nfunction get_opt_kf(p)\n    T = eltype(p)\n    R1i = Diagonal(SVector{4}(exp10.(p[1:4])))\n    R2i = SMatrix{2,2}(exp10(p[5])*R2)\n    d0i = MvNormal(SVector{4, T}(T.(d0.Î¼)), SMatrix{4,4}(T.(d0.Î£)))\n    modegain = 2+exp10(p[6])\n    Pi = SMatrix{2,2, Float64,4}(P)\n    # sigmoid(x) = 1/(1+exp(-x))\n    # switch_prob = sigmoid(p[7])\n    # Pi = [1-switch_prob switch_prob; 0 1]\n    kffalse = UnscentedKalmanFilter{false,false,true,false}((x,u,p,t,w)->dynamics(x,u,p,t,w,false), measurement, R1i, R2i, d0i; ny, nu=0)\n    kftrue = UnscentedKalmanFilter{false,false,true,false}((x,u,p,t,w)->dynamics(x,u,p,t,w,true), measurement, R1i, R2i, d0i; ny, nu=0)\n\n    IMM([kffalse, kftrue], Pi, T.(Î¼), p=modegain)\nend\nfunction cost(pars)\n    try\n        imm = get_opt_kf(pars)\n        T = length(y)\n        ll = loglik(imm, u[1:T], y[1:T], interact=true) - 1/2*logdet(imm.models[1].R1)\n        return -ll\n    catch e\n        # rethrow() # If you only get Inf, you can uncomment this line to see the error message\n        return eltype(pars)(Inf)\n\tend\nend\n\nusing Optim\nRandom.seed!(0)\nres = Optim.optimize(\n    cost,\n    params,\n    ParticleSwarm(), # Use a gradient-free optimizer. ForwardDiff works, but the algorithm is numerically difficult to compute gradients through and may suffer from overflows in the gradient computation\n    Optim.Options(\n        show_trace        = true,\n        show_every        = 5,\n        iterations        = 100,\n        time_limit        = 30,\n    ),\n)\n\nimm = get_opt_kf(res.minimizer)\nimm = get_opt_kf([-0.1981314138910982, -0.18626406669394405, -2.7342979645906547, 0.17994244691004058, -11.706419070755908, -54.16703441089562]) #make sure it goes well # hide\n\nsol = forward_trajectory(imm, u, y)\nplot(sol.extra', title=\"Mode (optimized filter)\")\n\nIf it went well, the filter should be in mode 1 (the false mode) from the start until around 200 time steps, at which point it should switch to model 2 (true). This method of detecting the mode switch of the beetle appears to be somewhat less robust than the particle filter, but is significantly cheaper computationally. \n\nThe IMM filter does not stick in mode 2 perpetually after having reached it since it never actually becomes fully confident that mode 2 has been reached, but detecting the first switch is sufficient to know that the switch has occurred. \n\nThe log-likelihood of the solution\n\nsol.ll\n\nshould be similar to that of the particle-filter in the tutorial Smoothing the track of a moving beetle, which was around -1660.","category":"section"},{"location":"friction_nn_example/#Learning-Friction-Dynamics-with-Neural-Networks","page":"SciML: Adaptive Universal Differential Equation","title":"Learning Friction Dynamics with Neural Networks","text":"In this example, we demonstrate how to learn an unknown friction model using a neural network within the Extended Kalman Filter framework. We consider an actuated mass subject to friction with Stribeck effect - a nonlinear phenomenon where friction decreases from static friction to Coulomb friction as velocity increases.\n\nThe key point is that while we know the basic physics (Newton's second law), we might not have an accurate friction model. We'll use a neural network to learn this friction component while leveraging our knowledge of the system structure.\n\nCombining first-principles models and black-box neural networks, today popularized under the name \"Universal Differential Equations\" (UDEs), has been explored for a long time in the process-control community, early work includes [UDE1] and [UDE2], where neural networks were used to augment continuous-time models of chemical processes. Contrary to those works, we will let the state estimator itself find the parameters of the neural network alongside the state, rather than relying on a separate training phase using gradient descent.\n\n[UDE1]: Psichogios, Dimitris C., and Lyle H. Ungar. \"A hybrid neural networkâ€first principles approach to process modeling.\" AIChE Journal 38.10 (1992): 1499-1511.\n\n[UDE2]: Psichogios, Dimitris C., and Lyle H. Ungar. \"Process modeling using structured neural networks.\" 1992 American Control Conference. IEEE, 1992.","category":"section"},{"location":"friction_nn_example/#System-Description","page":"SciML: Adaptive Universal Differential Equation","title":"System Description","text":"We consider a simple mass moving in one dimension:\n\nState variables: position xâ‚ and velocity xâ‚‚  \nControl input: applied force u\nUnknown friction force: f_friction(xâ‚‚)\n\nThe continuous-time dynamics are:\n\náº‹â‚ = xâ‚‚\náº‹â‚‚ = (u - f_friction(xâ‚‚)) / m\n\nThe true friction model includes Stribeck effect:\n\nf_friction(v) = (f_c + (f_s - f_c) * exp(-|v|/v_s)) * sign(v) + f_v * v\n\nwhere:\n\nf_s: static friction coefficient\nf_c: Coulomb friction coefficient  \nv_s: Stribeck velocity\nf_v: viscous friction coefficient","category":"section"},{"location":"friction_nn_example/#Setup-and-Data-Generation","page":"SciML: Adaptive Universal Differential Equation","title":"Setup and Data Generation","text":"We generate some data from the true system using the, assumed unknown, friction model. We let the friction increase linearly, simulating, e.g., increased friction due to increased temperature over time.\n\nusing LowLevelParticleFilters, Lux, Random, SeeToDee, StaticArrays, Plots, LinearAlgebra\nusing ComponentArrays, DifferentiationInterface, SparseMatrixColorings\nusing SparseConnectivityTracer: TracerSparsityDetector\nusing DisplayAs # hide\n\nusing LowLevelParticleFilters: SimpleMvNormal\n\n# True friction model with Stribeck effect\nfunction true_friction(v, t; f_s=2.0, f_c=1.0, v_s=0.1, f_v=0.5)\n    if abs(v) < 1e-6\n        return 0.0f0  # Avoid numerical issues at zero velocity\n    else\n        # Friction increases linearly over time from 1.0 to 1.8\n        t_max = 400.0f0  # Maximum time in simulation\n        friction_multiplier = 1.0f0 + 0.3f0 * (t / t_max)\n        return Float32((f_c + (f_s - f_c) * exp(-abs(v)/v_s)) * sign(v) + f_v * v) * friction_multiplier\n    end\nend\n\nplot(v->true_friction(v, 0), -2, 2, lab=\"\\$t = 0\\$\", xlabel=\"Velocity\", ylabel=\"Friction Force\", title=\"True friction model\")\nplot!(v->true_friction(v, 400), -2, 2, lab=\"\\$t = 400\\$\")\n\n# True system dynamics\nfunction mass_dynamics(x, u, p, t)\n    m = 1.0f0  # Mass\n    xâ‚, xâ‚‚ = x\n    force = u[1]\n    friction = true_friction(xâ‚‚, t)\n    \n    SA[\n        xâ‚‚,  # áº‹â‚ = velocity\n        (force - friction) / m  # áº‹â‚‚ = acceleration\n    ]\nend\n\n# Discretize the system\nTs = 0.1f0  # Sample time\ndiscrete_dynamics = SeeToDee.Rk4(mass_dynamics, Ts)\n\n# System dimensions\nnx = 2  # State dimension [position, velocity]\nnu = 1  # Input dimension [force]\nny = 2  # Output dimension [position, velocity]\n\n# Generate training data\nfunction generate_data(rng)\n    measurement(x, u, p, t) = x  # Measure full state\n    \n    # Time vector\n    t = 0:Ts:200\n    N = length(t)\n    \n    # Generate varied control inputs to excite different velocities\n    u = Float32[]\n    for i in 1:N\n        if i < NÃ·4\n            push!(u, 3.0f0 * cos(0.1f0 * t[i]))  # Slow oscillation\n        elseif i < NÃ·2  \n            push!(u, 5.0f0 * sign(sin(0.5f0 * t[i])))  # Square wave\n        elseif i < 3NÃ·4\n            push!(u, 2.0f0 * randn(rng))  # Random excitation\n        else\n            freq = 0.05f0 + 0.2f0 * (i - 3NÃ·4) / (NÃ·4)\n            push!(u, 4.0f0 * sin(2Ï€ * freq * t[i]))  # Chirp signal\n        end\n    end\n    u = [SA[u_i] for u_i in u]\n    u = [u; u]\n    \n    # Initial state\n    x0 = Float32[0.0, 0.0]\n    \n    # Simulate system\n    x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u)[1:end-1]\n    \n    # Add measurement noise\n    y = [Float32.(x_i + 0.01f0 * randn(2)) for x_i in x]\n    \n    (; x, u, y, nx, nu, ny, Ts)\nend\n\n# Generate data\nrng = Random.default_rng()\nRandom.seed!(rng, 42)\ndata = generate_data(rng)\nnothing # hide","category":"section"},{"location":"friction_nn_example/#Neural-Network-Friction-Model","page":"SciML: Adaptive Universal Differential Equation","title":"Neural Network Friction Model","text":"We'll use a small feedforward network to learn the friction as a function of velocity only:\n\n# Neural network for friction model\n# Input: velocity (1D)\n# Output: friction force (1D)\nni = 1  # Network input dimension (velocity only)\nno = 1  # Network output dimension (friction force)\nnhidden = 6  # Hidden layer size\n\nconst friction_model2 = Chain(\n    Dense(ni, nhidden, tanh),\n    Dense(nhidden, nhidden, tanh),\n    Dense(nhidden, nhidden, tanh),\n    Dense(nhidden, no)\n)\n\n# Setup network parameters\ndev = cpu_device()\nps, st = Lux.setup(rng, friction_model2) |> dev\nparr = ComponentArray(ps)\nnothing # hide","category":"section"},{"location":"friction_nn_example/#Hybrid-Dynamics-Model","page":"SciML: Adaptive Universal Differential Equation","title":"Hybrid Dynamics Model","text":"We combine our knowledge of the physics with the neural network friction model, the only part of the friction we assume known is that it is anti-symmetric around zero velocity:\n\n# Initial state combining physical states and NN parameters\nx0 = Float32[0.0, 0.0]\ns0 = ComponentVector(; x=x0, p=parr)\n\nfunction friction_function(v, params, st)\n    # Neural network predicts friction based on velocity\n    # We assume that we know that friction is anti-symmetric around zero velocity\n    friction_nn, _ = Lux.apply(friction_model2, SA[abs(v)], params, st)\n    return friction_nn[1]*sign(v)\nend\n\n# Continuous-time hybrid dynamics: known physics + learned friction\nfunction hybrid_dynamics_continuous(xp, u, p, t)\n    xp_comp = ComponentArray(xp, getaxes(s0))\n    \n    xâ‚, xâ‚‚ = xp_comp.x\n    params = xp_comp.p\n    m = 1.0f0\n    \n    friction = friction_function(xâ‚‚, params, st)\n    \n    # Known physics: Newton's second law\n    force = u[1]\n    acceleration = (force - friction) / m\n    \n    # Combine state and parameter dynamics\n    ComponentVector(\n        x = SA[xâ‚‚, acceleration],  # State derivatives\n        p = -0.0001f0 * params  # Parameter dynamics (slow decay equivalent to 0.999 in discrete time)\n    )\nend\n\n# Discretize the hybrid dynamics\ndiscrete_hybrid_dynamics = SeeToDee.Rk4(hybrid_dynamics_continuous, Ts)\n\n# Wrapper for in-place version needed by EKF\nfunction hybrid_dynamics(out0, xp0, u, p, t)\n    xp_next = discrete_hybrid_dynamics(xp0, u, p, t)\n    out0 .= xp_next\n    nothing\nend","category":"section"},{"location":"friction_nn_example/#Extended-Kalman-Filter-Setup","page":"SciML: Adaptive Universal Differential Equation","title":"Extended Kalman Filter Setup","text":"# Process and measurement noise covariances\nR1 = Diagonal([\n    0.001f0 * ones(nx);             # Process noise for physical state\n    0.0001f0 * ones(length(parr))   # Noise for NN parameters (allows learning)\n])\nR2 = Diagonal(0.05f0^2 * ones(ny))  # Measurement noise\n\n# Jacobian computation with sparsity detection\nfunction Ajacfun(x, u, p, t)\n    backend = AutoSparse(\n        AutoForwardDiff(),\n        sparsity_detector=TracerSparsityDetector(),\n        coloring_algorithm=GreedyColoringAlgorithm(),\n    )\n    out = similar(getdata(x))\n    inner = (out, x) -> hybrid_dynamics(out, x, u, p, t)\n    prep = prepare_jacobian(inner, out, backend, getdata(x))\n    jac = one(eltype(x)) .* sparsity_pattern(prep)\n    \n    function (x, u, p, t)\n        inner2 = (out, x) -> hybrid_dynamics(out, x, u, p, t)\n        DifferentiationInterface.jacobian!(inner2, out, jac, prep, backend, x)\n    end\nend\n\nAjac = Ajacfun(s0, data.u[1], nothing, 0)\n\n# Measurement model (observe full state)\nmeasurement_model = LinearMeasurementModel(IndexingMatrix(SVector{nx}(1:nx), nx+length(parr)), 0, R2; ny)\n\n\n# Initialize Extended Kalman Filter\nynames = [\"position\", \"velocity\"]\nxnames = [ynames; [\"nn_$i\" for i in 1:length(parr)]]\nunames = [\"force\"]\nsnames = SignalNames(x = xnames, y = ynames, u = unames, name=\"EKF\")\nekf = ExtendedKalmanFilter(\n    hybrid_dynamics, \n    measurement_model, \n    R1, \n    SimpleMvNormal(s0, 10000R1);\n    nu, \n    ny,\n    check=false, \n    Ajac, \n    Ts,\n    names = snames,\n)\nnothing # hide","category":"section"},{"location":"friction_nn_example/#State-Estimation-and-Friction-Learning","page":"SciML: Adaptive Universal Differential Equation","title":"State Estimation and Friction Learning","text":"# Perform filtering\n@time sol = forward_trajectory(ekf, data.u, data.y)\n\n# Plot state estimation results\nkwargs = (plotx=false, plotxt=false, plotyh=true, plotyht=false, plotu=true, plote=true)\np1 = plot(sol; name=\"EKF\", layout=(nx+nu, 1), size=(900, 600), kwargs...)\nDisplayAs.PNG(p1) # hide","category":"section"},{"location":"friction_nn_example/#Learned-Friction-vs-True-Friction","page":"SciML: Adaptive Universal Differential Equation","title":"Learned Friction vs True Friction","text":"Let's compare the learned friction model with the true friction:\n\n# Extract final parameters\nfinal_params = ComponentArray(sol.xt[end][nx+1:end], getaxes(parr))\n\n# Generate velocity range for comparison\nv_test = LinRange(-3.0f0, 3.0f0, 100)\n\n# Compute true friction\nfriction_halfway = true_friction.(v_test, 200)\n\n# Compute learned friction (at t=200, before change)\nfriction_learned_mid = Float32[]\nparams_mid = ComponentArray(sol.xt[2000-1][nx+1:end], getaxes(parr))  # At t=200\nfor v in v_test\n    friction = friction_function(Float32(v), params_mid, st)\n    push!(friction_learned_mid, friction)\nend\n\n# Compute learned friction (final, after adaptation)\nfriction_learned_final = Float32[]\nfor v in v_test\n    friction = friction_function(Float32(v), final_params, st)\n    push!(friction_learned_final, friction)\nend\n\n# Compute modified true friction (after t=200)\nfriction_end = true_friction.(v_test, 400)\n\n# Plot comparison\np2 = plot(v_test, friction_halfway, label=\"True friction (initial)\", lw=2, ls=:dash, c=1)\nplot!(v_test, friction_end, label=\"True friction (after t=200)\", lw=2, ls=:dash, c=2)\nplot!(v_test, friction_learned_mid, label=\"Learned (at t=200)\", lw=2, alpha=0.7, c=1)\nplot!(v_test, friction_learned_final, label=\"Learned (final)\", lw=2, c=2)\nplot!(xlabel=\"Velocity\", ylabel=\"Friction Force\", title=\"Friction Model Comparison\")\nplot!(legend=:bottomright, size=(800, 500))\nDisplayAs.PNG(p2) # hide","category":"section"},{"location":"friction_nn_example/#Evolution-of-Learned-Friction-Function","page":"SciML: Adaptive Universal Differential Equation","title":"Evolution of Learned Friction Function","text":"# Create animation showing evolution of learned friction\nanim = @animate for i in 1:10:length(sol.x)\n    t_current = (i-1) * Ts\n    \n    # Extract parameters at current timestep\n    params_current = ComponentArray(sol.x[i][nx+1:end], getaxes(parr))\n    \n    friction_learned_current = friction_function.(Float32.(v_test), Ref(params_current), Ref(st))\n    \n    plot(v_test, true_friction.(v_test, t_current), label=\"True friction\", lw=2, c=:red)    \n    plot!(v_test, friction_learned_current, label=\"Learned friction\", lw=2, c=:blue)\n    \n    plot!(xlabel=\"Velocity\", ylabel=\"Friction Force\", \n          title=\"t = $(round(t_current, digits=1))\",\n          legend=:bottomright, size=(800, 500), ylims=(-4,4))\nend\n\ngif(anim, fps=30)","category":"section"},{"location":"friction_nn_example/#Closing-Remarks","page":"SciML: Adaptive Universal Differential Equation","title":"Closing Remarks","text":"We combined first-principles knowledge (Newton's laws) with a neural network to learn only the unknown component (friction). This is more sample-efficient and interpretable than learning the entire dynamics.\n\nThe Extended Kalman Filter continuously updates the neural network parameters, allowing the model to adapt to changes in the system (e.g., the continuous friction increase).","category":"section"},{"location":"param_est_optimizer/#Prediction-Error-minimization-using-an-optimizer","page":"Using an optimizer","title":"Prediction-Error minimization using an optimizer","text":"The state estimators in this package are all statistically motivated and thus compute things like the likelihood of the data as a by-product of the estimation. Maximum-likelihood or prediction-error estimation is thus very straight-forward by simply calling a gradient-based optimizer with gradients provided by differentiating through the state estimator using automatic differentiation. In this example, we will use the quad-tank process and estimate all its parameters. We will first use a standard optimization algorithm from Optim.jl to minimize the cost function based on the prediction error, and then use a Gauss-Newton optimizer.\n\nnote: Prediction-Error Method\nMinimizing the one-step ahead prediction errors made by a state estimator is often referred to as the \"Prediction-Error Method\" (PEM) in the system identification literature.","category":"section"},{"location":"param_est_optimizer/#Setup","page":"Using an optimizer","title":"Setup","text":"We define the quad-tank dynamics function such that it takes its parameters from the p input argument. We also define a variable p_true that contains the true values that we will use to simulate some estimation data. For an introduction to the quad-tank system, see Joint state and parameter estimation.\n\nusing LowLevelParticleFilters\nusing SeeToDee\nusing Distributions\nusing StaticArrays\nusing Plots, LinearAlgebra\n\nfunction quadtank(h, u, p, t)\n    k1, k2, g = p[1], p[2], 9.81\n    A1 = A3 = A2 = A4 = p[3]\n    a1 = a3 = a2 = a4 = p[4]\n    Î³1 = Î³2 = p[5]\n\n    ssqrt(x) = âˆš(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n\n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     Î³1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     Î³2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-Î³2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-Î³1)*k1/A4 * u[1]\n    ]\nend\n\nTs = 1 # sample time\nnu = 2 # number of control inputs\nnx = 4 # number of state variables\nny = 2 # number of measured outputs\n\nmeasurement(x,u,p,t) = SA[x[1], x[2]]\ndiscrete_dynamics = SeeToDee.Rk4(quadtank, Ts) # Discretize the dynamics using a 4:th order Runge-Kutta integrator\np_true = [1.6, 1.6, 4.9, 0.03, 0.2]\nnothing # hide\n\nWe simulate the system, this time using a more exciting input in order to be able to identify several parameters:\n\nusing Random; Random.seed!(1) # hide\nTperiod = 200\nt = 0:Ts:1000\nu1 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2)) .+ 0.25)\nu2 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2 .+ pi/2)) .+ 0.25)\nu  = SVector{nu}.(vcat.(u1,u2))\nx0 = SA[2.0,2,3,3] # Initial condition, static array for performance\nx = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u, p_true)[1:end-1]\ny = measurement.(x, u, 0, 0)\ny = [y .+ 0.01 .* randn.() for y in y]\n\nplot(\n    plot(reduce(hcat, x)', title=\"State\"),\n    plot(reduce(hcat, u)', title=\"Inputs\")\n)\n\nThis time, we define a cost function for the optimizer to optimize, we'll use the sum of squared errors (sse). It's important to define the UKF with an initial state distribution with the same element type as the parameter vector so that automatic differentiation through the state estimator works, hence the explicit casting T.(x0) and T.(R1). We also make sure to use StaticArrays for the covariance matrices and the initial condition for performance reasons (optional).\n\nR1 = SMatrix{nx,nx}(Diagonal([0.1, 0.1, 0.1, 0.1])) # Use of StaticArrays is generally good for performance\nR2 = SMatrix{ny,ny}(Diagonal((1e-2)^2 * ones(ny)))\nx0 = SA[2.0, 2, 3, 3]\n\nfunction cost(p::Vector{T}) where T\n    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), T.(R1)); ny, nu, Ts)\n    LowLevelParticleFilters.sse(kf, u, y, p) # Sum of squared prediction errors\nend\nnothing # hide\n\nWe generate a random initial guess for the estimation problem\n\np_guess = p_true .+  0.1*p_true .* randn(length(p_true))","category":"section"},{"location":"param_est_optimizer/#Solving-using-Optim","page":"Using an optimizer","title":"Solving using Optim","text":"We first minimize the cost using the BFGS optimization algorithm from Optim.jl\n\nusing Optim\nres = Optim.optimize(\n    cost,\n    p_guess,\n    BFGS(),\n    Optim.Options(\n        show_trace = true,\n        show_every = 5,\n        iterations = 100,\n        time_limit = 30,\n    ),\n    autodiff = :forward, # Indicate that we want to use forward-mode AD to derive gradients\n)\n\nWe started out with a normalized parameter error of\n\nnorm(p_true - p_guess) / norm(p_true)\n\nand ended with\n\np_opt = res.minimizer\nnorm(p_true - p_opt) / norm(p_true)","category":"section"},{"location":"param_est_optimizer/#Solving-using-Gauss-Newton-optimization","page":"Using an optimizer","title":"Solving using Gauss-Newton optimization","text":"Below, we optimize the sum of squared residuals again, but this time we do it using a Gauss-Newton style algorithm (Levenberg Marquardt). These algorithms want the entire residual vector rather than the sum of squares of the residuals, so we define an alternative \"cost function\" called residuals that calls the lower-level function LowLevelParticleFilters.prediction_errors!\n\nusing LeastSquaresOptim\n\nfunction residuals!(res, p::Vector{T}) where T\n    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), T.(R1)); ny, nu, Ts)\n    LowLevelParticleFilters.prediction_errors!(res, kf, u, y, p)\nend\n\nres_gn = optimize!(LeastSquaresProblem(x = copy(p_guess), f! = residuals!, output_length = length(y)*ny, autodiff = :forward), LevenbergMarquardt())\n\np_opt_gn = res_gn.minimizer\nnorm(p_true - p_opt_gn) / norm(p_true)\n\nWhen performing sum-of-squares minimization like here, we can, assuming that we converge to the global optimum, estimate the covariance of the estimated parameters. The precision matrix Î›, which is the inverse of the covariance matrix of the parameters, is given by a scaled Hessian of the cost function. The Gauss-Newton appoximation of the Hessian is given by JJ, where J is the Jacobian of the residuals.\n\nusing ForwardDiff\nT = length(y)\nout = zeros(T * ny)\nJ = ForwardDiff.jacobian(residuals!, out, res_gn.minimizer)\nresiduals!(out, res_gn.minimizer)\nÎ› = (T - length(p_guess))/dot(out,out) * Symmetric(J' * J) # Precision matrix of the estimated parameters\n# Î£ = inv(Î›) # Covariance matrix of the estimated parameters (only compute this if precision matrix is well conditioned)\nsvdvals(Î›)\n\nIn this case, the precision matrix is singular, indicating that there is at least one direction in parameter space that yields no increase in cost, and we can thus not determine where along a line in this direction the true parameter lies.\n\nGauss-Newton algorithms are often more efficient at sum-of-squares minimization than the more generic BFGS optimizer. This form of Gauss-Newton optimization of prediction errors is also available through ControlSystemIdentification.jl, which uses this package underneath the hood.","category":"section"},{"location":"param_est_optimizer/#Optimizing-log-likelihood-using-Gauss-Newton-optimization","page":"Using an optimizer","title":"Optimizing log-likelihood using Gauss-Newton optimization","text":"We can use a Gauss-Newton optimizer to maximize the log-likelihood as well, the only thing we need to change is to pass loglik = true to the prediction_errors! function, adjust the residual output length accordingly (notice the (ny+1) below, we now have an additional residual per time step corresponding to a logdet term in the likelihood) as well as possibly providing an offset argument. The reason for the offset is that the logdet term may be negative and cannot be the result of squaring a real number. The addition of the offset does not affect the optimization process, but adds a constant offset to the computed log liklihood value (cost function). If the offset is needed, you will get an error message indicating that when calling prediction_errors!. The code looks like this:\n\nusing LeastSquaresOptim\n\nfunction residuals!(res, p::Vector{T}) where T\n    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), T.(R1)); ny, nu, Ts)\n    LowLevelParticleFilters.prediction_errors!(res, kf, u, y, p, loglik=true, offset=12)\nend\n\nres_gn = optimize!(LeastSquaresProblem(x = copy(p_guess), f! = residuals!, output_length = length(y)*(ny+1), autodiff = :forward), LevenbergMarquardt())\n\np_opt_gn = res_gn.minimizer\nnorm(p_true - p_opt_gn) / norm(p_true)","category":"section"},{"location":"noisetuning/#How-to-tune-a-Kalman-filter","page":"Noise tuning and disturbance modeling for Kalman filtering","title":"How to tune a Kalman filter","text":"This tutorial is hosted as a notebook.\n\nSee also section 3.3 in \"Stochastic Differential Equation Methods for Spatio-Temporal Gaussian Process Regression\", Arno Solin for how to model temporal Gaussian processes as linear statespace models, suitable for inclusion as disturbance models for Kalman filtering. Many of these Gaussian processes are demonstrated in our Disturbance gallery.","category":"section"},{"location":"param_est_joint/#Joint-state-and-parameter-estimation","page":"Joint state and parameter estimation","title":"Joint state and parameter estimation","text":"In this example, we'll show how to perform parameter estimation by treating a parameter as a state variable. This method can not only estimate constant parameters, but also time-varying parameters.\n\nWhether we want to estimate constant or time-varying parameters is controlled by the process noise covariance associated with the parameter state, a zero covariance means that the parameter is constant, while a non-zero covariance allows the parameter to vary over time. In either case, the initial variance associated with the parameter state controls how certain we are about the initial value of the parameter.\n\nThe system we will consider is a quadruple tank, where two upper tanks feed into two lower tanks. The outlet for tank 1 can vary in size, simulating, e.g., that something partially blocks the outlet. We start by defining the dynamics on a form that changes the outlet area a_1 at time t=500:\n\nusing LowLevelParticleFilters\nusing SeeToDee\nusing Distributions\nusing StaticArrays\nusing Plots, LinearAlgebra\n\nfunction quadtank(h,u,p,t)\n    k1, k2, g = 1.6, 1.6, 9.81\n    A1 = A3 = A2 = A4 = 4.9\n    a1, a3, a2, a4 = 0.03, 0.03, 0.03, 0.03\n    Î³1, Î³2 = 0.2, 0.2\n\n    if t > 500\n        a1 *= 2 # Change the parameter at t = 500\n    end\n\n    ssqrt(x) = âˆš(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n\n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     Î³1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     Î³2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-Î³2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-Î³1)*k1/A4 * u[1]\n    ]\nend\n\nnu = 2 # number of control inputs\nnx = 4 # number of state variables\nny = 2 # number of measured outputs\nTs = 1 # sample time\nnothing # hide\n\nWe then define a measurement function, we measure the levels of tanks 1 and 2, and discretize the continuous-time dynamics using a Runge-Kutta 4 integrator SeeToDee.Rk4:\n\nmeasurement(x,u,p,t) = SA[x[1], x[2]]\ndiscrete_dynamics = SeeToDee.Rk4(quadtank, Ts)\nnothing # hide\n\nWe simulate the system using the rollout function and add some noise to the measurements. The inputs in this case are just square waves.\n\nTperiod = 200\nt = 0:Ts:1000\nu = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* t)) .+ 0.25)\nu = SVector{nu}.(vcat.(u,u))\nx0 = Float64[2,2,3,3]\nx = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u)[1:end-1]\ny = measurement.(x, u, 0, 0)\ny = [y .+ 0.01.*randn.() for y in y]\n\nplot(\n    plot(reduce(hcat, x)', title=\"State\"),\n    plot(reduce(hcat, u)', title=\"Inputs\")\n)\n\nTo perform the joint state and parameter estimation, we define a version of the dynamics that contains an extra state, corresponding to the unknown or time varying parameter, in this case a_1. We do not have any apriori information about how this parameter changes, so we say that its derivative is 0 and it's thus only driven by noise:\n\nfunction quadtank_paramest(h, u, p, t)\n    k1, k2, g = 1.6, 1.6, 9.81\n    A1 = A3 = A2 = A4 = 4.9\n    a3, a2, a4 = 0.03, 0.03, 0.03\n    Î³1, Î³2 = 0.2, 0.2\n\n    a1 = h[5] # the a1 parameter is a state\n\n    ssqrt(x) = âˆš(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0\n\n    SA[\n        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     Î³1*k1/A1 * u[1]\n        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     Î³2*k2/A2 * u[2]\n        -a3/A3*ssqrt(2g*h[3])                          + (1-Î³2)*k2/A3 * u[2]\n        -a4/A4*ssqrt(2g*h[4])                          + (1-Î³1)*k1/A4 * u[1]\n        0 # the state is only driven by noise\n    ]\nend\n\ndiscrete_dynamics_params = SeeToDee.Rk4(quadtank_paramest, Ts)\nnothing # hide\n\nWe then define a nonlinear state estimator, we will use the UnscentedKalmanFilter, and solve the filtering problem. We start by an initial state estimate x_0 that is slightly off for the parameter a_1\n\nnx = 5\nnames = SignalNames(x = [\"h1\", \"h2\", \"h3\", \"h4\", \"a1\"], y = [\"h$i\" for i in 1:2], u = [\"p1\", \"p2\"], name=\"UKF\") # For nicer plot labels\n\nR1 = SMatrix{nx,nx}(Diagonal([0.1, 0.1, 0.1, 0.1, 0.0001])) # Use of StaticArrays is generally good for performance\nR2 = SMatrix{ny,ny}(Diagonal((1e-2)^2 * ones(ny)))\nx0 = SA[2, 2, 3, 3, 0.02] # The SA prefix makes the array static, which is good for performance\n\nkf = UnscentedKalmanFilter(discrete_dynamics_params, measurement, R1, R2, MvNormal(x0, R1); ny, nu, Ts, names)\n\nsol = forward_trajectory(kf, u, y)\nplot(sol, plotx=false, plotxt=true, plotu=false, ploty=true, legend=:bottomright)\nplot!([0,500,500,1000], [0.03, 0.03, 0.06, 0.06], l=(:dash, :black), sp=5, lab=\"True param\")\n\nas we can see, the correct value of the parameter is quickly found (a_1), and it also adapts at t=500 when the parameter value changes. The speed with which the parameter adapts to changes is determined by the covariance matrix R_1, a higher value results in faster adaptation, but also higher sensitivity to noise.\n\nIf adaptive parameter estimation is coupled with a model-based controller, we get an adaptive controller! Note: the state that corresponds to the estimated parameter is typically not controllable, a fact that may require some special care for some control methods.\n\nWe may ask ourselves, what's the difference between a parameter and a state variable if we can add parameters as state variables? Typically, parameters do not vary with time, and if they do, they vary significantly slower than the state variables. State variables also have dynamics associate with them, whereas we often have no idea about how the parameters vary other than that they vary slowly.\n\nAbrupt changes to the dynamics like in the example above can happen in practice, for instance, due to equipment failure or change of operating mode. This can be treated as a scenario with time-varying parameters that are continuously estimated.","category":"section"},{"location":"param_est_joint/#More-advanced-example","page":"Joint state and parameter estimation","title":"More advanced example","text":"For systems with conditionally linear structure, the MUKF (Marginalized Unscented Kalman Filter) can provide more efficient joint state and parameter estimation. See Joint state and parameter estimation using MUKF for an example.","category":"section"},{"location":"param_est_bayesian/#Bayesian-inference","page":"Bayesian inference","title":"Bayesian inference","text":"This page demonstrates Bayesian inference methods for parameter estimation, building upon the maximum-likelihood estimation setup. For the basic setup and introduction to likelihood-based parameter estimation, see Maximum-likelihood and MAP estimation.","category":"section"},{"location":"param_est_bayesian/#Setup","page":"Bayesian inference","title":"Setup","text":"We first set up the same linear system used in the maximum-likelihood example:\n\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots\nnx = 2   # Dimension of state\nnu = 2   # Dimension of input\nny = 2   # Dimension of measurements\nN = 2000 # Number of particles\n\nconst dg = MvNormal(ny,1.0)          # Measurement noise Distribution\nconst df = MvNormal(nx,1.0)          # Dynamics noise Distribution\nconst d0 = MvNormal(@SVector(randn(nx)),2.0)   # Initial state Distribution\n\nconst A = SA[1 0.1; 0 1]\nconst B = @SMatrix [0.0 0.1; 1 0.1]\nconst C = @SMatrix [1.0 0; 0 1]\n\ndynamics(x,u,p,t) = A*x .+ B*u\nmeasurement(x,u,p,t) = C*x\neye(n) = SMatrix{n,n}(1.0I(n))\n\npf = ParticleFilter(N, dynamics, measurement, df, dg, d0)\nxs,u,y = simulate(pf,300,df)\np = nothing\nnothing # hide","category":"section"},{"location":"param_est_bayesian/#Bayesian-inference-using-PMMH","page":"Bayesian inference","title":"Bayesian inference using PMMH","text":"We proceed like we did for MAP in Maximum-likelihood and MAP estimation, but when calling the function metropolis, we will get the entire posterior distribution of the parameter vector, for the small cost of a massive increase in the amount of computations. metropolis runs the Metropolis Hastings algorithm, or more precisely if a particle filter is used, the \"Particle Marginal Metropolis Hastings\" (PMMH) algorithm. Here we use the Kalman filter simply to have the documentation build a bit faster, it can be quite heavy to run.\n\nfilter_from_parameters(Î¸, pf = nothing) = KalmanFilter(A, B, C, 0, exp(Î¸[1])^2*I(nx), exp(Î¸[2])^2*I(ny), d0) # Works with particle filters as well\nnothing # hide\n\nThe call to exp on the parameters is so that we can define log-normal priors\n\npriors = [Normal(0,2),Normal(0,2)]\nll     = log_likelihood_fun(filter_from_parameters, priors, u, y, p)\nÎ¸â‚€     = log.([1.0, 1.0]) # Starting point\nnothing # hide\n\nWe also need to define a function that suggests a new point from the \"proposal distribution\". This can be pretty much anything, but it has to be symmetric since I was lazy and simplified an equation.\n\ndraw   = Î¸ -> Î¸ .+ 0.05 .* randn.() # This function dictates how new proposal parameters are being generated.\nburnin = 200 # remove this many initial samples (\"burn-in period\")\n@info \"Starting Metropolis algorithm\"\n@time theta, lls = metropolis(ll, 2200, Î¸â‚€, draw) # Run PMMH for 2200  iterations\nthetam = reduce(hcat, theta)'[burnin+1:end,:] # Build a matrix of the output\nhistogram(exp.(thetam), layout=(3,1), lab=[\"R1\" \"R2\"]); plot!(lls[burnin+1:end], subplot=3, lab=\"log likelihood\") # Visualize\n\nIn this example, we initialize the MH algorithm on the correct value Î¸â‚€, in general, you'd see a period in the beginning where the likelihood (bottom plot) is much lower than during the rest of the sampling, this is the reason we remove a number of samples in the beginning, typically referred to as \"burn in\".\n\nIf you are lucky, you can run the above threaded as well. I tried my best to make particle filters thread safe with their own rngs etc., but your milage may vary. For threading to help, the dynamics must be non-allocating, e.g., by using StaticArrays etc.\n\n@time thetalls = LowLevelParticleFilters.metropolis_threaded(burnin, ll, 2200, Î¸â‚€, draw, nthreads=2)\nhistogram(exp.(thetalls[:,1:2]), layout=3)\nplot!(thetalls[:,3], subplot=3)","category":"section"},{"location":"param_est_bayesian/#Bayesian-inference-using-DynamicHMC.jl","page":"Bayesian inference","title":"Bayesian inference using DynamicHMC.jl","text":"The following snippet of code performs the same estimation as above, but uses the much more sophisticated HMC sampler in DynamicHMC.jl rather than the PMMH sampler above. This package requires the log-likelihood function to be wrapped in a custom struct that implements the LogDensityProblems interface, which is done below. We also indicate that we want to use ForwardDiff.jl to compute the gradients for fast sampling.\n\nusing DynamicHMC, LogDensityProblemsAD, ForwardDiff, LogDensityProblems, LinearAlgebra, Random\n\nstruct LogTargetDensity{F}\n    ll::F\n    dim::Int\nend\nLogDensityProblems.logdensity(p::LogTargetDensity, Î¸) = p.ll(Î¸)\nLogDensityProblems.dimension(p::LogTargetDensity) = p.dim\nLogDensityProblems.capabilities(::Type{LogTargetDensity}) = LogDensityProblems.LogDensityOrder{0}()\n\nfunction filter_from_parameters(Î¸, pf = nothing)\n    # It's important that the distribution of the initial state has the same\n    # element type as the parameters. DynamicHMC will use Dual numbers for differentiation,\n    # hence, we make sure that d0 has `eltype(d0) = eltype(Î¸)`\n    T = eltype(Î¸)\n    d0i = MvNormal(T.(d0.Î¼), T.(d0.Î£))\n    KalmanFilter(A, B, C, 0, exp(Î¸[1])^2*eye(nx), exp(Î¸[2])^2*eye(ny), d0i)\nend\nll = log_likelihood_fun(filter_from_parameters, priors, u, y, p)\n\nD = length(Î¸â‚€)\nâ„“Ï€ = LogTargetDensity(ll, D)\nâˆ‡P = ADgradient(:ForwardDiff, â„“Ï€)\n\nresults = mcmc_with_warmup(Random.default_rng(), âˆ‡P, 3000)\nDynamicHMC.Diagnostics.summarize_tree_statistics(results.tree_statistics)\nlls = [ts.Ï€ for ts in results.tree_statistics]\n\nhistogram(exp.(results.posterior_matrix)', layout=(3,1), lab=[\"R1\" \"R2\"])\nplot!(lls, subplot=3, lab=\"log likelihood\") # Visualize","category":"section"},{"location":"param_est_identifiability/#Identifiability","page":"Identifiability","title":"Identifiability","text":"There is no guarantee that we will recover the true parameters by perfoming parameter estimation, especially not if the input excitation is poor. For the quad-tank system used in Using an optimizer, we will generally find parameters that results in a good predictor for the system (this is after all what we're optimizing for), but these may not be the \"correct\" parameters.","category":"section"},{"location":"param_est_identifiability/#Polynomial-methods","page":"Identifiability","title":"Polynomial methods","text":"A tool like StructuralIdentifiability.jl may be used to determine the identifiability of parameters and state variables (for rational systems), something that for the quad-tank system could look like\n\nusing StructuralIdentifiability\n\node = @ODEmodel(\n    h1'(t) = -a1/A1 * h1(t) + a3/A1*h3(t) +     gam*k1/A1 * u1(t),\n    h2'(t) = -a2/A2 * h2(t) + a4/A2*h4(t) +     gam*k2/A2 * u2(t),\n    h3'(t) = -a3/A3*h3(t)                 + (1-gam)*k2/A3 * u2(t),\n    h4'(t) = -a4/A4*h4(t)                 + (1-gam)*k1/A4 * u1(t),\n\ty1(t) = h1(t),\n    y2(t) = h2(t),\n)\n\nlocal_id = assess_local_identifiability(ode)\n\nwhere we have made the substitution sqrt h rightarrow h due to a limitation of the tool (it currently only handles rational ODEs). The output of the above analysis is\n\njulia> local_id = assess_local_identifiability(ode)\nDict{Nemo.fmpq_mpoly, Bool} with 15 entries:\n  a3  => 0\n  gam => 1\n  k2  => 0\n  A4  => 0\n  h4  => 0\n  h2  => 1\n  A3  => 0\n  a1  => 0\n  A2  => 0\n  k1  => 0\n  a4  => 0\n  h3  => 0\n  h1  => 1\n  A1  => 0\n  a2  => 0\n\nindicating that we can not hope to resolve all of the parameters. However, using appropriate regularization from prior information, we might still recover a lot of information about the system. Regularization could easily be added to the function cost in Using an optimizer, e.g., using a penalty like (p-p_guess)'Î“*(p-p_guess) for some matrix Gamma, to indicate our confidence in the initial guess.","category":"section"},{"location":"param_est_identifiability/#Linear-methods","page":"Identifiability","title":"Linear methods","text":"This package also contains an interface to ControlSystemsBase, which allows you to call ControlSystemsBase.observability(f, x, u, p, t) on a filter f to linearize (if needed) it in the point x,u,p,t and assess observability using linear methods (the PHB test). Also ControlSystemsBase.obsv(f, x, u, p, t) for computing the observability matrix is available.","category":"section"},{"location":"param_est_identifiability/#Fisher-Information-and-Augmented-State-Covariance","page":"Identifiability","title":"Fisher Information and Augmented State Covariance","text":"When using augmented-state methods for joint state and parameter estimation (see Joint state and parameter estimation), we embed the parameters as additional state variables, often with zero process noise, i.e.\n\nz_k =\nbeginbmatrix\nx_k \np\nendbmatrix\nqquad\nz_k+1 =\nunderbracebeginbmatrix\nA_k  A^(p)_k \n0    I\nendbmatrix_A_k^textaug\nz_k +\nbeginbmatrix\nw_k  0\nendbmatrix\nqquad\ny_k = C_k x_k + e_k\n\nwhere\n\nx_k\n= original system state\np\n= constant parameters (no process noise)\nw_k sim mathcalN(0R_1)\n= process noise driving the state\ne_k sim mathcalN(0R_2)\n= measurement noise\nA^(p)_k = fracpartial fpartial pbig_(x_ku_kp)\nencodes the parameter influence\nParameters evolve as p_k+1 = p_k, modeled here as a random walk with zero covariance\n\n","category":"section"},{"location":"param_est_identifiability/#Connection-to-Fisher-Information","page":"Identifiability","title":"Connection to Fisher Information","text":"Running an Extended or Unscented Kalman Filter on this augmented system produces a covariance matrix\n\nR_k =\nbeginbmatrix\nR_xxk  R_xpk \nR_xpk^top  R_ppk\nendbmatrix\n\nThe block (R_ppk) represents the covariance of the parameter estimates at time index k. For constant parameters (R_1^p = 0), this parameter covariance evolves by accumulating information from measurements:\n\nR_ppk+1^-1\n=\nR_ppk^-1 +\nJ_k^top S_k^-1 J_k\n\nwhere\n\nJ_k = C_k S^(p)_k\nis the output sensitivity to parameters,\nS_k = C_k R_xxk C_k^top + R_2\nis the innovation covariance,\nS^(p)_k = fracpartial x_kpartial p\nis the state sensitivity satisfying the recursion (from the chain rule applied to the nonlinear dynamics)\nS^(p)_k+1 = A_k S^(p)_k + A^(p)_k qquad S^(p)_0 = 0\n\nIf we define the (trajectory) Fisher Information Matrix (FIM) as\n\nmathcalI(p) =\nsum_k=1^N J_k^top S_k^-1 J_k\n\nthen it follows that\n\nR_ppN^-1\n=\nR_pp0^-1 + mathcalI(p)\n\nThis shows a connection between the Fisher Information Matrix and the parameter covariance arising from augmented-state filtering:\n\nThe FIM measures how much information the data contains about the parameters\nWhen parameters are constant (R_1^p = 0), the augmented Kalman filter accumulates FIM over time\nThe CramÃ©râ€“Rao lower bound becomes\n\nmathrmcov(hatp) succeq mathcalI(p)^-1","category":"section"},{"location":"param_est_identifiability/#Summary","page":"Identifiability","title":"Summary","text":"In joint stateâ€“parameter estimation with constant parameters, the parameter covariance block R_ppk of the augmented Kalman filter (or EKF/UKF approximation) decreases as information is accumulated according to the Fisher information matrix. This link provides a principled way to analyze *parameter identifiability and experiment excitation design using information theory.\n\nThis relationship is useful for understanding how well parameters can be estimated from data, and it explains why insufficient excitation or poor observability leads to slow decay of R_ppk and unreliable parameter estimates in practice. The FIM is also equal to the Hessian of the negative log-likelihood function at the optimum found when performing maximum-likelihood parameter estimation.","category":"section"},{"location":"rbpf_example/#Rao-Blackwellized-particle-filter","page":"Rao-Blackwellized filter tutorial","title":"Rao-Blackwellized particle filter","text":"This example will demonstrate use of the Rao-Blackwellized particle filter and UKF (RBPF and MUKF respectively), also called \"Marginalized particle filter\" and \"Marginalized Unscented Kalman Filter\".","category":"section"},{"location":"rbpf_example/#RBPF","page":"Rao-Blackwellized filter tutorial","title":"RBPF","text":"The RBPF filter is effectively a particle filter where each particle is a Kalman filter that is responsible for the estimation of a linear sub structure.\n\nThe filter assumes that the dynamics follow \"model 2\" in the article \"Marginalized Particle Filters for Mixed Linear/Nonlinear State-space Models\" by Thomas SchÃ¶n, Fredrik Gustafsson, and Per-Johan Nordlund, i.e., the dynamics is described by\n\nbeginalign\n    x_t+1^n = f_n(x_t^n u p t) + A_n(x_t^n u p t) x_t^l + w_t^n quad w_t^n sim mathcalN(0 R_1^n) \n    x_t+1^l = A() x_t^l + Bu + w_t^l quad w_t^l sim mathcalN(0 R_1^l) \n    y_t = g(x_t^n u p t) + C() x_t^l + e_t quad e_t sim mathcalN(0 R_2)\nendalign\n\nwhere x^n is a subset of the state that has nonlinear dynamics or measurement function, and x^l is a subset of the state where both dynamics and measurement function are linear and Gaussian. The entire state vector is represented by a special type RBParticle that behaves like the vector [xn; xl], but stores xn, xl and the covariance R of xl separately.\n\nwarning: Experimental\nThis filter is currently considered experimental and the user interface may change in the future without respecting semantic versioning.\n\nBelow, we define all functions and matrices that are needed to perform marginalized particle filtering for the dynamical system\n\nbeginalign\nx_t+1^n = arctan x_t^n + beginpmatrix 1  0  0 endpmatrix x_t^1 + w_t^n tag1a \nx_t+1^1 = beginpmatrix\n1  03  0 \n0  092  -03 \n0  03  092\nendpmatrix x_t^1 + w_t^1 tag1b \ny_t = beginpmatrix\n01(x_t^n)^2 operatornamesgn(x_t^n) \n0\nendpmatrix + beginpmatrix\n0  0  0 \n1  -1  1\nendpmatrix x_t^1 + e_t tag1c \ntextwhere\nw_t = beginpmatrix\nw_t^n \nw_t^1\nendpmatrix sim mathcalN(0 001I_4times 4) tag1d \ne_t sim mathcalN(0 01I_2times 2) tag1e \nx_0^n sim mathcalN(0 1) tag1f \nx_0^1 sim mathcalN(0_3times 1 0_3times 3) tag1g\nendalign\n\nSince this is a tracking problem without control inputs, and there are no parameters and time dependence, we define functions with the signature fn(xn, args...) to handle the fact that the filter will pass empty arguments for inputs, parameters and time.\n\nBelow, we define functions that return the matrix A_n despite that it is constant, we do this to illustrate that this matrix may in general be a function of the nonlinear state, parameter and time. If the matrix is constant, it's okay to let An be a Matrix or SMatrix instead of a function.\n\nusing LowLevelParticleFilters, LinearAlgebra\nusing LowLevelParticleFilters: SimpleMvNormal\nusing StaticArrays\nusing Random\nusing DisplayAs # hide\nnxn = 1         # Dimension of nonlinear state\nnxl = 3         # Dimension of linear state\nnx  = nxn + nxl # Total dimension of state\nnu  = 0         # Dimension of control input\nny  = 2         # Dimension of measurement\nN   = 200       # Number of particles\nfn(xn, args...) = SA[atan(xn[])]         # Nonlinear part of nonlinear state dynamics\nAn  = SA[1.0 0.0 0.0]     # Linear part of nonlinear state dynamics\nAl  = SA[1.0  0.3   0.0;  # Linear part of linear state dynamics (the standard Kalman-filter A matrix). It's defined as a matrix here, but it can also be a function of (x, u, p, t)\n                   0.0  0.92 -0.3; \n                   0.0  0.3   0.92] # 3x3 matrix\nCl = SA[0.0  0.0 0.0; \n      1.0 -1.0 1.0]    # 2x3 measurement matrix\ng(xn, args...) = SA[0.1 * xn[]^2 * sign(xn[]), 0.0] # 2x1 vector\n\nBl = zeros(nxl, nu)\n\n# Noise parameters\nR1n = SA[0.01;;]          # Scalar variance for w^n\nR1l = 0.01 * I(3)       # 3x3 covariance for w^l\nR2  = 0.1 * I(2)         # 2x2 measurement noise (shared between linear and nonlinear parts)\n\n# Initial states (xn ~ N(0,1), xl ~ N(0, 0.01I))\nx0n = @SVector zeros(nxn)\nR0n = SA[1.0;;]\nx0l = @SVector zeros(nxl)\nR0l = 0.01 * I(nxl)\n\nd0l = SimpleMvNormal(x0l, R0l)\nd0n = SimpleMvNormal(x0n, R0n)\n\nkf    = KalmanFilter(Al, Bl, Cl, 0, R1l, R2, d0l; ny, nu) # Since we are providing a function instead of a matrix for C, we also provide the number of outputs ny\nmm    = RBMeasurementModel(g, R2, ny)\nnames = SignalNames(x=[\"\\$x^n_1\\$\", \"\\$x^l_2\\$\", \"\\$x^l_3\\$\", \"\\$x^l_4\\$\"], u=[], y=[\"\\$y_1\\$\", \"\\$y_2\\$\"], name=\"RBPF\") # For nicer labels in the plot\npf    = RBPF(N, kf, fn, mm, R1n, d0n; nu, An, Ts=1.0, names)\nRandom.seed!(pf.rng, 1234)\n\n# Simulate some data from the filter dynamics\nu     = [zeros(nu) for _ in 1:100]\nx,u,y = simulate(pf, u)\n\n# Perform the filtering\nsol = forward_trajectory(pf, u, y)\n\nusing Plots\nfig_rbpf = plot(sol, size=(800,600), xreal=x, markersize=1, nbinsy=50, colorbar=false)\nfor i = 1:nx\n    plot!(ylims = extrema(getindex.(x, i)) .+ (-1, 1), sp=i)\nend\ncurrent()\nDisplayAs.PNG(Plots.current()) # hide\n\nThe cyan markers represent the true state in the state plots, and the measurements in the measurement plots. The heatmap represents the particle distribution. Note, since each particle has an additional covariance estimate for the linear sub state, the heatmaps for the linear sub state are constructed by drawing a small number of samples from this marginal distribution. Formally, the marginal distribution over the linear sub state is a gaussian-mixture model where the weight of each gaussian is the weight of the particle. This fact is not taken into account when the heat map for the predicted measurement is constructed, so interpret this heatmap with caution.\n\nIn this example, we made use of standard julia arrays for the dynamics and covariances etc., for optimum performance (the difference may be dramatic), make use of static arrays from StaticArrays.jl. \n\nThe paper referenced above mention a lot of special cases in which the filter can be simplified, it's worth a read if you are considering using this filter.","category":"section"},{"location":"rbpf_example/#Marginalized-UKF","page":"Rao-Blackwellized filter tutorial","title":"Marginalized UKF","text":"The MUKF (Marginalized Unscented Kalman Filter) is an alternative to RBPF that uses the Unscented Transform instead of random particles. While RBPF uses N random particles (each with a Kalman filter), MUKF uses deterministic sigma points (typically 2n+1 for an n-dimensional nonlinear state). This makes MUKF:\n\nDeterministic\nEfficient for low-dimensional nonlinear states: Uses fewer \"hypotheses\" than typical RBPF and fewer sigma points than the corresponding UKF\nGaussian assumption: Like UKF, assumes posterior remains Gaussian (cannot handle multimodal distributions)\n\nThe MUKF filter in this package accepts a slightly more general form of the dynamics than RBPF, notably, we allow the d_l(x_t^n u p t) term in the linear sub state dynamics.\n\nbeginaligned\nx_t+1^n = d_n(x_t^n u p t) + A_n(x_t^n u p t) x_t^l + w_t^n \nx_t+1^l = d_l(x_t^n u p t) + A_l(x_t^n u p t) x_t^l + w_t^l \nw_t = beginbmatrix w_t^n  w_t^l endbmatrix sim mathcalN(0 R_1) \ny_t = g(x_t^n u p t) + C_l(x_t^n) x_t^l + e_t quad e_t sim mathcalN(0 R_2)\nendaligned\n\nThe MUKF filter takes the nonlinear dynamics term d_n d_l as a single function fn(xn, u, p, t) and the linear coupling matrix A = A_n A_l as a single matrix or function, so we need to define a new function for these. Control input dependence can be encoded directly in both d_n and d_l. We also need to combine the process noise covariances into a single matrix R_1 and the initial distributions into a single distribution. Let's compare MUKF with RBPF on the same system:\n\nusing Statistics\nfn_mukf(xn, args...) = SA[atan(xn[]); 0.0; 0.0; 0.0] # d_n and d_l combined\n# Create MUKF using the same model components\n# Combine process noise covariances into full R1 matrix\nR1 = [R1n zeros(nxn, nxl); zeros(nxl, nxn) R1l]\n# Unified initial distribution for MUKF\nx0 = [x0n; x0l]\nR0_full = [R0n zeros(nxn, nxl); zeros(nxl, nxn) R0l]\nd0 = SimpleMvNormal(x0, R0_full)\n# Combine An and Al into single A matrix for MUKF\nA = [An; Al]  # A is nx Ã— nxl, formed by stacking An (nxn Ã— nxl) and Al (nxl Ã— nxl)\nweight_params = MerweParams(Î± = 0.5) # MUKF does much better at this example if this is set to 0.5 instead of the default 1.0\nmukf = MUKF(; dynamics=fn_mukf, nl_measurement_model=mm, A, Cl, R1, d0, nxn, nu, ny, weight_params, names=SignalNames(names, \"MUKF\"))\n\n# Run filtering on the same data\nsol_mukf = forward_trajectory(mukf, u, y)\n\n# Extract nonlinear state estimates for comparison\nxn_true = first.(x)\nxn_rbpf = [mean(sol.x[:, t])[1] for t in 1:length(y)]  # Mean of RBPF particles\nxn_mukf = first.(sol_mukf.xt)                          # MUKF filtered estimate\n\n# Compute RMSE\nusing Statistics\nrmse_rbpf = sqrt(mean((xn_true .- xn_rbpf).^2))\nrmse_mukf = sqrt(mean((xn_true .- xn_mukf).^2))\n\nprintln(\"RBPF RMSE: $(round(rmse_rbpf, digits=4))\")\nprintln(\"MUKF RMSE: $(round(rmse_mukf, digits=4))\")\n\nLet's add the MUKF result to the previous plot for comparison:\n\nplot!(fig_rbpf, sol_mukf, ploty=false, plotx=false, plotRt=true, fillalpha=0.3, linewidth=2)\nDisplayAs.PNG(Plots.current()) # hide\n\nBoth filters successfully track the nonlinear state. The MUKF uses only 3 sigma points (for the 1D nonlinear state) compared to 200 particles in the RBPF, yet achieves comparable performance. For this problem with a low-dimensional nonlinear state and unimodal posterior, MUKF is more efficient.\n\nWhen to use each filter:\n\nUse MUKF when: posterior is unimodal, you want deterministic results. The MUKF estimator is often suitable for disturbance and parameter estimation, since it is deterministic, differentiable and disturbances and parameters are often modeled with linear time evolution.\nUse RBPF when: posterior may be multimodal, you need maximum flexibility","category":"section"},{"location":"rbpf_example/#Details-of-the-marginal-distribution-over-the-linear-sub-state","page":"Rao-Blackwellized filter tutorial","title":"Details of the marginal distribution over the linear sub state","text":"We can create a distribution object that represents the Gaussian mixture model that represents the marginal distribution over the linear sub state. This may be useful to compute confidence intervals or quantiles etc.\n\nusing Distributions\ntime_step = 100 # The time step at which to access the solution object from above\nwe = sol.we[:, time_step] # Extract the weights of the particles at the desired time step\nlinear_state_inds = nxn+1:nx\nxl = getindex.(sol.x[:, time_step], Ref(linear_state_inds)) # Extract the linear sub state from the particles at the desired time step\nRv = [sol.x[i, time_step].R for i = 1:num_particles(pf)] # Extract the covariance of each mixture component\n\ncomponents = [MvNormal(xl[i], Rv[i]) for i = 1:num_particles(pf)] # The component distribution in the mixture model\n\nD = Distributions.MixtureModel(components, we)\n\ncov(D)\n\nAbove, we showed how to compute the covariance of the mixture distribution. If we consider the marginal distribution of a single dimension of the linear sub state, we can compute, e.g., quantiles as well by calling quantile(D, q).","category":"section"},{"location":"fault_detection/#Fault-detection","page":"Fault detection","title":"Fault detection","text":"This is also a video tutorial, available below:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/NgDcMuewPbI?si=6_bgIDiz9PFIE_gQ\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"section"},{"location":"fault_detection/#Fault-detection-using-state-estimation","page":"Fault detection","title":"Fault detection using state estimation","text":"This tutorial explores the use of a Kalman filter for fault detection in a thermal system\n\nModeling\nFiltering\nMaximum-likelihood estimation of covariance and model parameters\nMonitor prediction-error Z-score to detect faults\nA fault may be faulty sensor or unexpected temperature fluctuations\n\nusing DelimitedFiles, Plots, Dates\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays\nusing LowLevelParticleFilters: AbstractKalmanFilter, particletype, covtype,state,  covariance, parameters, KalmanFilteringSolution\nusing Optim\nusing DisplayAs # hide","category":"section"},{"location":"fault_detection/#Load-data","page":"Fault detection","title":"Load data","text":"From kaggle.com/datasets/arashnic/sensor-fault-detection-data\n\nA time series of temperature measurements\n\nusing Downloads\nurl = \"https://drive.google.com/uc?export=download&id=1zuIBaOhhrCxnifbvY7qJQTOyKWBDeBRh\"\nfilename = \"sensor-fault-detection.csv\"\nDownloads.download(url, filename)\nraw_data = readdlm(filename, ';')\nheader = raw_data[1,:]\ndf = dateformat\"yyyy-mm-ddTHH:MM:SS\"\nnothing # hide\n\nThe data is not stored in order\n\ntime_unsorted = DateTime.(getindex.(raw_data[2:end, 1], Ref(1:19)), df)\n\nso we compute a sorting permutation that brings it into chronological order\n\nperm = sortperm(time_unsorted)\ntime = time_unsorted[perm]\ny = raw_data[2:end, 3][perm] .|> float\nnothing # hide\n\ny is the recorded temperature data.","category":"section"},{"location":"fault_detection/#Look-at-the-data","page":"Fault detection","title":"Look at the data","text":"plot(time, y, ylabel=\"Temperature\", legend=false)\nDisplayAs.PNG(Plots.current()) # hide\n\ntimev = Dates.value.(time)  ./ 1000 # A numerical time vector, time was in milliseconds\nplot(diff(timev), yscale=:log10, title=\"Time interval between measurement points\", legend=false)\nDisplayAs.PNG(Plots.current()) # hide\n\nSamples are not evenly spaced (lots of missing data), but the interval is always a multiple of Ts\n\nintervals = sort(unique(diff(timev)))\nintervals ./ intervals[1]\nTs = intervals[1]\nnothing # hide\n\nTf = intervals[end] - intervals[1]\nnothing # hide\n\nWe expand the data arrays such that we can treat them as having a constant sample interval, time points where there is no data available are indicated as missing\n\ntime_full = range(timev[1], timev[end], step=Ts)\n\navailable_inds = [findfirst(==(t), time_full) for t in timev]\n\ny_full = fill(NaN, length(time_full))\ny_full[available_inds] .= y\ny_full = replace(y_full, NaN=>missing)\ny_full = SVector{1}.(y_full)\nnothing # hide","category":"section"},{"location":"fault_detection/#Design-Kalman-filter","page":"Fault detection","title":"Design Kalman filter","text":"","category":"section"},{"location":"fault_detection/#Modeling","page":"Fault detection","title":"Modeling","text":"A simple model of temperature change is\n\ndot T(t) = alpha big(T(t) - T_env(t)big) + w(t)\n\nWhere T is the temperature of the system, T_env the temperature of the environment and w represents thermal energy added or removed by unmodeled sources.\n\nSince we have no knowledge of T_env and w, but we observe that they vary slowly, we add yet another state variable to the model corresponding to an integrating disturbance model:\n\nbeginaligned\ndot T(t) = z(t) + b_T w_T(t) \ndot z(t) =  b_z w_z(t)\nendaligned\n\nThis model is linear, and can be written on the form\n\nbeginaligned\ndot x = Ax + Bw \ny = Cx + e\nendaligned\n\nwith A matrix \n\nA = beginbmatrix\n0  1 \n0  0\nendbmatrix\n\nwhich, when discretized (assuming unit sample interval), becomes\n\nA = beginbmatrix\n1  1 \n0  1\nendbmatrix\n\nA,B,C,D = SA[1.0 1; 0 1], @SMatrix(zeros(2,0)), SA[1.0 0], 0;\nnothing # hide","category":"section"},{"location":"fault_detection/#Picking-covariance-matrices","page":"Fault detection","title":"Picking covariance matrices","text":"R1 = 1e-4LowLevelParticleFilters.double_integrator_covariance(1) |> SMatrix{2,2}\nR2 = SA[0.1^2;;]\nd0 = LowLevelParticleFilters.SimpleMvNormal(SA[y[1], 0], SA[100.0 0; 0 0.1])\nkf = KalmanFilter(A,B,C,D,R1,R2,d0; Ts)","category":"section"},{"location":"fault_detection/#Perform-filtering","page":"Fault detection","title":"Perform filtering","text":"When data is missing, we omit the call to correct!. We still perform the prediction step though.\n\nfunction special_forward_trajectory(kf::AbstractKalmanFilter, u::AbstractVector, y::AbstractVector, p=parameters(kf))\n    reset!(kf)\n    T    = length(y)\n    x    = Array{particletype(kf)}(undef,T)\n    xt   = Array{particletype(kf)}(undef,T)\n    R    = Array{covtype(kf)}(undef,T)\n    Rt   = Array{covtype(kf)}(undef,T)\n    e    = zeros(eltype(particletype(kf)), length(y))\n\tÏƒs   = zeros(eltype(particletype(kf)), length(y))\n    ll   = zero(eltype(particletype(kf)))\n    S    = Vector{Any}(undef, T)\n    K    = Vector{Any}(undef, T)\n    for t = 1:T\n        ti = (t-1)*kf.Ts\n        x[t]  = state(kf)      |> copy\n        R[t]  = covariance(kf) |> copy\n\t\tif !any(ismissing, y[t])\n        \tlli, ei, Si, Sáµªi, Ki = correct!(kf, u[t], y[t], p, ti)\n\t\t\tÏƒs[t] = âˆš(ei'*(Sáµªi\\ei)) # Compute the Z-score\n\t\t\te[t] = ei[]\n\t\t\tll += lli\n            S[t] = Sáµªi\n            K[t] = Ki\n\t\tend\n        xt[t] = state(kf)      |> copy\n        Rt[t] = covariance(kf) |> copy\n        predict!(kf, u[t], p, ti)\n    end\n    KalmanFilteringSolution(kf,u,y,x,xt,R,Rt,ll,vcat.(e),K,S), Ïƒs\nend\n\nu_full = [@SVector(zeros(0)) for y in y_full];\n\nstart = 1 # Change this value to display different parts of the data set\nN = 1000  # Number of data points to include (to limit plot size in the docs, plot with Plots.plotly() and N = length(y_full) to see the full data set with the ability to zoom interactively in the plot)\n\nsol, Ïƒs = special_forward_trajectory(kf, u_full[(1:N) .+ (start-1)], y_full[(1:N) .+ (start-1)])\n\nsol.ll","category":"section"},{"location":"fault_detection/#Smoothing","page":"Fault detection","title":"Smoothing","text":"For good measure, we also perform smoothing, computing\n\nx(k  T_f)\n\nas opposed to filtering which is computing\n\nx(k  k)\n\nor prediction\n\nx(k  k-1)\n\nsmoothsol = smooth(sol)\nnothing # hide","category":"section"},{"location":"fault_detection/#Visualize-the-filtered-and-smoothed-trajectories","page":"Fault detection","title":"Visualize the filtered and smoothed trajectories","text":"timevec = range(0, step=Ts, length=length(sol.y))\n\nplot(smoothsol,\n    plotx   = false, # prediction\n    plotxt  = true,  # filtered\n    plotxT  = true,  # smoothed\n    plotRt  = true,\n    plotRT  = true,\n    plotyh  = false,\n    plotyht = true,\n    size = (650,600), seriestype = [:line :line :scatter :line], link = :x,\n)\nplot!(timevec, reduce(hcat, smoothsol.xT)[1,:], sp=3, label=\"Smoothed\")\nDisplayAs.PNG(Plots.current()) # hide","category":"section"},{"location":"fault_detection/#Estimate-the-dynamics-covariance-using-maximum-likelihood-estimation-(MLE)","page":"Fault detection","title":"Estimate the dynamics covariance using maximum-likelihood estimation (MLE)","text":"Since we have a single parameter only, we may plot the loss landscape.\n\nsvec = exp10.(range(-5, -2, length=30)) # Covariance values to try\n\n# Compute the log-likelihood for all covariance values\nlls = map(svec) do s # \n\tR1 = s*LowLevelParticleFilters.double_integrator_covariance(1) |> SMatrix{2,2}\n\tkf = KalmanFilter(A,B,C,D,R1,R2,d0; Ts)\n\tsol, Ïƒs = special_forward_trajectory(kf, u_full, y_full)\n\tsol.ll\nend\n\nplot(svec, lls, xscale=:log10, title=\"Log-likelihood estimation\")\n\nGet the covariance parameter associated with the maximum likelihood:\n\nsvec[argmax(lls)]","category":"section"},{"location":"fault_detection/#Optimize-\"friction\"-and-covariance-jointly","page":"Fault detection","title":"Optimize \"friction\" and covariance jointly","text":"We can add some damping to the velocity state in the double-integrator model. When doing so, we should also estimate the full covariance matrix of the dynamics noise. This gives us an estimation problem with 1 + 3 parameters, 3 for the triangular part of the covariance matrix Cholesky factor. Estimating the Cholesky factor instead of the full covariance matrix yields fewer optimizaiton variables and ensures that the result is a valid, positive definite and symmetric covariance matrix. To ensure that the \"friction parameter\" is positive, we optimize the log of the parameter.\n\nA double integrator has the dynamics matrix\n\nbeginbmatrix\n1  1 \n0  1\nendbmatrix\n\nBy modifying this to\n\nbeginbmatrix\n1  1 \n0  alpha\nendbmatrix\n\nwhere 0 leq alpha leq 1, we can add some damping to the velocity, i.e., if no force is acting on it it will eventually slow down to velocity zero. It's not quite correct to call the parameter alpha a \"damping term\", the formulation beta = 1 - alpha would be closer to an actual discrete-time damping factor.\n\nfunction triangular(x)\n    m = length(x)\n    n = round(Int, sqrt(2m-1))\n    T = zeros(eltype(x), n, n)\n    k = 1\n    for i = 1:n, j = i:n\n        T[i,j] = x[k]\n        k += 1\n    end\n    T\nend\n\ninvtriangular(T) = [T[i,j] for i = 1:size(T,1) for j = i:size(T,1)]\n\nparams = log.([invtriangular(cholesky(R1).U); 1])\n\nfunction get_opt_kf(logp)\n\tT = eltype(logp)\n\tp = exp.(logp)\n\tR1c = triangular(p[1:3]) |> SMatrix{2,2}\n\tR1 = R1c'R1c + 1e-8I\n\tvel = p[4]\n\tvel > 1 && (return T(Inf))\n\tA = SA[1 1; 0 vel]\n\td0T = LowLevelParticleFilters.SimpleMvNormal(T.(d0.Î¼), T.(d0.Î£ + 0.01I))\n\tkf = KalmanFilter(A,B,C,D,R1,R2,d0T; Ts, check=false)\nend\n\nfunction cost(logp)\n\ttry\n\t\tkf = get_opt_kf(logp)\n\t\tsoli, Ïƒs = special_forward_trajectory(kf, u_full, y_full)\n\t\treturn -soli.ll\n\tcatch e\n\t\treturn eltype(logp)(Inf)\n\tend\nend\n\ncost(params)","category":"section"},{"location":"fault_detection/#Optimize","page":"Fault detection","title":"Optimize","text":"res = Optim.optimize(\n    cost,\n    params,\n    LBFGS(),\n    Optim.Options(\n        show_trace        = true,\n        show_every        = 5,\n        iterations        = 1000,\n\t\tx_tol \t\t\t  = 1e-7,\n    ),\n\tautodiff = :forward,\n)\nget_opt_kf(res.minimizer).R1\n\nThe initial guess was \n\nR1\n\nCompare optimized parameter vector with initial guess:\n\nexp.([params res.minimizer])","category":"section"},{"location":"fault_detection/#Visualize-optimized-filtering-trajectory","page":"Fault detection","title":"Visualize optimized filtering trajectory","text":"kf2 = get_opt_kf(res.minimizer)\nsol2, Ïƒs2 = special_forward_trajectory(kf2, u_full[(1:N) .+ (start-1)], y_full[(1:N) .+ (start-1)])\n\nsmoothsol2 = smooth(sol2, kf2, sol2.u, sol2.y)\n\nplot(smoothsol2, plotx=false, plotxt=true, plotRt=true, plotyh=false, plotyht=true, size=(650,600), seriestype=[:line :line :scatter :line], link=:x)\nplot!(timevec, reduce(hcat, smoothsol2.xT)[1,:], sp=3, label=\"Smoothed\")\n\noutliers = findall(Ïƒs2 .> 5)\nvline!([timevec[outliers]], sp=3)\nDisplayAs.PNG(Plots.current()) # hide","category":"section"},{"location":"fault_detection/#Fault-detection-2","page":"Fault detection","title":"Fault detection","text":"We implement a simple fault detector using Z-scores. When the Z-score is higher than 4, we consider it a fault.\n\nplot(timevec, Ïƒs2); hline!([1 2 3 4], label=false)\nDisplayAs.PNG(Plots.current()) # hide\n\n(change the value of the variable start to see different parts of the data set, e.g., set start = 30_000)\n\nZ-scores may not capture large outliers if they occur when the estimator is very uncertain Does Z-score correlate with \"velocity\", i.e., are faults correlated with large continuous slopes in the data?\n\nsol_full, Ïƒs_full = special_forward_trajectory(kf2, u_full, y_full)\nscatter(abs.(getindex.(sol_full.xt, 2)), Ïƒs_full, ylabel=\"Z-score\", xlabel=\"velocity\")\nDisplayAs.PNG(Plots.current()) # hide\n\nnot really, it looks like large Z-scores can appear even when the estimated velocity is small.","category":"section"},{"location":"fault_detection/#Alternative-fault-detection-strategies","page":"Fault detection","title":"Alternative fault-detection strategies","text":"In this tutorial, we used the Z-score of the prediction error to detect faults. A Kalman filter, being a statistical estimator, maintains a belief about the state of the system, whenever this belief is inconsistent with fault-free operation, we may experiencing a fault. Below are some alternative ways in which we can detect faults using a Kalman filter:\n\nA single measurement has a Z-score larger than a threshold. The benefit of this approach is that it can isolate issues to a single sensor.\nThe entire measurement vector has a large Z-score. This can detect issues that cause unexpected correlation in the output, but where each individual output looks as expected on its own.\nThe filter may be augmented with a disturbance model. If the estimated disturbance is larger than expected, e.g., significantly different from zero, it may indicate a fault. See How to tune a Kalman filter and Disturbance gallery for more information on how to do this.\nParameters of the system may be modeled as time-varying and estimated online. If, e.g., an estimated gain parameter decreases significantly, it may indicate a fault. This is similar in spirit to adding a disturbance model, but instead of estimating an input disturbance, we estimate a property of the system. See Joint state and parameter estimation for an example of this.\nAn article suggesting several consistency checks similar to the Z-score check used here is \"New Kalman filter and smoother consistency tests\" by Gibbs, all of which can be readily computed from the quantities saved in the KalmanFilteringSolution object and the result of smooth. One suggestion is to use the filter error and associated filter-error covariance instead of the prediction error, another one is similar but using a smoothed error instead. The last suggestion is to use the smoothed stat error in a similar check.","category":"section"},{"location":"fault_detection/#Summary","page":"Fault detection","title":"Summary","text":"A state estimator can indicate faults when the error is larger than expected\nWhat is expected is determined by the model\n\nThe notebook used in the tutorial is available here:\n\nidentification_12_fault_detection.jl on GitHub","category":"section"},{"location":"cross_covariance/#Cross-covariance-between-process-and-measurement-noise","page":"Cross-covariance between dynamics and measurement","title":"Cross-covariance between process and measurement noise","text":"In standard Kalman filter formulations, the process noise w and measurement noise v are assumed to be uncorrelated. However, in some applications, these noise sources may be correlated. This tutorial demonstrates how to model and account for cross-covariance between process and measurement noise using the R12 parameter.","category":"section"},{"location":"cross_covariance/#Background","page":"Cross-covariance between dynamics and measurement","title":"Background","text":"The standard discrete-time stochastic state-space model is\n\nbeginaligned\nx_k+1 = f(x_k u_k) + w_k \ny_k = h(x_k u_k) + v_k\nendaligned\n\nwhere w_k sim N(0 R_1) is the process noise and v_k sim N(0 R_2) is the measurement noise. The standard assumption is that Ew_k v_j^T = 0 for all k j.\n\nWhen process and measurement noise are correlated, we have\n\ntextCovbeginpmatrix w_k  v_k endpmatrix = beginpmatrix R_1  R_12  R_12^T  R_2 endpmatrix\n\nwhere R_12 = Ew_k v_k^T is the cross-covariance matrix (following the notation in Simon's \"Optimal State Estimation\", Section 7.1).\n\nThis correlation can arise in several scenarios:\n\nWhen process and measurement noise share a common source\nSystems with feedback loops where measurement noise influences the process","category":"section"},{"location":"cross_covariance/#Measurement-models-with-R12-support","page":"Cross-covariance between dynamics and measurement","title":"Measurement models with R12 support","text":"The following measurement models support the R12 cross-covariance parameter:\n\nEKFMeasurementModel: Linearizing measurement model, used by default in ExtendedKalmanFilter\nLinearMeasurementModel: A linear measurement model\nIEKFMeasurementModel: Iteratively linearizing measurement model, used by default in IteratedExtendedKalmanFilter\n\nThe UKFMeasurementModel does not support R12 directly since the unscented transform uses sigma-point propagation rather than analytical covariance formulas. However, you can use an EKFMeasurementModel or LinearMeasurementModel with an UnscentedKalmanFilter to get R12 support while still using the unscented transform for the prediction step.","category":"section"},{"location":"cross_covariance/#Example:-Scalar-system-with-correlated-noise","page":"Cross-covariance between dynamics and measurement","title":"Example: Scalar system with correlated noise","text":"We demonstrate the effect of R12 using a simple scalar system:\n\nbeginaligned\nx_k+1 = 08 x_k + w_k \ny_k = x_k + v_k \ntextCovbeginpmatrix w_k  v_k endpmatrix = beginpmatrix 10  025  025  01 endpmatrix\nendaligned\n\nusing DisplayAs # hide\nusing LowLevelParticleFilters, LinearAlgebra, Plots, Statistics, Random\nusing LowLevelParticleFilters: SimpleMvNormal\nusing StaticArrays\n\n# System parameters\nA   = SA[0.8;;]\nB   = SA[0.0;;]\nC   = SA[1.0;;]\nR1  = SA[1.0;;]   # Process noise covariance\nR2  = SA[0.1;;]   # Measurement noise covariance\nR12 = SA[0.25;;]  # Cross-covariance\n\n# Initial state distribution\nd0 = SimpleMvNormal(SA[0.0], SA[1.0;;])\n\n# Dynamics and measurement functions\ndynamics(x, u, p, t)    = A * x\nmeasurement(x, u, p, t) = C * x\nnothing # hide","category":"section"},{"location":"cross_covariance/#Comparing-EKF-with-and-without-R12","page":"Cross-covariance between dynamics and measurement","title":"Comparing EKF with and without R12","text":"We now create two Extended Kalman Filters: one that ignores the cross-covariance (standard approach) and one that accounts for it.\n\n# EKF without R12 (ignoring correlation)\nekf_no_r12 = ExtendedKalmanFilter(dynamics, measurement, R1, R2, d0; nu=1)\n\n# EKF with R12\nekf_with_r12 = ExtendedKalmanFilter(dynamics, measurement, R1, R2, d0; nu=1, R12=R12)\n\nu = fill([], 100) # No control inputs\n\nx, u, y = simulate(ekf_with_r12, u) # Simulate data using the filter with R12\n\n# Run both filters\nsol_no_r12   = forward_trajectory(ekf_no_r12, u, y)\nsol_with_r12 = forward_trajectory(ekf_with_r12, u, y)\nnothing # hide","category":"section"},{"location":"cross_covariance/#Comparing-estimation-performance","page":"Cross-covariance between dynamics and measurement","title":"Comparing estimation performance","text":"The filter that accounts for the cross-covariance achieves a lower steady-state estimation variance. This is expected because it correctly uses all available information about the noise correlation structure.\n\nWe can compare the actual estimation errors:\n\n# Estimation errors\nerr_no_r12   = x .- sol_no_r12.xt   |> stack\nerr_with_r12 = x .- sol_with_r12.xt |> stack\n\nprintln(\"RMS error without R12: \", round(sqrt(mean(abs2, err_no_r12)), digits=4))\nprintln(\"RMS error with R12: \",  round(sqrt(mean(abs2, err_with_r12)), digits=4))\n\nplot(err_no_r12', label=\"Without R12\", xlabel=\"Time step\", ylabel=\"Estimation error\", alpha=0.7)\nplot!(err_with_r12', label=\"With R12\", alpha=0.7)\nDisplayAs.PNG(Plots.current()) # hide","category":"section"},{"location":"cross_covariance/#Using-R12-with-UnscentedKalmanFilter","page":"Cross-covariance between dynamics and measurement","title":"Using R12 with UnscentedKalmanFilter","text":"The UnscentedKalmanFilter uses sigma-point propagation and its native UKFMeasurementModel does not yet support R12. However, you can combine an UKF with an EKFMeasurementModel or LinearMeasurementModel to get R12 support in the correction step:\n\n# Create an EKFMeasurementModel with R12\nmm_ekf_r12 = EKFMeasurementModel{Float64, false}(measurement, R2; nx=1, ny=1, R12=R12)\n\n# Create UKF with this measurement model\nukf_with_r12 = UnscentedKalmanFilter(dynamics, mm_ekf_r12, R1, d0; nu=1, ny=1)\n\nSimilarly, you can use a LinearMeasurementModel with R12:\n\nmm_linear_r12 = LinearMeasurementModel(C, 0, R2; nx=1, ny=1, R12=R12)\nukf_linear_r12 = UnscentedKalmanFilter(dynamics, mm_linear_r12, R1, d0; nu=1, ny=1)","category":"section"},{"location":"cross_covariance/#Summary","page":"Cross-covariance between dynamics and measurement","title":"Summary","text":"When process and measurement noise are correlated:\n\nIgnoring the correlation (setting R12=0) leads to suboptimal estimation with higher estimation-error variance.\nThe R12 parameter can be specified in:\nLinearMeasurementModel\nExtendedKalmanFilter\nEKFMeasurementModel\nIEKFMeasurementModel\nTo use R12 with UnscentedKalmanFilter, provide an EKFMeasurementModel, LinearMeasurementModel, or IEKFMeasurementModel instead of the default UKFMeasurementModel.\nThe mathematical formulas used when R12 is present follow Simon's \"Optimal State Estimation\" Section 7.1:\nInnovation covariance: S = C R C^T + C R_12 + R_12^T C^T + R_2\nKalman gain: K = (R C^T + R_12) S^-1\nUpdated covariance: R^+ = (I - K C) R - K R_12^T","category":"section"},{"location":"discretization/#Discretization","page":"Discretization","title":"Discretization","text":"This package operates exclusively on discrete-time dynamics, and dynamics describing, e.g., ODE systems must thus be discretized. This page describes the details around discretization for nonlinear and linear systems, as well as how to discretize continuous-time noise processes. ","category":"section"},{"location":"discretization/#Nonlinear-ODEs","page":"Discretization","title":"Nonlinear ODEs","text":"Continuous-time dynamics functions on the form (x,u,p,t) -> xÌ‡ can be discretized (integrated) using the function SeeToDee.Rk4, e.g.,\n\nusing SeeToDee\ndiscrete_dynamics = SeeToDee.Rk4(continuous_dynamics, sampletime; supersample=1)\n\nwhere the integer supersample determines the number of RK4 steps that is taken internally for each change of the control signal (1 is often sufficient and is the default). The returned function discrete_dynamics is on the form (x,u,p,t) -> xâº.\n\nnote: Note\nWhen solving state-estimation problems, accurate integration is often less important than during simulation. The motivations for this are severalThe dynamics model is often inaccurate, and solving an inaccurate model to high accuracy can be a waste of effort.\nThe performance is often dictated by the disturbances acting on the system.\nState-estimation enjoys feedback from measurements that corrects for slight errors due to integration.","category":"section"},{"location":"discretization/#Linear-systems","page":"Discretization","title":"Linear systems","text":"A linear system on the form \n\nbeginaligned\ndotx(t) = Ax(t) + Bu(t)\ny(t) = Cx(t) + Du(t)\nendaligned\n\ncan be discretized using ControlSystems.c2d, which defaults to a zero-order hold discretization. See the example below for more info.","category":"section"},{"location":"discretization/#Covariance-matrices","page":"Discretization","title":"Covariance matrices","text":"Covariance matrices for continuous-time noise processes can also be discretized using ControlSystems.c2d\n\nusing ControlSystemIdentification\nR1d      = c2d(sys::StateSpace{Continuous}, R1c, Ts)\nR1d, R2d = c2d(sys::StateSpace{Continuous}, R1c, R2c, Ts)\nR1d      = c2d(sys::StateSpace{Discrete},   R1c)\nR1d, R2d = c2d(sys::StateSpace{Discrete},   R1c, R2c)\n\nThis samples a continuous-time covariance matrix to fit the provided system sys.\n\nThe method used comes from theorem 5 in the reference below.\n\nRef: \"Discrete-time Solutions to the Continuous-time Differential Lyapunov Equation With Applications to Kalman Filtering\",  Patrik Axelsson and Fredrik Gustafsson\n\nOn singular covariance matrices: The traditional double integrator with covariance matrix Q = diagm([0,ÏƒÂ²]) warrants special consideration since it is rank-deficient, i.e., it indicates that there is a single source of randomness only, despite the presence of two state variables. If we assume that the noise is piecewise constant, we can use the input matrix (\"Cholesky factor\") of Q, e.g., the noise of variance ÏƒÂ² enters like N = [0, 1] which is sampled using ZoH and becomes Nd = [Ts^2 / 2; Ts] which results in the covariance matrix ÏƒÂ² * Nd * Nd' (see example below). If we instead assume that the noise is a continuous-time white noise process, the discretized covariance matrix is full rank and can be computed by c2d(sys::StateSpace{Continuous}, R1c, Ts) or directly by the function double_integrator_covariance_smooth.\n\nFor higher-order integrators (n > 2), the functions n_integrator_covariance and n_integrator_covariance_smooth provide the corresponding covariance matrices for piecewise constant and continuous white noise, respectively.","category":"section"},{"location":"discretization/#Example","page":"Discretization","title":"Example","text":"The following example will discretize a linear double integrator system. Double integrators arise when the position of an object is controlled by a force, i.e., when Newtons second law f = ma governs the dynamics. The system can be written on the form\n\nbeginaligned\ndot x(t) = Ax(t) + Bu(t) + Nw(t)\ny(t) = Cx(t) + e(t)\nendaligned\n\nwhere N = B are both equal to [0, 1], indicating that the noise w(t) enters like a force (this could be for instance due to air resistance or friction).\n\nWe start by defining the system that takes u as an input and discretize that with a sample time of T_s = 01.\n\nusing ControlSystemsBase\nA = [0 1; 0 0]\nB = [0; 1;;]\nC = [1 0]\nD = 0\nTs = 0.1 # Sample time\n\nsys = ss(A,B,C,D)\nsysd = c2d(sys, Ts) # Discretize the dynamics\n\nWe then form another system, this time with w(t) as the input, and thus N as the input matrix instead of B. We assume that the noise has a standard deviation of sigma_1 = 05\n\nÏƒ1 = 0.5\nN  = Ïƒ1*[0; 1;;]\nsys_w  = ss(A,N,C,D)\nsys_wd = c2d(sys_w, Ts) # Discretize the noise system\nNd  = sys_wd.B # The discretized noise input matrix\nR1d = Nd*Nd' # The final discrete-time covariance matrix\n\nWe can verify that the matrix we computed corresponds to the theoretical covariance matrix for a discrete-time double integrator where the noise is piecewise constant:\n\nR1d â‰ˆ Ïƒ1^2*[Ts^2 / 2; Ts]*[Ts^2 / 2; Ts]'\n\nIf the noise is not piecewise constant the discretized covariance matrix will be full rank, but a good rank-1 approximation in this case is R1d ./ Ts.\n\nFor a nonlinear system, we could adopt a similar strategy by first linearizing the system around a suitable operating point. Alternatively, we could make use of the fact that some of the state estimators in this package allows the covariance matrices to be functions of the state, and thus compute a new discretized covariance matrix using a linearization around the current state.","category":"section"},{"location":"discretization/#Sample-interval-insensitive-tuning","page":"Discretization","title":"Sample-interval insensitive tuning","text":"When the dynamics covariance of a state estimator is tuned, it may be desirable to have the covariance dynamics be approximately invariant to the choice of sample interval T_s. How to achieve this depends on what formulation of the dynamics is used, in particular, whether the noise inputs are included in the discretization procedure or not. Note, when a higher sample-rate implies the use of more frequent measurements, the covariance dynamics will not be rendered invariant to the sample interval using the methods below, only the covariance dynamics during prediction only will have this property.","category":"section"},{"location":"discretization/#Noise-inputs-are-not-discretized","page":"Discretization","title":"Noise inputs are not discretized","text":"This case arises when using the standard KalmanFilter with dynamics equation\n\nx^+ = Ax + Bu + w\n\nor a nonlinear version with dynamics(x, u, p, t). To achieve sample-rate invariant tuning, construct the covariance matrix as R1 = [...] .* Ts, i.e., tune a matrix that is scaled by the the sample interval. If you later change Ts, you'll get approximately the same performance of the estimator for prediction intervals during which there are no measurements available.","category":"section"},{"location":"discretization/#Noise-inputs-are-discretized","page":"Discretization","title":"Noise inputs are discretized","text":"This case arises when using an augmented UnscentedKalmanFilter with dynamics dynamics(x, u, p, t, w) which is discretized using an integrator, such as\n\ndisc_dynamics = SeeToDee.Rk4(dynamics, Ts)\n\nIn this case, the integrator integrates also the noise process, and we instead achieve sample-rate invariant tuning by constructing the covariance matrix as R1 = [...] ./ Ts, i.e., tune a matrix that is scaled by the inverse of the sample interval. \n\nThis case can also arise when using a linear system with noise input, i.e., the dynamics equation\n\ndot x = Ax + Bu + Nw\n\nwhere N is the input matrix for the noise process. When this system is discretized with the input matrix [B N] and the R1 matrix is derived as R_1^d = N_d R_1^c N_d^T, we need to further scale the covariance matrix by 1/Ts, i.e., use R_1^d = frac1T_s N_d R_1^c N_d^T.","category":"section"},{"location":"discretization/#When-using-integrator-covariance-functions","page":"Discretization","title":"When using integrator covariance functions","text":"The function double_integrator_covariance_smooth already has the desired scaling with Ts built in, and this is thus to be used with additive noise that is not discretized. Similarly, n_integrator_covariance_smooth provides the same functionality for higher-order integrators.\n\ndouble_integrator_covariance is for piecewise constant noise and this does generally not lead to sample-rate invariant tuning, however double_integrator_covariance(Ts) ./ Ts does. The same applies to n_integrator_covariance for higher-order integrators.","category":"section"},{"location":"discretization/#Non-uniform-sample-rates","page":"Discretization","title":"Non-uniform sample rates","text":"Special care is needed if the sample rate is not constant, i.e., the time interval between measurements varies. ","category":"section"},{"location":"discretization/#Dropped-samples","page":"Discretization","title":"Dropped samples","text":"A common case is that the sample rate is constant, but some measurements are lost. This case is very easy to handle; the filter loop iterates between two steps\n\nPrediction using predict!(filter, x, u, p, t)\nCorrection using\ncorrect!(f, u, y, p, t) if using the standard measurement model of the filter\ncorrect!(f, mm, u, y, p, t, mm) to use a custom measurement model mm\n\nIf a measurement y is lacking, one simply skips the corresponding call to correct! where y is missing. Repeated calls to predict! corresponds to simulating the system without any feedback from measurements, like if an ODE was solved. Internally, the filter will keep track of the covariance of the estimate, which is likely to grow if no measurements are used to inform the filter about the state of the system.","category":"section"},{"location":"discretization/#Sensors-with-different-sample-rates","page":"Discretization","title":"Sensors with different sample rates","text":"For Kalman-type filters, it is possible to construct custom measurement models, and pass an instance of a measurement model as the second argument to correct!. This allows for sensor fusion with sensors operating at different rates, or when parts of the measurement model are linear, and other parts are nonlinear. See examples in Measurement models for how to construct explicit measurement models.\n\nA video demonstrating the use of multiple measurement models running at different rates is available on YouTube:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/BLsJrW5XXcg?si=bkob76-uJj27-S80\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"section"},{"location":"discretization/#Stochastic-sample-rate","page":"Discretization","title":"Stochastic sample rate","text":"In some situations, such as in event-based systems, the sample rate is truly stochastic. There is no single correct way of handling this, and we instead outline some alternative approaches.\n\nIf the filtering is performed offline on a batch of data, time-varying dynamics can be used, for instance by supplying matrices to a KalmanFilter on the form A[:, :, t], R1[:, :, t]. Each A and R1 is then computed as the discretization with the sample time given as the time between measurement t and measurement t+1.\nA conceptually simple approach is to choose a very small sample interval T_s which is smaller than the smallest occurring sample interval in the data, and approximate each sample interval by rounding it to the nearest integer multiple of T_s. This transforms the problem to an instance of the \"dropped samples\" problem described above.\nMake use of an adaptive integrator instead of the fixed-step rk4 supplied in this package, and manually keep track of the step length that needs to be taken as well as the adjustment to the dynamics covariance.","category":"section"},{"location":"discretization/#Example:-EKF-with-stochastic-sample-rate","page":"Discretization","title":"Example: EKF with stochastic sample rate","text":"The following example demonstrates how to perform EKF filtering when data arrives at stochastic time intervals. We simulate a Dubin's car model (a simple kinematic vehicle model) and filter the data using an Extended Kalman Filter that adapts to varying sample rates. The control inputs are assumed to be updated at a fixed time interval Ts, while measurements arrive stochastically with an interval chosen uniformly at random between 0 and 2s.\n\nusing LowLevelParticleFilters\nusing LowLevelParticleFilters: SimpleMvNormal\nusing SeeToDee\nusing Random, Statistics, LinearAlgebra\nusing StaticArrays\nusing Plots\nRandom.seed!(42)\n\n# Dubin's car continuous-time dynamics\n# State: [x, y, Î¸, v] - position, heading angle, velocity\n# Input: [a, Ï‰] - acceleration, angular velocity\nfunction dubins_car(x, u, p, t)\n    Î¸ = x[3]\n    v = x[4]\n    a = u[1]\n    Ï‰ = u[2]\n    SA[\n        v * cos(Î¸),    # áº‹\n        v * sin(Î¸),    # áº\n        Ï‰,             # Î¸Ì‡\n        a              # vÌ‡\n    ]\nend\n\n# Measurement function - observe position only\nmeasurement(x, u, p, t) = SA[x[1], x[2]]\n\n# System parameters\nnx = 4  # state dimension\nnu = 2  # input dimension\nny = 2  # output dimension\n\n# Base sample time for the filter, the control input is updated at this interval\nTs = 0.1\n\n# Create discretized dynamics\ndiscrete_dynamics = SeeToDee.Rk4(dubins_car, Ts)\n\n# Wrapper that uses the Ts from the parameter\nfunction adaptive_step_dynamics(x, u, p, t)\n    Ts = p # The sample step duration is passed as the parameter\n    return discrete_dynamics(x, u, nothing, t; Ts)\nend\n\n# Control input function of time\nu_func(t) = SA[0.5 * cos(0.5 * t) - 0.1, 0.3 * cos(0.3 * t)]\n\nx0 = SA[0.0, 0.0, 0.0, 1.0]  # Initial state\n\n# Setup EKF\n# Base process noise covariance (will be scaled by Ts during filtering)\nR1_base = Diagonal([0.001, 0.001, 0.001, 0.001])  # Process noise per unit time\nR2 = Diagonal([0.3^2, 0.3^2])                     # Measurement noise\nd0 = SimpleMvNormal(x0, 0.1 * I(4))               # Initial state distribution\n\n# For the EKF constructor, use the base rate scaled according to advice above\nR1 = R1_base * Ts\n\n# Create EKF with adaptive dynamics\n# The dynamics function will receive the time step through the parameter p\nekf = ExtendedKalmanFilter(\n    adaptive_step_dynamics,\n    measurement,\n    R1,\n    R2,\n    d0;\n    nu,\n    ny,\n    p = Ts  # Default time step\n)","category":"section"},{"location":"discretization/#Simulation","page":"Discretization","title":"Simulation","text":"The function simulate_stochastic_ekf! implements both simulation of the plant by means of propagating the true state and filtering the measurements using the EKF. At each time step, a decision is made whether to update the control input or to take a measurement, depending on which event occurs first.\n\nfunction simulate_stochastic_ekf!(\n    ekf, adaptive_step_dynamics, u_func, x0, Tf\n)\n    (; measurement, Ts) = ekf\n    next_control_t  = Ts\n    next_sample_t   = 2rand()\n    t               = 0.0\n    x_true          = x0\n    u               = u_func(t)\n    # Arrays for storing simulation data\n    U               = [u]\n    X               = [x_true]\n    Xf              = [x0]\n    Y               = [measurement(x_true, u, nothing, t)]\n    T               = [t] # Array with all time points\n    Ty              = [t] # Array with only time points with new measurements\n    while t < Tf\n        # We choose how long step to take depending on whether the next event is a measurement arrival or control update\n        if next_sample_t < next_control_t\n            # Step forward to next_sample_t and sample a measurement\n            dt = next_sample_t - t                              # Step length to take, pass this as the parameter\n            R1t = R1_base * dt                                  # Scale process noise covariance by step length. Note the advice above regarding how to perform this scaling depending on discretization context.\n            x_true = adaptive_step_dynamics(x_true, u, dt, t)\n            predict!(ekf, u, dt, t, R1=R1t)                     # Step the filter forward dt time units as well\n            t = next_sample_t                                   # Update the current time\n            y = measurement(x_true, u, nothing, t) + 0.3*randn(ekf.ny) # Simulate a measurement\n            correct!(ekf, u, y, dt, t)                          # Apply filter measurement update\n            push!(Y, y)                                         # Store measurement data for plotting\n            push!(Ty, t)\n            next_sample_t += 2rand()\n        else\n            # Step forward to next_control_t, in this branch there is no new measurement\n            dt      = next_control_t - t\n            R1t     = R1_base * dt # Scale process noise covariance by step length. Note the advice above regarding how to perform this scaling depending on discretization context.\n            x_true  = adaptive_step_dynamics(x_true, u, dt, t)\n            t       = next_control_t\n            predict!(ekf, u, dt, t, R1=R1t)\n            u       = u_func(t)\n            next_control_t += Ts\n        end\n        push!(X, x_true)\n        push!(Xf, ekf.x)\n        push!(T, t)\n        push!(U, u)\n    end\n    return (T, X, Xf, U, Y, Ty)\nend\n\n# Run the simulation\nTf = 20 # Final time, duration of the simulation\nT, X, Xf, U, Y, Ty = simulate_stochastic_ekf!(\n    ekf, adaptive_step_dynamics, u_func, x0, Tf\n)\n\n# Plot true and filtered estimate\nusing Plots\n\n# Xf at Ty times\nXy = reduce(hcat, [x for (t, x) in zip(T, X) if t in Ty])'\nXfy = reduce(hcat, [x for (t, x) in zip(T, Xf) if t in Ty])'\n\n# Compute filtering errors \nEf = (Xy .- Xfy)[:, 1:2]\nEy = (Xy[:, 1:2] .- reduce(hcat, Y)')\n\nplot(T, reduce(hcat, X)', label=\"\\$x\\$\", layout=4)\nscatter!(Ty, Xfy, label=\"\\$x(t|t)\\$\", markersize=3, markerstrokewidth=0, sp=1:4)\nscatter!(Ty, reduce(hcat, Y)', label=\"\\$y\\$\", markersize=3, markerstrokewidth=0, sp=1:2)\n\nIn this example, we performed filtering using an ExtendedKalmanFilter that takes nonlinear dynamics discretized with an RK4 integrator. When the dynamics are linear and we employ a standard KalmanFilter, varying-length discretization is similarly handled by providing custom A and B matrices to the predict! function. ZoH discretization of a linear system is performed using the matrix exponential e^A T_s (see implementation of c2d for how to handle also the B matrix at the same time).","category":"section"},{"location":"discretization/#Example:-Adaptive-interval-velocity-estimation-from-encoder-pulses","page":"Discretization","title":"Example: Adaptive interval velocity estimation from encoder pulses","text":"This example demonstrates how one can use a Kalman filter when measurements arrive at irregular intervals. The application is estimation of velocity (and possibly higher-order derivatives) from encoder pulses. An encoder has a fixed number of teeth, and a pulse is generated each time a tooth crosses a light sensor. For simplicity, we do not model the specifics of the encoder here, and instead simply generate a position measurement whenever a simulated position signal mas moved a certain amount (corresponding to the distance between teeth).\n\nThe Kalman filter is setup using a model corresponding to a series of n = filter_order integrators with nominal values for covariance and dynamics and in the loop as measurements arrive, we discretize the continuous-time dynamical model with the interval between the current and last obtained measurement. This discretization involves not only the dynamics, we also compute the discrete-time covariance matrix R_1 corresponding to passing a continuous-time white-noise process through the series of n integrators.\n\nBelow, we show the results for filter order 4 (sometimes called a constant-jerk model). A lower filter order makes the system more responsive to changes in the measurement, while a higher order provides smoother estimates at the cost of increased lag. When viewed in the frequency domain, the filter order controls the slope of the rolloff for high frequencies, while the covariance value, sigma^2 below, controls the cut-off frequency.\n\nFor fun, we use the square-root version of the Kalman filter here, SqKalmanFilter so that we have a demo that uses this as well.\n\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays\nusing LowLevelParticleFilters: SimpleMvNormal\nusing ControlSystemsBase, Plots\ntraj(t)  = t < 10 ? t   :  10cos(t-10)\ntrajv(t) = t < 10 ? 1.0 : -10sin(t-10)\ntraja(t) = t < 10 ? 0.0 : -10cos(t-10)\n\nto_step(x, n) = floor(x*n)/n\nfunction find_crossings(traj::F, resolution) where F\n    # resolution is given in number of levels per unit position\n    t_candidates = 0:1e-6:20\n    crossings = Float64[]\n    t0 = to_step(traj(t_candidates[1]), resolution)\n    for t in 1:length(t_candidates) - 1\n        t1 = to_step(traj(t_candidates[t + 1]), resolution)\n        if t0 != t1\n            # Interpolate to get accurate t crossing\n            t_cross = t_candidates[t]\n            push!(crossings, t_cross)\n            t0 = t1\n        end\n    end\n    return crossings\nend\n\nsample_times = find_crossings(traj, 1)\npos_measurements = traj.(sample_times)\nvel_measurements = diff(pos_measurements) ./ diff(sample_times)\n##\nplot(traj, 0, 20, layout=(2,1))\nscatter!(sample_times, traj.(sample_times), sp=1)\nplot!(trajv, 0, 20, sp=2)\nscatter!(sample_times[2:end], vel_measurements, sp=2)\n\n##\n\nfilter_order = 4 # This controls the slope of the rolloff for high frequencies\nP = ss((1/tf('s')))^filter_order\n(; A, C, D) = P\nB  = @SMatrix zeros(filter_order, 0)\nTs = 0.1\nÏƒ2 = 1e5 # This controls the amount of filtering. Higher value gives a smoother but laggier response\nR1 = LowLevelParticleFilters.n_integrator_covariance_smooth(P.nx, Ts, Ïƒ2)\nR2 = [1.0;;]\nd0 = SimpleMvNormal(1e9R1)\nkf = SqKalmanFilter(to_static(A), B, to_static(C), to_static(D), R1, R2, d0)\nchol(x) = cholesky(x).U\nfunction kf_velocity_estimation!(\n    kf, sample_times\n)\n    (; Ts) = kf\n    Xf = [copy(kf.x)]\n    for i = 2:length(sample_times)\n        t0 = sample_times[i-1]\n        t1 = sample_times[i]\n        dt = t1 - t0\n        Ai = exp(A*dt)\n        R1 = LowLevelParticleFilters.n_integrator_covariance_smooth(kf.nx, dt, Ïƒ2) |> chol # This is the solution to a fixed-horizon Lyapunov equation\n        predict!(kf, nothing, nothing, t0; At=Ai, R1)\n        y = pos_measurements[i]\n        correct!(kf, nothing, y, nothing, t1)\n        push!(Xf, copy(kf.x))\n    end\n    Xf\nend\nXf = kf_velocity_estimation!(kf, sample_times)\nXF = reduce(hcat, Xf)'\n##\nscatter(sample_times, XF, lab=permutedims([\"\\$\\\\frac{d^$(i)\\\\hat{x}}{dt^$(i)}\\$\" for i in 0:filter_order-1]), layout=(filter_order,1), size=(1000,1000), markerstrokewidth=1, m=:cross)\nplot!(traj, 0, 20, lab=\"True Position\")\nplot!(trajv, 0, 20, sp=2, lab=\"True Velocity\")\nplot!(traja, 0, 20, sp=3, lab=\"True Acceleration\")\n\nNotice how there are no measurements for a while when the velocity changes sign (the velocity is low), while there are more frequent measurements when the velocity is high.","category":"section"},{"location":"benchmark/#Benchmarks","page":"Benchmark","title":"Benchmarks","text":"","category":"section"},{"location":"benchmark/#Particle-filtering","page":"Benchmark","title":"Particle filtering","text":"To see how the performance varies with the number of particles, we simulate several times. The following code simulates the system and performs filtering using the simulated measurements. We do this for varying number of time steps and varying number of particles.\n\nnote: Note\nTo run this code, see the bottom of src/example_lineargaussian.jl.\n\nfunction run_test()\n    particle_count = [10, 20, 50, 100, 200, 500, 1000]\n    time_steps = [20, 100, 200]\n    RMSE = zeros(length(particle_count),length(time_steps)) # Store the RMS errors\n    propagated_particles = 0\n    t = @elapsed for (Ti,T) = enumerate(time_steps)\n        for (Ni,N) = enumerate(particle_count)\n            montecarlo_runs = 2*maximum(particle_count)*maximum(time_steps) Ã· T Ã· N\n            E = sum(1:montecarlo_runs) do mc_run\n                pf = ParticleFilter(N, dynamics, measurement, df, dg, d0) # Create filter\n                u = @SVector randn(2)\n                x = SVector{2,Float64}(rand(rng, d0))\n                y = SVector{2,Float64}(sample_measurement(pf,x,u,0,1))\n                error = 0.0\n                @inbounds for t = 1:T-1\n                    pf(u, y) # Update the particle filter\n                    x = dynamics(x,u,t) + SVector{2,Float64}(rand(rng, df)) # Simulate the true dynamics and add some noise\n                    y = SVector{2,Float64}(sample_measurement(pf,x,u,0,t)) # Simulate a measuerment\n                    u = @SVector randn(2) # draw a random control input\n                    error += sum(abs2,x-weighted_mean(pf))\n                end # t\n                âˆš(error/T)\n            end # MC\n            RMSE[Ni,Ti] = E/montecarlo_runs\n            propagated_particles += montecarlo_runs*N*T\n            @show N\n        end # N\n        @show T\n    end # T\n    println(\"Propagated $propagated_particles particles in $t seconds for an average of $(propagated_particles/t/1000) particles per millisecond\")\n    return RMSE\nend\n\n@time RMSE = run_test()\n\nPropagated 8400000 particles in 1.140468043 seconds for an average of 7365.397085484139 particles per millisecond\n\nWe then plot the results\n\ntime_steps     = [20, 100, 200]\nparticle_count = [10, 20, 50, 100, 200, 500, 1000]\nnT             = length(time_steps)\nleg            = reshape([\"$(time_steps[i]) time steps\" for i = 1:nT], 1,:)\nplot(particle_count,RMSE,xscale=:log10, ylabel=\"RMS errors\", xlabel=\" Number of particles\", lab=leg)\n\n(Image: window)","category":"section"},{"location":"benchmark/#Comparison-against-filterpy","page":"Benchmark","title":"Comparison against filterpy","text":"filterpy is a popular Python library for state estimation. Below, we compare performance on their UKF example, but we use a longer trajectory of 50k time steps:","category":"section"},{"location":"benchmark/#Python-implementation","page":"Benchmark","title":"Python implementation","text":"from filterpy import *\nfrom filterpy.kalman import *\nimport numpy as np\nfrom numpy.random import randn\nfrom filterpy.common import Q_discrete_white_noise\nimport time\ndef fx(x, dt):\n    # state transition function - predict next state based\n    # on constant velocity model x = vt + x_0\n    F = np.array([[1, dt, 0, 0],\n                  [0, 1, 0, 0],\n                  [0, 0, 1, dt],\n                  [0, 0, 0, 1]], dtype=float)\n    return np.dot(F, x)\n\ndef hx(x):\n   # measurement function - convert state into a measurement\n   # where measurements are [x_pos, y_pos]\n   return np.array([x[0], x[2]])\n\ndt = 0.1\n# create sigma points to use in the filter. This is standard for Gaussian processes\npoints = MerweScaledSigmaPoints(4, alpha=.1, beta=2., kappa=-1)\n\nkf = UnscentedKalmanFilter(dim_x=4, dim_z=2, dt=dt, fx=fx, hx=hx, points=points)\nkf.x = np.array([-1., 1., -1., 1]) # initial state\nkf.P *= 0.2 # initial uncertainty\nz_std = 0.1\nkf.R = np.diag([z_std**2, z_std**2]) # 1 standard\nkf.Q = Q_discrete_white_noise(dim=2, dt=dt, var=0.01**2, block_size=2)\n\nzs = [[i+randn()*z_std, i+randn()*z_std] for i in range(50000)] # measurements\n\nstart_time = time.time()\n\nfor z in zs:\n    kf.predict()\n    kf.update(z)\n    # print(kf.x, 'log-likelihood', kf.log_likelihood)\n\nend_time = time.time()\nprint(f\"Execution time: {end_time - start_time} seconds\")\n\nExecution time: 6.390492916107178 seconds","category":"section"},{"location":"benchmark/#Julia-implementation","page":"Benchmark","title":"Julia implementation","text":"using LowLevelParticleFilters, StaticArrays, LinearAlgebra, BenchmarkTools\nconst dt = 0.1\nfunction fx(x,u,p,t)\n    # state transition function - predict next state based\n    # on constant velocity model x = vt + x_0\n    F = SA[1.0 dt 0.0 0.0;\n         0.0 1.0 0.0 0.0;\n         0.0 0.0 1.0 dt;\n         0.0 0.0 0.0 1.0]\n    return F*x\nend\n\nfunction hx(x,u,p,t)\n    # measurement function - convert state into a measurement\n    # where measurements are [x_pos, y_pos]\n    return x[SA[1,3]]\nend\n\nx0 = SA[-1.0, 1.0, -1.0, 1.0] # initial state\nR0 = 0.2I(4) # initial uncertainty\nz_std = 0.1\nR1 = LowLevelParticleFilters.double_integrator_covariance(dt, 0.01^2)\nR1 = SMatrix{4,4}(cat(R1, R1, dims=(1,2)))  # Called Q in the Python code\nR2 = Diagonal(SA[z_std^2, z_std^2])         # Called R in the Python code\nd0 = LowLevelParticleFilters.SimpleMvNormal(x0, R0)\nukf = UnscentedKalmanFilter(fx, hx, R1, R2, d0; nu=0, ny=2, Ts=dt, p=nothing)\nzs = [[i+randn()*z_std, i+randn()*z_std] for i in 1:50000] # measurements\n\nfunction runsim(ukf, zs)\n    for z in zs\n        predict!(ukf, SA[])\n        ll, _ = correct!(ukf, SA[], z)\n        # @show ll\n    end\nend\n\nrunsim(ukf, zs)\n\ntime_julia = @belapsed runsim($ukf, $zs)\n\n0.017676814","category":"section"},{"location":"benchmark/#Result","page":"Benchmark","title":"Result","text":"time_python = 6.390492916107178\ntime_python / time_julia\n\n361.51836615507625\n\nThe Julia version is about 360x faster than the Python version.","category":"section"},{"location":"#LowLevelParticleFilters","page":"Home","title":"LowLevelParticleFilters","text":"(Image: CI) (Image: codecov)\n\nThis is a library for state estimation, that is, given measurements y(t) from a dynamical system, estimate the state vector x(t). Throughout, we assume dynamics on the form\n\nbeginaligned\nx(t+1) = f(x(t) u(t) p t w(t))\ny(t) = g(x(t) u(t) p t e(t))\nendaligned\n\nor the linear version\n\nbeginaligned\nx(t+1) = Ax(t) + Bu(t) + w(t)\ny(t) = Cx(t) + Du(t) + e(t)\nendaligned\n\nwhere x is the state vector, u an input, p some form of parameters, t is the time and we are disturbances (noise). Throughout the documentation, we often call the function f dynamics and the function g measurement.\n\nThe dynamics above describe a discrete-time system, i.e., the function f takes the current state and produces the next state. This is in contrast to a continuous-time system, where f takes the current state but produces the time derivative of the state. A continuous-time system can be discretized, described in detail in Discretization.\n\nThe parameters p can be anything, or left out. You may write the dynamics functions such that they depend on p and include parameters when you create a filter object. You may also override the parameters stored in the filter object when you call any function on the filter object. This behavior is modeled after the SciML ecosystem.\n\nDepending on the nature of f and g, the best method of estimating the state may vary. If fg are linear and the disturbances are additive and Gaussian, the KalmanFilter is an optimal state estimator. If any of the above assumptions fail to hold, we may need to resort to more advanced estimators. This package provides several filter types, outlined below.","category":"section"},{"location":"#Estimator-types","page":"Home","title":"Estimator types","text":"We provide a number of filter types\n\nKalmanFilter. A standard Kalman filter. Is restricted to linear dynamics (possibly time varying) and Gaussian noise.\nSqKalmanFilter. A standard Kalman filter on square-root form (slightly slower but more numerically stable with ill-conditioned covariance).\nExtendedKalmanFilter: For nonlinear systems, the EKF runs a regular Kalman filter on linearized dynamics. Uses ForwardDiff.jl for linearization (or user provided). The noise model must still be Gaussian and additive.\nSqExtendedKalmanFilter: A square-root version of the EKF.\nIteratedExtendedKalmanFilter same as EKF, but performs iteration in the measurement update for increased accuracy in the covariance update.\nUnscentedKalmanFilter: The Unscented Kalman filter often performs slightly better than the Extended Kalman filter but may be slightly more computationally expensive. The UKF handles nonlinear dynamics and measurement models, but still requires a Gaussian noise model (may be non additive) and still assumes that all posterior distributions are Gaussian, i.e., can not handle multi-modal posteriors.\nEnsembleKalmanFilter: The Ensemble Kalman filter uses an ensemble of states instead of explicitly tracking the covariance matrix. This makes it suitable for high-dimensional systems where covariance matrices become intractable. Uses the stochastic EnKF formulation with perturbed observations. Like the UKF, it handles nonlinear dynamics but assumes Gaussian posteriors.\nParticleFilter: The particle filter is a nonlinear estimator. This version of the particle filter is simple to use and assumes that both dynamics noise and measurement noise are additive. Particle filters handle multi-modal posteriors.\nAdvancedParticleFilter: This filter gives you more flexibility, at the expense of having to define a few more functions. This filter does not require the noise to be additive and is thus the most flexible filter type.\nAuxiliaryParticleFilter: This filter is identical to ParticleFilter, but uses a slightly different proposal mechanism for new particles.","category":"section"},{"location":"#Experimental-estimator-types","page":"Home","title":"Experimental estimator types","text":"Additionally, these filter types are currently considered experimental and may change in future releases without respecting semantic versioning.\n\nIMM: The Interacting Multiple Models filter switches between multiple internal filters based on a hidden Markov model. This filter is useful when the system dynamics change over time and the change can be modeled as a discrete Markov chain, i.e., the system may switch between a small number of discrete \"modes\".\nRBPF: A Rao-Blackwellized (marginalized) particle filter that uses a Kalman filter for the linear part of the state and a particle filter for the nonlinear part.\nMUKF: A Rao-Blackwellized (marginalized) Unscented Kalman Filter that combines an Unscented Kalman Filter for the nonlinear substate with a bank of Kalman filters (one per sigma point) for the linear substate. Similar to RBPF but uses deterministic sigma points instead of random particles.\nUIKalmanFilter: An Unknown Input Kalman Filter that estimates both the state and unknown inputs to a linear system without augmenting the state vector. See Gillijns & De Moor (2007), \"Unbiased minimum-variance input and state estimation for linear discrete-time systems\".","category":"section"},{"location":"#Functionality","page":"Home","title":"Functionality","text":"This package provides \n\nFiltering, estimating x(t) given measurements up to and including time t. We call the filtered estimate x(tt) (read as x at t given t).\nSmoothing, estimating x(t) given data up to T  t, i.e., x(tT).\nParameter estimation.\n\nAll filters work in two distinct steps.\n\nThe prediction step (predict!). During prediction, we use the dynamics model to form x(tt-1) = f(x(t-1) )\nThe correction step (correct!). In this step, we adjust the predicted state x(tt-1) using the measurement y(t) to form x(tt).\n\nThe following two exceptions to the above exist\n\nThe IMM filter has two additional steps, combine! and interact!\nThe AuxiliaryParticleFilter makes use of the next measurement in the dynamics update, and thus only has an update! method.\n\nIn general, all filters represent not only a point estimate of x(t), but a representation of the complete posterior probability distribution over x given all the data available up to time t. One major difference between different filter types is how they represent these probability distributions.","category":"section"},{"location":"#Particle-filter","page":"Home","title":"Particle filter","text":"A particle filter represents the probability distribution over the state as a collection of samples, each sample is propagated through the dynamics function f individually. When a measurement becomes available, the samples, called particles, are given a weight based on how likely the particle is given the measurement. Each particle can thus be seen as representing a hypothesis about the current state of the system. After a few time steps, most weights are inevitably going to be extremely small, a manifestation of the curse of dimensionality, and a resampling step is incorporated to refresh the particle distribution and focus the particles on areas of the state space with high posterior probability.\n\nDefining a particle filter (ParticleFilter) is straightforward, one must define the distribution of the noise df in the dynamics function, dynamics(x,u,p,t) and the noise distribution dg in the measurement function measurement(x,u,p,t). Both of these noise sources are assumed to be additive, but can have any distribution (see AdvancedParticleFilter for non-additive noise). The distribution of the initial state estimate d0 must also be provided. In the example below, we use linear Gaussian dynamics so that we can easily compare both particle and Kalman filters. (If we have something close to linear Gaussian dynamics in practice, we should of course use a Kalman filter and not a particle filter.)\n\nusing LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots\nusing DisplayAs # hide\n\nDefine problem\n\nnx = 2   # Dimension of state\nnu = 1   # Dimension of input\nny = 1   # Dimension of measurements\nN = 500  # Number of particles\n\nconst dg = MvNormal(ny,0.2)          # Measurement noise Distribution\nconst df = MvNormal(nx,0.1)          # Dynamics noise Distribution\nconst d0 = MvNormal(randn(nx),2.0)   # Initial state Distribution\nnothing # hide\n\nDefine linear state-space system (using StaticArrays for maximum performance)\n\nconst A = SA[0.97043   -0.097368\n             0.09736    0.970437]\nconst B = SA[0.1; 0;;]\nconst C = SA[0 1.0]\nnothing # hide\n\nNext, we define the dynamics and measurement equations, they both take the signature (x,u,p,t) = (state, input, parameters, time) \n\ndynamics(x,u,p,t) = A*x .+ B*u\nmeasurement(x,u,p,t) = C*x\nvecvec_to_mat(x) = copy(reduce(hcat, x)') # Helper function\nnothing # hide\n\nthe parameter p can be anything, and is often optional. If p is not provided when performing operations on filters, any p stored in the filter objects (if supported) is used. The default if none is provided and none is stored in the filter is p = LowLevelParticleFilters.NullParameters().\n\nWe are now ready to define and use a filter\n\npf = ParticleFilter(N, dynamics, measurement, df, dg, d0)\n\nWith the filter in hand, we can simulate from its dynamics and query some properties\n\ndu = MvNormal(nu,1.0)         # Random input distribution for simulation\nxs,u,y = simulate(pf,200,du) # We can simulate the model that the pf represents\npf(u[1], y[1])               # Perform one filtering step using input u and measurement y\nparticles(pf)                # Query the filter for particles, try weights(pf) or expweights(pf) as well\nxÌ‚ = weighted_mean(pf)        # using the current state\n\nIf you want to perform batch filtering using an existing trajectory consisting of vectors of inputs and measurements, try any of the functions forward_trajectory, mean_trajectory:\n\nsol = forward_trajectory(pf, u, y) # Filter whole trajectories at once\nxÌ‚,ll = mean_trajectory(pf, u, y)\nplot(sol, xreal=xs, markersize=2)\nDisplayAs.PNG(Plots.current()) # hide\n\nu ad y are then assumed to be vectors of vectors. StaticArrays is recommended for maximum performance.\n\nWe can also plot weighted quantiles instead of 2D histograms by providing a vector of desired quantiles through the q keyword argument\n\nplot(sol, xreal=xs, markersize=2, q=[0.1, 0.5, 0.9], ploty=false, legend=true)\nDisplayAs.PNG(Plots.current()) # hide\n\nIf MonteCarloMeasurements.jl is loaded, you may transform the output particles to Matrix{MonteCarloMeasurements.Particles} with the layout T Ã— n_state using Particles(x,we). Internally, the particles are then resampled such that they all have unit weight. This is conventient for making use of the plotting facilities of MonteCarloMeasurements.jl.\n\nFor a full usage example, see the benchmark section below or example_lineargaussian.jl","category":"section"},{"location":"#Resampling","page":"Home","title":"Resampling","text":"The particle filter will perform a resampling step whenever the distribution of the weights has become degenerate. The resampling is triggered when the effective number of samples is smaller than pf.resample_threshold in 0 1, this value can be set when constructing the filter. How the resampling is done is governed by pf.resampling_strategy, we currently provide ResampleSystematic <: ResamplingStrategy as the only implemented strategy. See https://en.wikipedia.org/wiki/Particle_filter for more info.","category":"section"},{"location":"#Particle-Smoothing","page":"Home","title":"Particle Smoothing","text":"Smoothing is the process of finding the best state estimate given both past and future data. Smoothing is thus only possible in an offline setting. This package provides a particle smoother, based on forward filtering, backward simulation (FFBS), example usage follows:\n\nN     = 2000 # Number of particles\nT     = 80   # Number of time steps\nM     = 100  # Number of smoothed backwards trajectories\npf    = ParticleFilter(N, dynamics, measurement, df, dg, d0)\ndu    = MvNormal(nu,1)     # Control input distribution\nx,u,y = simulate(pf,T,du) # Simulate trajectory using the model in the filter\ntosvec(y) = reinterpret(SVector{length(y[1]),Float64}, reduce(hcat,y))[:] |> copy\nx,u,y = tosvec.((x,u,y)) # It's good for performance to use StaticArrays to the extent possible\n\nxb,ll = smooth(pf, M, u, y) # Sample smoothing particles\nxbm   = smoothed_mean(xb)   # Calculate the mean of smoothing trajectories\nxbc   = smoothed_cov(xb)    # And covariance\nxbt   = smoothed_trajs(xb)  # Get smoothing trajectories\nxbs   = [diag(xbc) for xbc in xbc] |> vecvec_to_mat .|> sqrt\nplot(xbm', ribbon=2xbs, lab=\"PF smooth\")\nplot!(vecvec_to_mat(x), l=:dash, lab=\"True\")\n\nWe can plot the particles themselves as well\n\ndownsample = 5\nplot(vecvec_to_mat(x), l=(4,), layout=(2,1), show=false)\nscatter!(xbt[1, 1:downsample:end, :]', subplot=1, show=false, m=(1,:black, 0.5), lab=\"\")\nscatter!(xbt[2, 1:downsample:end, :]', subplot=2, m=(1,:black, 0.5), lab=\"\")\nDisplayAs.PNG(Plots.current()) # hide","category":"section"},{"location":"#Kalman-filter","page":"Home","title":"Kalman filter","text":"The KalmanFilter (wiki) assumes that f and g are linear functions, i.e., that they can be written on the form\n\nbeginaligned\nx(t+1) = Ax(t) + Bu(t) + w(t)\ny(t) = Cx(t) + Du(t) + e(t)\nendaligned\n\nfor some matrices ABCD where w sim N(0 R_1) and e sim N(0 R_2) are zero mean and Gaussian. The Kalman filter represents the posterior distributions over x by the mean and a covariance matrix. The magic behind the Kalman filter is that linear transformations of Gaussian distributions remain Gaussian, and we thus have a very efficient way of representing them.\n\nA Kalman filter is easily created using the constructor KalmanFilter. Many of the functions defined for particle filters, are defined also for Kalman filters, e.g.:\n\nR1 = cov(df)\nR2 = cov(dg)\nkf = KalmanFilter(A, B, C, 0, R1, R2, d0)\nsol = forward_trajectory(kf, u, y) # sol contains filtered state, predictions, pred cov, filter cov, loglik\nnothing # hide\n\nIt can also be called in a loop like the pf above\n\nfor t = 1:T\n    kf(u,y) # Performs both correct! and predict!\n    # alternatively\n    ll, e = correct!(kf, y, nothing, t) # Returns loglikelihood and prediction error (plus other things if you want)\n    x     = state(kf)       # Access the state estimate\n    R     = covariance(kf)  # Access the covariance of the estimate\n    predict!(kf, u, nothing, t)\nend\n\nThe matrices in the Kalman filter may be time varying, such that A[:, :, t] is A(t). They may also be provided as functions on the form A(t) = A(x u p t). This works for both dynamics and covariance matrices. When providing functions, the dimensions of the state, input and output, nx, nu, ny, must be provided as keyword arguments to the filter constructor since these cannot be inferred from the function signature.\n\nThe numeric type used in the Kalman filter is determined from the mean of the initial state distribution, so make sure that this has the correct type if you intend to use, e.g., Float32 or ForwardDiff.Dual for automatic differentiation.","category":"section"},{"location":"#Smoothing-using-KF","page":"Home","title":"Smoothing using KF","text":"Kalman filters can also be used for smoothing \n\nkf = KalmanFilter(A, B, C, 0, cov(df), cov(dg), d0)\nsmoothsol = smooth(kf, u, y) # Returns a smoothing solution including smoothed state and smoothed cov\nnothing # hide\n\nPlot and compare PF and KF\n\n# plot(smoothsol) The smoothing solution object can also be plotted directly\nplot(vecvec_to_mat(smoothsol.xT), lab=\"Kalman smooth\", layout=2)\nplot!(xbm', lab=\"pf smooth\")\nplot!(vecvec_to_mat(x), lab=\"true\")","category":"section"},{"location":"#Kalman-filter-tuning-tutorial","page":"Home","title":"Kalman filter tuning tutorial","text":"The tutorial \"How to tune a Kalman filter\" details how to figure out appropriate covariance matrices for the Kalman filter, as well as how to add disturbance models to the system model.","category":"section"},{"location":"#Unscented-Kalman-Filter","page":"Home","title":"Unscented Kalman Filter","text":"The UnscentedKalmanFilter represents posterior distributions over x as Gaussian distributions just like the KalmanFilter, but propagates them through a nonlinear function f by a deterministic sampling of a small number of particles called sigma points (this is referred to as the unscented transform). This UKF thus handles nonlinear functions fg, but only Gaussian disturbances and unimodal posteriors. The UKF will by default treat the noise as additive, but by using the augmented UKF form, non-additive noise may be handled as well. See the docstring of UnscentedKalmanFilter for more details.\n\nThe UKF takes the same arguments as a regular KalmanFilter, but the matrices defining the dynamics are replaced by two functions, dynamics and measurement, working in the same way as for the ParticleFilter above (unless the augmented form is used).\n\nukf = UnscentedKalmanFilter(dynamics, measurement, cov(df), cov(dg), MvNormal(SA[1.,1.]); nu, ny)\n\ninfo: Info\nIf your function dynamics describes a continuous-time ODE, do not forget to discretize it before passing it to the UKF. See Discretization for more information.\n\nThe UnscentedKalmanFilter has many customization options, see the docstring for more details. In particular, the UKF may be created with a linear measurement model as an optimization.","category":"section"},{"location":"#Extended-Kalman-Filter","page":"Home","title":"Extended Kalman Filter","text":"The ExtendedKalmanFilter (EKF) is similar to the UKF, but propagates Gaussian distributions by linearizing the dynamics and using the formulas for linear systems similar to the standard Kalman filter. This can be slightly faster than the UKF (not always), but also less accurate for strongly nonlinear systems. The linearization is performed automatically using ForwardDiff.jl unless the user provides Jacobian functions that compute A and C. In general, the UKF is recommended over the EKF unless the EKF is faster and computational performance is the top priority.\n\nThe EKF constructor has the following two signatures\n\nExtendedKalmanFilter(dynamics, measurement, R1, R2, d0=MvNormal(R1); nu::Int, p = LowLevelParticleFilters.NullParameters(), Î± = 1.0, check = true, Ajac = nothing, Cjac = nothing)\nExtendedKalmanFilter(kf, dynamics, measurement; Ajac = nothing, Cjac = nothing)\n\nThe first constructor takes all the arguments required to initialize the extended Kalman filter, while the second one takes an already defined standard Kalman filter. using the first constructor, the user must provide the number of inputs to the system, nu.\n\nwhere kf is a standard KalmanFilter from which the covariance properties are taken.\n\ninfo: Info\nIf your function dynamics describes a continuous-time ODE, do not forget to discretize it before passing it to the UKF. See Discretization for more information.","category":"section"},{"location":"#AdvancedParticleFilter","page":"Home","title":"AdvancedParticleFilter","text":"The AdvancedParticleFilter works very much like the ParticleFilter, but admits more flexibility in its noise models.\n\nThe AdvancedParticleFilter type requires you to implement the same functions as the regular ParticleFilter, but in this case you also need to handle sampling from the noise distributions yourself. The function dynamics must have a method signature like below. It must provide one method that accepts state vector, control vector, parameter, time and noise::Bool that indicates whether or not to add noise to the state. If noise should be added, this should be done inside dynamics An example is given below\n\nusing Random\nconst rng = Random.Xoshiro()\nfunction dynamics(x, u, p, t, noise=false) # It's important that `noise` defaults to false\n    x = A*x .+ B*u # A simple linear dynamics model in discrete time\n    if noise\n        x += rand(rng, df) # it's faster to supply your own rng\n    end\n    x\nend\nnothing # hide\n\nThe measurement_likelihood function must have a method accepting state, input, measurement, parameter and time, and returning the log-likelihood of the measurement given the state, a simple example below:\n\nfunction measurement_likelihood(x, u, y, p, t)\n    logpdf(dg, C*x-y) # An example of a simple linear measurement model with normal additive noise\nend\nnothing # hide\n\nThis gives you very high flexibility. The noise model in either function can, for instance, be a function of the state, something that is not possible for the simple ParticleFilter. To be able to simulate the AdvancedParticleFilter like we did with the simple filter above, the measurement method with the signature measurement(x,u,p,t,noise=false) must be available and return a sample measurement given state (and possibly time). For our example measurement model above, this would look like this\n\n# This function is only required for simulation\nmeasurement(x, u, p, t, noise=false) = C*x + noise*rand(rng, dg)\nnothing # hide\n\nWe now create the AdvancedParticleFilter and use it in the same way as the other filters:\n\napf = AdvancedParticleFilter(N, dynamics, measurement, measurement_likelihood, df, d0)\nsol = forward_trajectory(apf, u, y, ny) # Perform batch filtering\n\nplot(sol, xreal=x)\nDisplayAs.PNG(Plots.current()) # hide\n\nWe can even use this type as an AuxiliaryParticleFilter\n\napfa = AuxiliaryParticleFilter(apf)\nsol = forward_trajectory(apfa, u, y, ny)\nplot(sol, dim=1, xreal=x) # Same as above, but only plots a single dimension\nDisplayAs.PNG(Plots.current()) # hide\n\nSee the tutorials section for more advanced examples, including state estimation for DAE (Differential-Algebraic Equation) systems.","category":"section"},{"location":"#Troubleshooting-and-tuning","page":"Home","title":"Troubleshooting and tuning","text":"","category":"section"},{"location":"#Particle-filters","page":"Home","title":"Particle filters","text":"Tuning a particle filter can be quite the challenge. To assist with this, we provide som visualization tools\n\ndebugplot(pf,u[1:20],y[1:20], runall=true, xreal=x[1:20])\n\nThe plot displays all state variables and all measurements. The heatmap in the background represents the weighted particle distributions per time step. For the measurement sequences, the heatmap represent the distributions of predicted measurements. The blue dots corresponds to measured values. In this case, we simulated the data and we had access to the state as well, if we do not have that, just omit xreal. You can also manually step through the time-series using\n\ncommandplot(pf,u,y; kwargs...)\n\nFor options to the debug plots, see ?pplot.","category":"section"},{"location":"#Troubleshooting-Kalman-filters","page":"Home","title":"Troubleshooting Kalman filters","text":"Filter state diverges: This may be due to an unstable system model, forgetting to discretize a continuous-time model, or inadequate integration of a nonlinear model (too large time step etc.).\nCovariance estimate blows up: If the estimated covariance for one or several state variables grows without bound, the system may be unobservable. Observability is a property of the dynamics and the measurement model (i.e., which sensors are available), see Identifiability for more details. If the estimated mean blows up as well, inadequate integration may be at fault.\nA persistent difference between predicted and filtered state estimates: This may have several causes\nThe dynamics noise covariance is tuned too low, or the model is not controllable from the noise inputs (not enough degrees of freedom in the noise / the covariance matrix of the noise is singular).\nModel error that is not accounted for by any disturbance model.\nSensor bias. This can be handled by an integrating disturbance model affecting the output.\nSluggish filter performance (lag): Increase the dynamics noise covariance R_1 or decrease the measurement noise covariance R_2.\nNoisy state estimates: If the filter is affected too much by measurement noise, decrease the dynamics noise covariance R_1 or increase the measurement noise covariance R_2 (the opposite action to when the filter is too sluggish).\nA commonly occurring error is \"Cholesky factorization failed\", which may occur due to several different reasons\nThe dynamics is diverging and the covariance matrices end up with NaNs or Infs. If this is the case, verify that the dynamics is correctly implemented and that the integration is sufficiently accurate, especially if using a fixed-step integrator like any of those from SeeToDee.jl.\nThe covariance matrix is poorly conditioned and numerical issues make causes it to lose positive definiteness. This issue is rare, but can be mitigated by using the SqKalmanFilter, rescaling the dynamics or by using a different cholesky factorization method (available in UKF only).\n\nSee sampleplot for help with sampling-based tuning and validationplot for tuning validation. ","category":"section"},{"location":"#Tuning-noise-parameters-through-optimization","page":"Home","title":"Tuning noise parameters through optimization","text":"See examples in Parameter Estimation. See also autotune_covariances and validationplot for validation of tuning.","category":"section"},{"location":"#Tuning-through-simulation","page":"Home","title":"Tuning through simulation","text":"It is possible to sample from the Bayesian model implied by a filter and its parameters by calling the function simulate. A simple tuning strategy is to adjust the noise parameters such that a simulation looks \"similar\" to the data, i.e., the data must not be too unlikely under the model. See also sampleplot that facilitates this procedure.","category":"section"},{"location":"#Videos","page":"Home","title":"Videos","text":"Several video tutorials using this package are available in the playlists\n\nSystem identification in Julia\nControl systems in Julia\n\nSome examples featuring this package in particular are\n\n\n\nUsing an optimizer to optimize the likelihood of an UnscentedKalmanFilter:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/0RxQwepVsoM\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n\nEstimation of time-varying parameters:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/zJcOPPLqv4A?si=XCvpo3WD-4U3PJ2S\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n\n\nAdaptive control by means of estimation of time-varying parameters:\n\n<iframe style=\"height: 315px; width: 560px\" src=\"https://www.youtube.com/embed/Ip_prmA7QTU?si=Fat_srMTQw5JtW2d\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>","category":"section"}]
}
