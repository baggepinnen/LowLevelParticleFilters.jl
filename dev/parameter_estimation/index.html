<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parameter estimation · LowLevelParticleFilters Documentation</title><meta name="title" content="Parameter estimation · LowLevelParticleFilters Documentation"/><meta property="og:title" content="Parameter estimation · LowLevelParticleFilters Documentation"/><meta property="twitter:title" content="Parameter estimation · LowLevelParticleFilters Documentation"/><meta name="description" content="Documentation for LowLevelParticleFilters Documentation."/><meta property="og:description" content="Documentation for LowLevelParticleFilters Documentation."/><meta property="twitter:description" content="Documentation for LowLevelParticleFilters Documentation."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LowLevelParticleFilters Documentation</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../discretization/">Discretization</a></li><li><a class="tocitem" href="../measurement_models/">Multiple measurement models</a></li><li class="is-active"><a class="tocitem" href>Parameter estimation</a><ul class="internal"><li><a class="tocitem" href="#Maximum-likelihood-estimation"><span>Maximum-likelihood estimation</span></a></li><li><a class="tocitem" href="#MAP-estimation"><span>MAP estimation</span></a></li><li><a class="tocitem" href="#Bayesian-inference-using-PMMH"><span>Bayesian inference using PMMH</span></a></li><li><a class="tocitem" href="#Bayesian-inference-using-DynamicHMC.jl"><span>Bayesian inference using  DynamicHMC.jl</span></a></li><li><a class="tocitem" href="#Joint-state-and-parameter-estimation"><span>Joint state and parameter estimation</span></a></li><li><a class="tocitem" href="#Using-an-optimizer"><span>Using an optimizer</span></a></li><li><a class="tocitem" href="#Which-method-should-I-use?"><span>Which method should I use?</span></a></li><li><a class="tocitem" href="#Identifiability"><span>Identifiability</span></a></li><li><a class="tocitem" href="#Videos"><span>Videos</span></a></li></ul></li><li><a class="tocitem" href="../benchmark/">Benchmark</a></li><li><a class="tocitem" href="../distributions/">Performance tips</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../adaptive_kalmanfilter/">Kalman-filter tutorial with LowLevelParticleFilters</a></li><li><a class="tocitem" href="../noisetuning/">Noise tuning and disturbance modeling for Kalman filtering</a></li><li><a class="tocitem" href="../beetle_example/">Particle-filter tutorial</a></li><li><a class="tocitem" href="../beetle_example_imm/">IMM-filter tutorial</a></li><li><a class="tocitem" href="../rbpf_example/">Rao-Blackwellized filter tutorial</a></li><li><a class="tocitem" href="../dae/">State estimation for DAE systems</a></li><li><a class="tocitem" href="../adaptive_control/">Adaptive estimation and control</a></li><li><a class="tocitem" href="../neural_network/">Adaptive Neural-Network training</a></li><li><a class="tocitem" href="../friction_nn_example/">SciML: Adaptive Universal Differential Equation</a></li><li><a class="tocitem" href="../thermal_nn_example/">SciML: Learning a sunshine disturbance model</a></li><li><a class="tocitem" href="../fault_detection/">Fault detection</a></li><li><a class="tocitem" href="../ut/">Unscented transform</a></li><li><a class="tocitem" href="../disturbance_gallery/">Disturbance gallery</a></li><li><a class="tocitem" href="../sample_rate/">Influence of sample rate on performance</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Parameter estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parameter estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/baggepinnen/LowLevelParticleFilters.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/baggepinnen/LowLevelParticleFilters.jl/blob/master/docs/src/parameter_estimation.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Parameter-Estimation"><a class="docs-heading-anchor" href="#Parameter-Estimation">Parameter Estimation</a><a id="Parameter-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Parameter-Estimation" title="Permalink"></a></h1><p>State estimation is an integral part of many parameter-estimation methods. Below, we will illustrate several different methods of performing parameter estimation. We can roughly divide the methods into two camps</p><ol><li>Methods that optimize prediction error or likelihood by tweaking model parameters.</li><li>Methods that add the parameters to be estimated as state variables in the model and estimate them using standard state estimation. </li></ol><p>From the first camp, we provide som basic functionality for maximum-likelihood estimation and MAP estimation, described below. An example of (2), joint state and parameter estimation, is provided in <a href="#Joint-state-and-parameter-estimation">Joint state and parameter estimation</a>.</p><h2 id="Maximum-likelihood-estimation"><a class="docs-heading-anchor" href="#Maximum-likelihood-estimation">Maximum-likelihood estimation</a><a id="Maximum-likelihood-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Maximum-likelihood-estimation" title="Permalink"></a></h2><p>Filters calculate the likelihood and prediction errors while performing filtering, this can be used to perform maximum likelihood estimation or prediction-error minimization. One can estimate all kinds of parameters using this method, in the example below, we will estimate the noise covariance. We may for example plot likelihood as function of the variance of the dynamics noise like this:</p><h3 id="Generate-data-by-simulation"><a class="docs-heading-anchor" href="#Generate-data-by-simulation">Generate data by simulation</a><a id="Generate-data-by-simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Generate-data-by-simulation" title="Permalink"></a></h3><p>This simulates the same linear system as on the index page of the documentation</p><pre><code class="language-julia hljs">using LowLevelParticleFilters, LinearAlgebra, StaticArrays, Distributions, Plots
nx = 2   # Dimension of state
nu = 2   # Dimension of input
ny = 2   # Dimension of measurements
N = 2000 # Number of particles

const dg = MvNormal(ny,1.0)          # Measurement noise Distribution
const df = MvNormal(nx,1.0)          # Dynamics noise Distribution
const d0 = MvNormal(@SVector(randn(nx)),2.0)   # Initial state Distribution

const A = SA[1 0.1; 0 1]
const B = @SMatrix [0.0 0.1; 1 0.1]
const C = @SMatrix [1.0 0; 0 1]

dynamics(x,u,p,t) = A*x .+ B*u
measurement(x,u,p,t) = C*x
vecvec_to_mat(x) = copy(reduce(hcat, x)&#39;) # Helper function
pf = ParticleFilter(N, dynamics, measurement, df, dg, d0)
xs,u,y = simulate(pf,300,df)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(StaticArraysCore.SVector{2, Float64}[[1.0812304200971112, -0.14562935751734435], [3.3398390369663726, 2.6117255112063114], [4.3007828745518255, 3.6052684450147865], [3.9899081696355654, 3.174109219038346], [4.929088829186488, 4.845899831231918], [4.686233765330584, 2.6220346737880713], [4.930527469212666, 4.605358722866291], [4.288136119466675, 4.690262164765202], [6.3732474147133065, 3.6302084044842786], [7.6683036103940925, 1.9090771633847305]  …  [410.56377819631575, 4.889612120602187], [411.6217078895859, 0.2907133256233947], [411.93866871954907, -0.47816157679828064], [413.38192199998593, -1.5836671071004567], [413.01423291879615, -1.0833177641287557], [412.4377761611456, -2.6893480803383403], [412.48941741117085, -4.768502194755624], [411.16657304638557, -7.392508087629931], [409.49027825382495, -7.221657961509199], [407.4190282657971, -5.170768824332136]], [[0.5839054062927054, -0.27929477378843304], [0.41007457728427377, 0.9184433161348705], [0.11204639752074251, 0.5631568392262732], [1.1255022555445502, -0.432131932236531], [-1.4609285400734122, -1.0047900574943391], [1.658369563599552, 0.41173127501428186], [0.080280121082907, -1.6750679461296805], [0.47545184209756375, 0.9200875097747347], [-0.8745692970385783, -0.6063211557138892], [-0.6371267005592348, 0.3182510062201885]  …  [-1.2489711048850263, 0.5737070285485795], [-0.5339829136703733, 0.2608634380802061], [-0.24862328178704068, 0.9549561375433364], [-0.16281638770760531, 1.0145987581223301], [-1.9226803890658999, 0.8827977883629121], [-0.858732315998032, -0.8824817581291353], [-0.6331406379760188, 0.42937840647202086], [-0.4115253891654016, -0.3459220491586696], [1.0877107905147378, -1.2027615350296437], [0.5789458507677563, 1.2073250722043054]], StaticArraysCore.SizedVector{2, Float64, Vector{Float64}}[[1.6442351456121158, 1.6766668007138197], [0.7426466291786973, 2.4718088682537407], [6.7320342341899995, 3.6665708828368713], [3.4969697583982913, 4.2348066931995625], [4.533049412664905, 4.726692441753012], [3.360060642306, 0.9197022598668725], [6.24340445526615, 1.9861203851110845], [5.600796909640847, 4.51710095901336], [8.46722145479709, 4.438330716619577], [5.208214774904236, 1.6050070144687867]  …  [410.26410942739403, 4.271857916208922], [412.43350778230837, 1.0396608238630654], [413.06690124043416, 0.021868938102517665], [413.1503297102212, -2.992765118116677], [412.0901334545664, -2.1744967485769386], [411.690381874379, -3.616954105982384], [411.84303973823353, -4.127065873392851], [413.4868029474449, -9.042224811642193], [408.5244861062999, -7.170893989181574], [407.9846094950049, -5.70127709693535]])</code></pre><h3 id="Compute-likelihood-for-various-values-of-the-parameters"><a class="docs-heading-anchor" href="#Compute-likelihood-for-various-values-of-the-parameters">Compute likelihood for various values of the parameters</a><a id="Compute-likelihood-for-various-values-of-the-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Compute-likelihood-for-various-values-of-the-parameters" title="Permalink"></a></h3><p>Since this example looks for a single parameter only, we can plot the likelihood as a function of this parameter. If we had been looking for more than 2 parameters, we typically use an optimizer instead (see further below).</p><pre><code class="language-julia hljs">p = nothing
svec = exp10.(LinRange(-0.8, 1.2, 60))
llspf = map(svec) do s
    df = MvNormal(nx,s)
    pfs = ParticleFilter(N, dynamics, measurement, df, dg, d0)
    loglik(pfs, u, y, p)
end
llspfaux = map(svec) do s
    df = MvNormal(nx,s)
    pfs = AuxiliaryParticleFilter(N, dynamics, measurement, df, dg, d0)
    loglik(pfs, u, y, p)
end
plot( svec, llspf,
    xscale = :log10,
    title = &quot;Log-likelihood&quot;,
    xlabel = &quot;Dynamics noise standard deviation&quot;,
    lab = &quot;PF&quot;,
)
plot!(svec, llspfaux, yscale=:identity, xscale=:log10, lab=&quot;AUX PF&quot;, c=:green)
vline!([svec[findmax(llspf)[2]]], l=(:dash,:blue), primary=false)</code></pre><img src="d1927c42.svg" alt="Example block output"/><p>the correct value for the simulated data is 1 (the simulated system is the same as on the front page of the docs).</p><p>We can do the same with a Kalman filter, shown below. When using Kalman-type filters, one may also provide a known state sequence if one is available, such as when the data is obtained from a simulation or in an instrumented lab setting. If the state sequence is provided, state-prediction errors are used for log-likelihood estimation instead of output-prediction errors.</p><pre><code class="language-julia hljs">eye(n) = SMatrix{n,n}(1.0I(n))
llskf = map(svec) do s
    kfs = KalmanFilter(A, B, C, 0, s^2*eye(nx), eye(ny), d0)
    loglik(kfs, u, y, p)
end
llskfx = map(svec) do s # Kalman filter with known state sequence, possible when data is simulated
    kfs = KalmanFilter(A, B, C, 0, s^2*eye(nx), eye(ny), d0)
    loglik_x(kfs, u, y, xs, p)
end
plot!(svec, llskf, yscale=:identity, xscale=:log10, lab=&quot;Kalman&quot;, c=:red)
vline!([svec[findmax(llskf)[2]]], l=(:dash,:red), primary=false)
plot!(svec, llskfx, yscale=:identity, xscale=:log10, lab=&quot;Kalman with known state sequence&quot;, c=:purple)
vline!([svec[findmax(llskfx)[2]]], l=(:dash,:purple), primary=false)</code></pre><img src="35546fc9.svg" alt="Example block output"/><p>the result can be quite noisy due to the stochastic nature of particle filtering. The particle filter likelihood agrees with the Kalman-filter estimate, which is optimal for the linear example system we are simulating here, apart for when the noise variance is small. Due to particle depletion, particle filters often struggle when dynamics-noise is too small. This problem is mitigated by using a greater number of particles, or simply by not using a too small covariance.</p><h2 id="MAP-estimation"><a class="docs-heading-anchor" href="#MAP-estimation">MAP estimation</a><a id="MAP-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#MAP-estimation" title="Permalink"></a></h2><p>Maximum a posteriori estimation (MAP) is similar to maximum likelihood (ML), but includes also prior knowledge of the distribution of the parameters in a way that is similar to parameter regularization. In this example, we will estimate the variance of the noises in the dynamics and the measurement functions.</p><p>To solve a MAP estimation problem, we need to define a function that takes a parameter vector and returns a filter, the parameters are used to construct the covariance matrices:</p><pre><code class="language-julia hljs">filter_from_parameters(θ, pf = nothing) = KalmanFilter(A, B, C, 0, exp(θ[1])^2*eye(nx), exp(θ[2])^2*eye(ny), d0) # Works with particle filters as well</code></pre><p>The call to <code>exp</code> on the parameters is so that we can define log-normal priors</p><pre><code class="language-julia hljs">priors = [Normal(0,2),Normal(0,2)]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Distributions.Normal{Float64}}:
 Distributions.Normal{Float64}(μ=0.0, σ=2.0)
 Distributions.Normal{Float64}(μ=0.0, σ=2.0)</code></pre><p>Now we call the function <code>log_likelihood_fun</code> that returns a function to be minimized</p><pre><code class="language-julia hljs">ll = log_likelihood_fun(filter_from_parameters, priors, u, y, p)</code></pre><p>Since this is once again a low-dimensional problem, we can plot the LL on a 2d-grid</p><pre><code class="language-julia hljs">function meshgrid(a,b)
    grid_a = [i for i in a, j in b]
    grid_b = [j for i in a, j in b]
    grid_a, grid_b
end
Nv       = 20
v        = LinRange(-0.7,1,Nv)
llxy     = (x,y) -&gt; ll([x;y])
VGx, VGy = meshgrid(v,v)
VGz      = llxy.(VGx, VGy)
heatmap(
    VGz,
    xticks = (1:Nv, round.(v, digits = 2)),
    yticks = (1:Nv, round.(v, digits = 2)),
    xlabel = &quot;sigma v&quot;,
    ylabel = &quot;sigma w&quot;,
) # Yes, labels are reversed</code></pre><img src="ca3e8495.svg" alt="Example block output"/><p>For higher-dimensional problems, we may estimate the parameters using an optimizer, e.g., Optim.jl.</p><h2 id="Bayesian-inference-using-PMMH"><a class="docs-heading-anchor" href="#Bayesian-inference-using-PMMH">Bayesian inference using PMMH</a><a id="Bayesian-inference-using-PMMH-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-inference-using-PMMH" title="Permalink"></a></h2><p>We proceed like we did for MAP above, but when calling the function <code>metropolis</code>, we will get the entire posterior distribution of the parameter vector, for the small cost of a massive increase in the amount of computations. <a href="../api/#LowLevelParticleFilters.metropolis"><code>metropolis</code></a> runs the <a href="https://en.wikipedia.org/wiki/Metropolis%E2%80%93Hastings_algorithm">Metropolis Hastings algorithm</a>, or more precisely if a particle filter is used, the &quot;Particle Marginal Metropolis Hastings&quot; (PMMH) algorithm. Here we use the Kalman filter simply to have the documentation build a bit faster, it can be quite heavy to run.</p><pre><code class="language-julia hljs">filter_from_parameters(θ, pf = nothing) = KalmanFilter(A, B, C, 0, exp(θ[1])^2*I(nx), exp(θ[2])^2*I(ny), d0) # Works with particle filters as well</code></pre><p>The call to <code>exp</code> on the parameters is so that we can define log-normal priors</p><pre><code class="language-julia hljs">priors = [Normal(0,2),Normal(0,2)]
ll     = log_likelihood_fun(filter_from_parameters, priors, u, y, p)
θ₀     = log.([1.0, 1.0]) # Starting point</code></pre><p>We also need to define a function that suggests a new point from the &quot;proposal distribution&quot;. This can be pretty much anything, but it has to be symmetric since I was lazy and simplified an equation.</p><pre><code class="language-julia hljs">draw   = θ -&gt; θ .+ 0.05 .* randn.() # This function dictates how new proposal parameters are being generated.
burnin = 200 # remove this many initial samples (&quot;burn-in period&quot;)
@info &quot;Starting Metropolis algorithm&quot;
@time theta, lls = metropolis(ll, 2200, θ₀, draw) # Run PMMH for 2200  iterations
thetam = reduce(hcat, theta)&#39;[burnin+1:end,:] # Build a matrix of the output
histogram(exp.(thetam), layout=(3,1), lab=[&quot;R1&quot; &quot;R2&quot;]); plot!(lls[burnin+1:end], subplot=3, lab=&quot;log likelihood&quot;) # Visualize</code></pre><img src="f2a80b54.svg" alt="Example block output"/><p>In this example, we initialize the MH algorithm on the correct value <code>θ₀</code>, in general, you&#39;d see a period in the beginning where the likelihood (bottom plot) is much lower than during the rest of the sampling, this is the reason we remove a number of samples in the beginning, typically referred to as &quot;burn in&quot;.</p><p>If you are lucky, you can run the above threaded as well. I tried my best to make particle filters thread safe with their own rngs etc., but your milage may vary. For threading to help, the dynamics must be non-allocating, e.g., by using StaticArrays etc.</p><pre><code class="language-julia hljs">@time thetalls = LowLevelParticleFilters.metropolis_threaded(burnin, ll, 2200, θ₀, draw, nthreads=2)
histogram(exp.(thetalls[:,1:2]), layout=3)
plot!(thetalls[:,3], subplot=3)</code></pre><img src="36624fb7.svg" alt="Example block output"/><h2 id="Bayesian-inference-using-DynamicHMC.jl"><a class="docs-heading-anchor" href="#Bayesian-inference-using-DynamicHMC.jl">Bayesian inference using  DynamicHMC.jl</a><a id="Bayesian-inference-using-DynamicHMC.jl-1"></a><a class="docs-heading-anchor-permalink" href="#Bayesian-inference-using-DynamicHMC.jl" title="Permalink"></a></h2><p>The following snippet of code performs the same estimation as above, but uses the much more sophisticated HMC sampler in <a href="https://www.tamaspapp.eu/DynamicHMC.jl/stable/worked_example/">DynamicHMC.jl</a> rather than the PMMH sampler above. This package requires the log-likelihood function to be wrapped in a custom struct that implements the <code>LogDensityProblems</code> interface, which is done below. We also indicate that we want to use ForwardDiff.jl to compute the gradients for fast sampling.</p><pre><code class="language-julia hljs">using DynamicHMC, LogDensityProblemsAD, ForwardDiff, LogDensityProblems, LinearAlgebra, Random

struct LogTargetDensity{F}
    ll::F
    dim::Int
end
LogDensityProblems.logdensity(p::LogTargetDensity, θ) = p.ll(θ)
LogDensityProblems.dimension(p::LogTargetDensity) = p.dim
LogDensityProblems.capabilities(::Type{LogTargetDensity}) = LogDensityProblems.LogDensityOrder{0}()

function filter_from_parameters(θ, pf = nothing)
    # It&#39;s important that the distribution of the initial state has the same
    # element type as the parameters. DynamicHMC will use Dual numbers for differentiation,
    # hence, we make sure that d0 has `eltype(d0) = eltype(θ)`
    T = eltype(θ)
    d0 = MvNormal(T.(d0.μ), T.(d0.Σ))
    KalmanFilter(A, B, C, 0, exp(θ[1])^2*eye(nx), exp(θ[2])^2*eye(ny), d0) 
end
ll = log_likelihood_fun(filter_from_parameters, priors, u, y, p)

D = length(θ₀)
ℓπ = LogTargetDensity(ll, D)
∇P = ADgradient(:ForwardDiff, ℓπ)

results = mcmc_with_warmup(Random.default_rng(), ∇P, 3000)
DynamicHMC.Diagnostics.summarize_tree_statistics(results.tree_statistics)
lls = [ts.π for ts in results.tree_statistics]

histogram(exp.(results.posterior_matrix)&#39;, layout=(3,1), lab=[&quot;R1&quot; &quot;R2&quot;])
plot!(lls, subplot=3, lab=&quot;log likelihood&quot;) # Visualize</code></pre><h2 id="Joint-state-and-parameter-estimation"><a class="docs-heading-anchor" href="#Joint-state-and-parameter-estimation">Joint state and parameter estimation</a><a id="Joint-state-and-parameter-estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Joint-state-and-parameter-estimation" title="Permalink"></a></h2><p>In this example, we&#39;ll show how to perform parameter estimation by treating a parameter as a state variable. This method can not only estimate constant parameters, but also <strong>time-varying parameters</strong>. The system we will consider is a quadruple tank, where two upper tanks feed into two lower tanks. The outlet for tank 1 can vary in size, simulating, e.g., that something partially blocks the outlet. We start by defining the dynamics on a form that changes the outlet area <span>$a_1$</span> at time <span>$t=500$</span>:</p><pre><code class="language-julia hljs">using LowLevelParticleFilters
using SeeToDee
using Distributions
using StaticArrays
using Plots, LinearAlgebra

function quadtank(h,u,p,t)
    k1, k2, g = 1.6, 1.6, 9.81
    A1 = A3 = A2 = A4 = 4.9
    a1, a3, a2, a4 = 0.03, 0.03, 0.03, 0.03
    γ1, γ2 = 0.2, 0.2

    if t &gt; 500
        a1 *= 2 # Change the parameter at t = 500
    end

    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0

    SA[
        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]
        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]
        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]
        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]
    ]
end

nu = 2 # number of control inputs
nx = 4 # number of state variables
ny = 2 # number of measured outputs
Ts = 1 # sample time</code></pre><p>We then define a measurement function, we measure the levels of tanks 1 and 2, and discretize the continuous-time dynamics using a Runge-Kutta 4 integrator <a href="https://baggepinnen.github.io/SeeToDee.jl/dev/api/#SeeToDee.Rk4"><code>SeeToDee.Rk4</code></a>:</p><pre><code class="language-julia hljs">measurement(x,u,p,t) = SA[x[1], x[2]]
discrete_dynamics = SeeToDee.Rk4(quadtank, Ts)</code></pre><p>We simulate the system using the <code>rollout</code> function and add some noise to the measurements. The inputs in this case are just square waves.</p><pre><code class="language-julia hljs">Tperiod = 200
t = 0:Ts:1000
u = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* t)) .+ 0.25)
u = SVector{nu}.(vcat.(u,u))
x0 = Float64[2,2,3,3]
x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u)[1:end-1]
y = measurement.(x, u, 0, 0)
y = [y .+ 0.01.*randn.() for y in y]

plot(
    plot(reduce(hcat, x)&#39;, title=&quot;State&quot;),
    plot(reduce(hcat, u)&#39;, title=&quot;Inputs&quot;)
)</code></pre><img src="9e6fb150.svg" alt="Example block output"/><p>To perform the joint state and parameter estimation, we define a version of the dynamics that contains an extra state, corresponding to the unknown or time varying parameter, in this case <span>$a_1$</span>. We do not have any apriori information about how this parameter changes, so we say that its derivative is 0 and it&#39;s thus only driven by noise:</p><pre><code class="language-julia hljs">function quadtank_paramest(h, u, p, t)
    k1, k2, g = 1.6, 1.6, 9.81
    A1 = A3 = A2 = A4 = 4.9
    a3, a2, a4 = 0.03, 0.03, 0.03
    γ1, γ2 = 0.2, 0.2

    a1 = h[5] # the a1 parameter is a state

    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0

    SA[
        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]
        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]
        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]
        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]
        0 # the state is only driven by noise
    ]
end

discrete_dynamics_params = SeeToDee.Rk4(quadtank_paramest, Ts)</code></pre><p>We then define a nonlinear state estimator, we will use the <a href="../api/#LowLevelParticleFilters.UnscentedKalmanFilter-Union{Tuple{AUGM}, Tuple{AUGD}, Tuple{IPM}, Tuple{IPD}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any, Any}} where {IPD, IPM, AUGD, AUGM}"><code>UnscentedKalmanFilter</code></a>, and solve the filtering problem. We start by an initial state estimate <span>$x_0$</span> that is slightly off for the parameter <span>$a_1$</span></p><pre><code class="language-julia hljs">nx = 5
names = SignalNames(x = [&quot;h1&quot;, &quot;h2&quot;, &quot;h3&quot;, &quot;h4&quot;, &quot;a1&quot;], y = [&quot;h$i&quot; for i in 1:2], u = [&quot;p1&quot;, &quot;p2&quot;], name=&quot;UKF&quot;) # For nicer plot labels

R1 = SMatrix{nx,nx}(Diagonal([0.1, 0.1, 0.1, 0.1, 0.0001])) # Use of StaticArrays is generally good for performance
R2 = SMatrix{ny,ny}(Diagonal((1e-2)^2 * ones(ny)))
x0 = SA[2, 2, 3, 3, 0.02] # The SA prefix makes the array static, which is good for performance

kf = UnscentedKalmanFilter(discrete_dynamics_params, measurement, R1, R2, MvNormal(x0, R1); ny, nu, Ts, names)

sol = forward_trajectory(kf, u, y)
plot(sol, plotx=false, plotxt=true, plotu=false, ploty=true, legend=:bottomright)
plot!([0,500,500,1000], [0.03, 0.03, 0.06, 0.06], l=(:dash, :black), sp=5, lab=&quot;True param&quot;)</code></pre><img src="bc831bb9.svg" alt="Example block output"/><p>as we can see, the correct value of the parameter is quickly found (<span>$a_1$</span>), and it also adapts at <span>$t=500$</span> when the parameter value changes. The speed with which the parameter adapts to changes is determined by the covariance matrix <span>$R_1$</span>, a higher value results in faster adaptation, but also higher sensitivity to noise. </p><p>If adaptive parameter estimation is coupled with a model-based controller, we get an adaptive controller! Note: the state that corresponds to the estimated parameter is typically not controllable, a fact that may require some special care for some control methods.</p><p>We may ask ourselves, what&#39;s the difference between a parameter and a state variable if we can add parameters as state variables? Typically, parameters do not vary with time, and if they do, they vary significantly slower than the state variables. State variables also have dynamics associate with them, whereas we often have no idea about how the parameters vary other than that they vary slowly.</p><p>Abrupt changes to the dynamics like in the example above can happen in practice, for instance, due to equipment failure or change of operating mode. This can be treated as a scenario with time-varying parameters that are continuously estimated.</p><h3 id="Joint-state-and-parameter-estimation-using-MUKF"><a class="docs-heading-anchor" href="#Joint-state-and-parameter-estimation-using-MUKF">Joint state and parameter estimation using MUKF</a><a id="Joint-state-and-parameter-estimation-using-MUKF-1"></a><a class="docs-heading-anchor-permalink" href="#Joint-state-and-parameter-estimation-using-MUKF" title="Permalink"></a></h3><p>The <a href="../api/#LowLevelParticleFilters.MUKF"><code>MUKF</code></a> (Marginalized Unscented Kalman Filter) is an estimator particularily well suited to joint state and parameter estimation.  When parameters have <strong>linear time evolution</strong> and enter <strong>multiplicatively</strong> into the system dynamics, MUKF explicitly separates the nonlinear state variables from linearly-evolving variables, leading to:</p><ul><li><em>Deterministic estimation</em>: No particle randomness like for particle filters, making it suitable for gradient-based optimization of hyperparameters</li><li><em>Computational efficiency</em>: Uses fewer sigma points than UKF for the same state dimension</li></ul><h4 id="Problem:-Quadrotor-with-Unknown-Mass-and-Drag"><a class="docs-heading-anchor" href="#Problem:-Quadrotor-with-Unknown-Mass-and-Drag">Problem: Quadrotor with Unknown Mass and Drag</a><a id="Problem:-Quadrotor-with-Unknown-Mass-and-Drag-1"></a><a class="docs-heading-anchor-permalink" href="#Problem:-Quadrotor-with-Unknown-Mass-and-Drag" title="Permalink"></a></h4><p>We consider a simplified quadrotor model where the mass and drag coefficient are unknown and time-varying. By cleverly partitioning the state using reparameterizations <span>$\theta = 1/m$</span> and <span>$\varphi = \theta C_d$</span>, we exploit the conditionally linear structure to achieve significant computational savings.</p><p>The system has 8 state dimensions total with the following partitioning:</p><ul><li><strong>Nonlinear substate</strong> (3D): velocities <span>$[v_x, v_y, v_z]$</span></li><li><strong>Linear substate</strong> (5D): positions <span>$[x, y, z]$</span>, inverse mass <span>$\theta = 1/m$</span>, and mass-scaled drag <span>$\varphi = \theta C_d$</span></li></ul><p>The key insight is that positions evolve linearly given the velocities (<span>$\dot{x} = v_x$</span>), and velocity dynamics depend linearly on both <span>$\theta$</span> and <span>$\varphi$</span>. This clever parameterization reduces sigma points from 17 (for full 8D UKF) to only 7 (for 3D nonlinear MUKF).</p><p>The physical dynamics are:</p><p class="math-container">\[\begin{aligned}
\dot{x} &amp;= v_x, \quad \dot{y} = v_y, \quad \dot{z} = v_z \\
\dot{v}_x &amp;= \frac{F_x - C_d \cdot v_x |v_x|}{m}, \quad
\dot{v}_y = \frac{F_y - C_d \cdot v_y |v_y|}{m}, \quad
\dot{v}_z = \frac{F_z - C_d \cdot v_z |v_z|}{m} - g
\end{aligned}\]</p><p>Using the inverse mass parameterization <span>$\theta = 1/m$</span> and defining <span>$\varphi = \theta C_d$</span>, we can rewrite the velocity dynamics as:</p><p class="math-container">\[\begin{aligned}
\dot{v}_x &amp;= \theta F_x - \varphi v_x |v_x|, \quad
\dot{v}_y = \theta F_y - \varphi v_y |v_y|, \quad
\dot{v}_z = \theta F_z - \varphi v_z |v_z| - g
\end{aligned}\]</p><p>This reveals the conditionally linear structure: the velocity derivatives depend linearly on both <span>$\theta$</span> and <span>$\varphi$</span>, while positions evolve as <span>$\dot{x} = v_x$</span> (linear dependence on velocities). The drag coefficient can be recovered as <span>$C_d = \varphi / \theta$</span> when needed. Since <span>$\theta = 1/m &gt; 0$</span>, this division is well defined as long as the estimate of <span>$\theta$</span> is reasonable.</p><pre><code class="language-julia hljs">using LowLevelParticleFilters
using SeeToDee
using Distributions
using StaticArrays
using Plots, LinearAlgebra, Random
Random.seed!(0) # For reproducibility

# System dimensions
nxn = 3  # Nonlinear state: [vx, vy, vz] (velocities only)
nxl = 5  # Linear state: [x, y, z, θ, φ] where θ = 1/m, φ = θ*Cd
nx = nxn + nxl
nu = 3   # Control inputs: [Fx, Fy, Fz] (thrust forces)
ny = 6   # Measurements: [x, y, z, vx, vy, vz] (GPS + velocity)

# Physical constants
g = 9.81    # Gravity (m/s²)
Ts = 0.02   # Sample time</code></pre><p>We&#39;ll simulate a scenario where:</p><ul><li>Mass decreases linearly from 1.0 to 0.85 kg (battery drain)</li><li>Drag increases abruptly at t=50s from 0.01 to 0.015 (damage/configuration change)</li></ul><h4 id="MUKF-Formulation-with-Conditionally-Linear-Structure"><a class="docs-heading-anchor" href="#MUKF-Formulation-with-Conditionally-Linear-Structure">MUKF Formulation with Conditionally Linear Structure</a><a id="MUKF-Formulation-with-Conditionally-Linear-Structure-1"></a><a class="docs-heading-anchor-permalink" href="#MUKF-Formulation-with-Conditionally-Linear-Structure" title="Permalink"></a></h4><p>By using the parameterization <span>$\theta = 1/m$</span> and <span>$\varphi = \theta C_d$</span>, we exploit the conditionally linear structure from Morelande &amp; Moran (2007), which has the form:</p><p class="math-container">\[\begin{aligned}
\dot{x}^n &amp;= d_n(x^n) + A_n(x^n) x^l \\
\dot{x}^l &amp;= d_l(x^n) + A_l x^l
\end{aligned}\]</p><p>where <span>$x^n = [v_x, v_y, v_z]$</span> and <span>$x^l = [x, y, z, \theta, \varphi]$</span>. The coupling matrix <span>$A_n(x^n)$</span> is <span>$3 \times 5$</span> and captures how <span>$\theta$</span> scales the thrust forces and <span>$\varphi$</span> scales the drag forces. The term <span>$d_l(x^n) = [v_x, v_y, v_z, 0, 0]$</span> captures how positions depend on velocities.</p><p>This clever parameterization reduces the number of sigma points from 17 (for a full 8D UKF with 2nx+1 = 2×8+1) to only 7 (for a 3D nonlinear MUKF with 2×3+1), a 59% reduction.</p><pre><code class="language-julia hljs"># Nonlinear dynamics function returns [dn; dl] where:
# - dn: uncoupled part of nonlinear state dynamics
# - dl: part of linear state dynamics that depends on nonlinear state
function quadrotor_nonlinear_dynamics(xn, u, p, t)
    vx, vy, vz = xn
    Fx, Fy, Fz = u

    # Nonlinear state dynamics (uncoupled part)
    # v̇ = dn + An*xl where xl = [x,y,z,θ,φ]
    dn = SA[
        0.0,     # v̇x base (thrust/drag coupling through An)
        0.0,     # v̇y base
        -g       # v̇z base (gravity is independent of θ and φ)
    ]

    # Linear state dynamics (part depending on xn)
    # ẋ, ẏ, ż = velocities, θ̇ = 0, φ̇ = 0
    dl = SA[vx, vy, vz, 0.0, 0.0]

    return [dn; dl]  # Return 8D vector
end

# Coupling matrix An: how linear state [x,y,z,θ,φ] affects nonlinear state [vx,vy,vz]
# θ scales thrust forces, φ scales drag forces: v̇ = θ*F - φ*v|v|
function An_matrix(xn, u, p, t)
    vx, vy, vz = xn
    Fx, Fy, Fz = u

    # 3×5 matrix: positions don&#39;t couple, θ and φ do
    SA[
        0.0  0.0  0.0  Fx        -vx*abs(vx)    # v̇x = θ*Fx - φ*vx|vx|
        0.0  0.0  0.0  Fy        -vy*abs(vy)    # v̇y = θ*Fy - φ*vy|vy|
        0.0  0.0  0.0  Fz        -vz*abs(vz)    # v̇z = θ*Fz - φ*vz|vz| - g
    ]
end

# Discrete coupling matrix (scaled by sampling time)
An_matrix_discrete(xn, u, p, t) = An_matrix(xn, u, p, t) * Ts

# Linear state evolution for discrete-time filter
# Al = I to carry over state from previous time step: xl[k+1] = xl[k] + Ts*dl(xn[k])
Al_discrete = SMatrix{nxl, nxl}(I(nxl))
Bl = zero(SMatrix{nxl, nu})    # No control input to linear substate

# Measurement: we measure [x,y,z,vx,vy,vz]
# This comes from d(xn) + Cl*xl where xl = [x,y,z,θ,φ]
measurement(xn, u, p, t) = SA[0.0, 0.0, 0.0, xn[1], xn[2], xn[3]]  # [0,0,0,vx,vy,vz]
Cl = SA[
    1.0  0.0  0.0  0.0  0.0    # x measurement
    0.0  1.0  0.0  0.0  0.0    # y measurement
    0.0  0.0  1.0  0.0  0.0    # z measurement
    0.0  0.0  0.0  0.0  0.0    # vx measurement (from xn)
    0.0  0.0  0.0  0.0  0.0    # vy measurement (from xn)
    0.0  0.0  0.0  0.0  0.0    # vz measurement (from xn)
]

# Discretize the nonlinear dynamics for the MUKF
discrete_nonlinear_dynamics(x,u,p,t) = [x; @SVector(zeros(5))] + Ts .* quadrotor_nonlinear_dynamics(x,u,p,t)</code></pre><h4 id="Simulation"><a class="docs-heading-anchor" href="#Simulation">Simulation</a><a id="Simulation-1"></a><a class="docs-heading-anchor-permalink" href="#Simulation" title="Permalink"></a></h4><p>We&#39;ll simulate a hovering scenario with small perturbations, where the mass decreases (fuel drain) and drag increases abruptly (damage).</p><pre><code class="language-julia hljs">Tf = 50  # 50 seconds at 0.01s sampling
t_vec = range(0, stop=Tf, step=Ts)
T = length(t_vec)

# Control: hovering thrust with small variations
m_nominal = 1.0
F_hover = m_nominal * g
u = [SA[F_hover + 0.1*randn(), F_hover + 0.1*randn(), F_hover + 0.1*randn()] for _ in eachindex(t_vec)]

# True parameters (time-varying)
m_true = [t &lt; 25 ? 1.0 - 0.006*t : 0.85 for t in t_vec]  # Linear decrease
θ_true = 1.0 ./ m_true                                    # Inverse mass
Cd_true = [t &lt; 25 ? 0.01 : 0.015 for t in t_vec]         # Abrupt increase
φ_true = θ_true .* Cd_true                                 # Scaled drag φ = θ*Cd

# Simulate true trajectory using known true parameters
function simulate_quadrotor(u, θ_true, Cd_true)
    # Define continuous dynamics with true parameters
    function dynamics_true(x_state, u_inner, p_inner, t_inner)
        θ_i, Cd_i = p_inner
        vx_s, vy_s, vz_s, px_s, py_s, pz_s = x_state
        Fx, Fy, Fz = u_inner
        SA[
            # Velocity derivatives: v̇ = θ*(F - Cd*v|v|) - g_z
            θ_i * (Fx - Cd_i * vx_s * abs(vx_s)),
            θ_i * (Fy - Cd_i * vy_s * abs(vy_s)),
            θ_i * (Fz - Cd_i * vz_s * abs(vz_s)) - g,
            # Position derivatives: ẋ = v
            vx_s,
            vy_s,
            vz_s
        ]
    end
    discrete_step = SeeToDee.Rk4(dynamics_true, Ts)

    x = zeros(T, nx)  # Full state: [vx,vy,vz,x,y,z,θ,φ]
    φ_0 = θ_true[1] * Cd_true[1]
    x[1, :] = [0, 0, 0, 0, 0, 10, θ_true[1], φ_0]  # Start at 10m altitude, zero velocity

    for i in 1:T-1
        vx, vy, vz = x[i, 1], x[i, 2], x[i, 3]
        pos_x, pos_y, pos_z = x[i, 4], x[i, 5], x[i, 6]

        # Use true parameter values at this time step
        θ_i = θ_true[i]
        Cd_i = Cd_true[i]

        p = [θ_i, Cd_i]
        # Integrate 6D state [vx,vy,vz,x,y,z] with true parameters
        state_6d = SA[vx, vy, vz, pos_x, pos_y, pos_z]
        state_next = discrete_step(state_6d, u[i], p, 0)

        # Store next state including parameters
        φ_next = θ_true[i+1] * Cd_true[i+1]
        x[i+1, :] = [state_next[1], state_next[2], state_next[3],  # vx,vy,vz
                     state_next[4], state_next[5], state_next[6],  # x,y,z
                     θ_true[i+1], φ_next]                           # θ,φ
    end
    return x
end

x_true = simulate_quadrotor(u, θ_true, Cd_true)

# Extract measurement components: [x,y,z,vx,vy,vz] from state [vx,vy,vz,x,y,z,θ,φ]
y_true = [SA[x_true[i, 4], x_true[i, 5], x_true[i, 6],  # x,y,z
              x_true[i, 1], x_true[i, 2], x_true[i, 3]]  # vx,vy,vz
          for i in eachindex(t_vec)]

# Add measurement noise
y = [y_true[i] .+ 0.01 .* @SVector(randn(ny)) for i in eachindex(t_vec)]

# Plot true trajectory and parameters
p1 = plot(t_vec, x_true[:, 6], label=&quot;Altitude (z)&quot;, xlabel=&quot;Time (s)&quot;, ylabel=&quot;m&quot;, legend=:topright)
p2 = plot(t_vec, m_true, label=&quot;Mass&quot;, xlabel=&quot;Time (s)&quot;, ylabel=&quot;kg&quot;, legend=:topright, c=:blue)
p3 = plot(t_vec, Cd_true, label=&quot;Drag&quot;, ylabel=&quot;kg·s/m&quot;, c=:red)
plot(p1, p2, p3)</code></pre><img src="c9407b21.svg" alt="Example block output"/><h4 id="MUKF-Setup-and-Estimation"><a class="docs-heading-anchor" href="#MUKF-Setup-and-Estimation">MUKF Setup and Estimation</a><a id="MUKF-Setup-and-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#MUKF-Setup-and-Estimation" title="Permalink"></a></h4><p>Now we set up the MUKF, which takes mostly the same configutation options as an <a href="../api/#LowLevelParticleFilters.UnscentedKalmanFilter-Union{Tuple{AUGM}, Tuple{AUGD}, Tuple{IPM}, Tuple{IPD}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any, Any}} where {IPD, IPM, AUGD, AUGM}"><code>UnscentedKalmanFilter</code></a></p><pre><code class="language-julia hljs"># Noise covariances
R1n = SMatrix{nxn,nxn}(Diagonal([0.01, 0.01, 0.01]))  # Process noise for [vx,vy,vz]
R1l = SMatrix{nxl,nxl}(Diagonal([0.01, 0.01, 0.01, 0.0001, 0.000001]))   # Process noise for [x,y,z,θ,φ]
R1 = [[R1n zeros(SMatrix{nxn,nxl})]; [zeros(SMatrix{nxl,nxn}) R1l]]

R2 = SMatrix{ny,ny}(Diagonal([0.1, 0.1, 0.1, 0.05, 0.05, 0.05]))  # Measurement noise

# Initial state estimate (slightly wrong)
m_guess = 0.9  # Wrong mass guess
θ_guess = 1.0 / m_guess
Cd_guess = 0.008  # Wrong Cd guess
φ_guess = θ_guess * Cd_guess  # φ = θ*Cd
x0n = SA[0.0, 0.0, 0.0]  # [vx,vy,vz]
x0l = SA[0.0, 0.0, 10.0, θ_guess, φ_guess]  # [x,y,z,θ,φ]
x0_full = [x0n; x0l]

R0n = SMatrix{nxn,nxn}(Diagonal([0.5, 0.5, 0.5]))  # Uncertainty in velocities
R0l = SMatrix{nxl,nxl}(Diagonal([1.0, 1.0, 1.0, 0.01, 0.0001]))    # Uncertainty in positions, θ, and φ
R0_full = [[R0n zeros(SMatrix{nxn,nxl})]; [zeros(SMatrix{nxl,nxn}) R0l]]

d0 = LowLevelParticleFilters.SimpleMvNormal(x0_full, R0_full)

# Create measurement model
mm = RBMeasurementModel(measurement, R2, ny)

# Create MUKF
mukf = MUKF(;
    dynamics = discrete_nonlinear_dynamics,  # Returns [dn; dl]
    nl_measurement_model = mm,
    An = An_matrix_discrete,  # Use discrete coupling matrix
    Al = Al_discrete,         # Use discrete Al = I for state carry-over
    Bl,
    Cl,
    R1,
    d0,
    nxn,
    nu,
    ny,
    Ts,
)

# Run estimation
sol_mukf = forward_trajectory(mukf, u, y)

# Extract estimates
x_est_mukf = reduce(hcat, sol_mukf.xt)&#39;
θ_est_mukf = x_est_mukf[:, 7]  # θ is the 7th state
φ_est_mukf = x_est_mukf[:, 8]  # φ is the 8th state
m_est_mukf = 1.0 ./ θ_est_mukf  # Convert back to mass
Cd_est_mukf = φ_est_mukf ./ θ_est_mukf  # Recover Cd = φ/θ</code></pre><h4 id="Results-and-Comparison"><a class="docs-heading-anchor" href="#Results-and-Comparison">Results and Comparison</a><a id="Results-and-Comparison-1"></a><a class="docs-heading-anchor-permalink" href="#Results-and-Comparison" title="Permalink"></a></h4><p>Let&#39;s visualize the parameter estimation performance:</p><pre><code class="language-julia hljs"># Plot parameter estimates
p1 = plot(t_vec, m_true, label=&quot;True mass&quot;, lw=2, xlabel=&quot;Time (s)&quot;, ylabel=&quot;Mass (kg)&quot;,
          legend=:topright, c=:black, ls=:dash)
plot!(p1, t_vec, m_est_mukf, label=&quot;MUKF estimate&quot;, lw=2, c=:blue)

p2 = plot(t_vec, Cd_true, label=&quot;True drag&quot;, lw=2, xlabel=&quot;Time (s)&quot;, ylabel=&quot;Drag coeff (kg·s/m)&quot;,
          legend=:topleft, c=:black, ls=:dash)
plot!(p2, t_vec, Cd_est_mukf, label=&quot;MUKF estimate&quot;, lw=2, c=:blue)

plot(p1, p2, layout=(2,1), size=(800,500))</code></pre><img src="0b982643.svg" alt="Example block output"/><p>The MUKF successfully tracks both parameters through the gradual mass decrease and the abrupt drag increase at t=50s. The estimation converges quickly from the initial guess.</p><h4 id="Comparison-with-UKF-Approach"><a class="docs-heading-anchor" href="#Comparison-with-UKF-Approach">Comparison with UKF Approach</a><a id="Comparison-with-UKF-Approach-1"></a><a class="docs-heading-anchor-permalink" href="#Comparison-with-UKF-Approach" title="Permalink"></a></h4><p>For comparison, let&#39;s solve the same problem using a standard UKF with the full 8D state (no exploitation of conditionally linear structure):</p><pre><code class="language-julia hljs"># For UKF, treat the entire 8D state uniformly (no structure exploitation)
function quadrotor_dynamics_ukf(x_full, u, p, t)
    xn = x_full[1:nxn]  # [vx,vy,vz]
    xl = x_full[nxn+1:end]  # [x,y,z,θ,φ]

    # Get dynamics and coupling
    dyn = quadrotor_nonlinear_dynamics(xn, u, nothing, 0)
    An = An_matrix(xn, u, nothing, 0)

    # Full derivative
    [dyn[1:nxn] + An * xl; dyn[nxn+1:end]]
end

discrete_dynamics_ukf = SeeToDee.Rk4(quadrotor_dynamics_ukf, Ts)
measurement_ukf(x, u, p, t) = SA[x[4], x[5], x[6], x[1], x[2], x[3]]  # [x,y,z,vx,vy,vz]

R1_ukf = Diagonal([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.0001, 0.000001])
R2_ukf = R2

ukf = UnscentedKalmanFilter(
    discrete_dynamics_ukf,
    measurement_ukf,
    R1_ukf,
    R2_ukf,
    MvNormal(x0_full, R0_full);
    ny = ny,
    nu = nu,
    Ts = Ts
)

sol_ukf = forward_trajectory(ukf, u, y)

# Extract UKF estimates
x_est_ukf = reduce(hcat, sol_ukf.xt)&#39;
θ_est_ukf = x_est_ukf[:, 7]  # θ is the 7th state
φ_est_ukf = x_est_ukf[:, 8]  # φ is the 8th state
m_est_ukf = 1.0 ./ θ_est_ukf  # Convert back to mass
Cd_est_ukf = φ_est_ukf ./ θ_est_ukf  # Recover Cd = φ/θ

# Compare the two approaches
p1 = plot(t_vec, m_true, label=&quot;True&quot;, lw=2, xlabel=&quot;Time (s)&quot;, ylabel=&quot;Mass (kg)&quot;,
          legend=:topright, c=:black, ls=:dash, title=&quot;Mass Estimation&quot;)
plot!(p1, t_vec, m_est_mukf, label=&quot;MUKF&quot;, lw=2, c=:blue, alpha=0.7)
plot!(p1, t_vec, m_est_ukf, label=&quot;UKF&quot;, lw=2, c=:green, alpha=0.7, ls=:dot)

p2 = plot(t_vec, Cd_true, label=&quot;True&quot;, lw=2, xlabel=&quot;Time (s)&quot;, ylabel=&quot;Drag coeff&quot;,
          legend=:topleft, c=:black, ls=:dash, title=&quot;Drag Estimation&quot;)
plot!(p2, t_vec, Cd_est_mukf, label=&quot;MUKF&quot;, lw=2, c=:blue, alpha=0.7)
plot!(p2, t_vec, Cd_est_ukf, label=&quot;UKF&quot;, lw=2, c=:green, alpha=0.7, ls=:dot)

plot(p1, p2, layout=(2,1), size=(800,500))</code></pre><img src="0319fc89.svg" alt="Example block output"/><h4 id="Performance-Analysis"><a class="docs-heading-anchor" href="#Performance-Analysis">Performance Analysis</a><a id="Performance-Analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Performance-Analysis" title="Permalink"></a></h4><p>Let&#39;s quantify the estimation accuracy:</p><pre><code class="language-julia hljs">using Statistics

# Compute RMSE for parameters (excluding initial transient)
transient = 500  # Exclude first 5 seconds
rmse_m_mukf = sqrt(mean((m_true[transient:end] - m_est_mukf[transient:end]).^2))
rmse_Cd_mukf = sqrt(mean((Cd_true[transient:end] - Cd_est_mukf[transient:end]).^2))

rmse_m_ukf = sqrt(mean((m_true[transient:end] - m_est_ukf[transient:end]).^2))
rmse_Cd_ukf = sqrt(mean((Cd_true[transient:end] - Cd_est_ukf[transient:end]).^2))

println(&quot;MUKF - Mass RMSE: $(round(rmse_m_mukf, digits=4)) kg&quot;)
println(&quot;MUKF - Drag RMSE: $(round(rmse_Cd_mukf, digits=6)) kg·s/m&quot;)
println()
println(&quot;UKF  - Mass RMSE: $(round(rmse_m_ukf, digits=4)) kg&quot;)
println(&quot;UKF  - Drag RMSE: $(round(rmse_Cd_ukf, digits=6)) kg·s/m&quot;)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">MUKF - Mass RMSE: 0.0044 kg
MUKF - Drag RMSE: 0.000214 kg·s/m

UKF  - Mass RMSE: 0.0043 kg
UKF  - Drag RMSE: 0.000214 kg·s/m</code></pre><p>Both filters perform comparably in terms of accuracy. However, MUKF uses only 7 sigma points (2×3+1 for 3D nonlinear state) compared to UKF&#39;s 17 sigma points (2×8+1 for 8D full state), a 59% reduction illustrating the computational benefit of exploiting the conditionally linear structure with the φ = θ·Cd parameterization.</p><p>We should note here that we have performed slightly different discretizations of the dynamics for the UKF and the MUKF. With the standard UKF, we discretized the entire dynamics using an RK4 method, a very accurate integrator in this context. For the MUKF, we instead discretized the dynamics using a simple forward Euler discretization (by multiplying <span>$A_n$</span> and the output of <code>quadrotor_nonlinear_dynamics</code> by <span>$T_s$</span>). The reason for this discrepancy is that the conditionally linearity that holds for this system in continuous time no longer holds after discretization, <em>unless</em> we use forward Euler discretization, which is the only scheme simple enough to not mess with the linearity. This primitive discretization is often sufficient for state estimation when sample intervals are short, which they tend to be when controlling quadrotors. See the note under <a href="../discretization/#Discretization">Discretization</a> for more comments regarding accuracy of integration for state estimation.</p><h2 id="Using-an-optimizer"><a class="docs-heading-anchor" href="#Using-an-optimizer">Using an optimizer</a><a id="Using-an-optimizer-1"></a><a class="docs-heading-anchor-permalink" href="#Using-an-optimizer" title="Permalink"></a></h2><p>The state estimators in this package are all statistically motivated and thus compute things like the likelihood of the data as a by-product of the estimation. Maximum-likelihood or prediction-error estimation is thus very straight-forward by simply calling a gradient-based optimizer with gradients provided by differentiating through the state estimator using automatic differentiation. In this example, we will continue the example from above, but now estimate all the parameters of the quad-tank process. This time, they will not vary with time. We will first use a standard optimization algorithm from <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> to minimize the cost function based on the prediction error, and then use a Gauss-Newton optimizer.</p><p>We now define the dynamics function such that it takes its parameters from the <code>p</code> input argument. We also define a variable <code>p_true</code> that contains the true values that we will use to simulate some estimation data</p><pre><code class="language-julia hljs">function quadtank(h, u, p, t)
    k1, k2, g = p[1], p[2], 9.81
    A1 = A3 = A2 = A4 = p[3]
    a1 = a3 = a2 = a4 = p[4]
    γ1 = γ2 = p[5]

    ssqrt(x) = √(max(x, zero(x)) + 1e-3) # For numerical robustness at x = 0

    SA[
        -a1/A1 * ssqrt(2g*h[1]) + a3/A1*ssqrt(2g*h[3]) +     γ1*k1/A1 * u[1]
        -a2/A2 * ssqrt(2g*h[2]) + a4/A2*ssqrt(2g*h[4]) +     γ2*k2/A2 * u[2]
        -a3/A3*ssqrt(2g*h[3])                          + (1-γ2)*k2/A3 * u[2]
        -a4/A4*ssqrt(2g*h[4])                          + (1-γ1)*k1/A4 * u[1]
    ]
end

discrete_dynamics = SeeToDee.Rk4(quadtank, Ts) # Discretize the dynamics using a 4:th order Runge-Kutta integrator
p_true = [1.6, 1.6, 4.9, 0.03, 0.2]</code></pre><p>Similar to previous example, we simulate the system, this time using a more exciting input in order to be able to identify several parameters</p><pre><code class="language-julia hljs">Tperiod = 200
t = 0:Ts:1000
u1 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2)) .+ 0.25)
u2 = vcat.(0.25 .* sign.(sin.(2pi/Tperiod .* (t ./ 40).^2 .+ pi/2)) .+ 0.25)
u  = SVector{nu}.(vcat.(u1,u2))
x0 = SA[2.0,2,3,3] # Initial condition, static array for performance
x = LowLevelParticleFilters.rollout(discrete_dynamics, x0, u, p_true)[1:end-1]
y = measurement.(x, u, 0, 0)
y = [y .+ 0.01 .* randn.() for y in y]

plot(
    plot(reduce(hcat, x)&#39;, title=&quot;State&quot;),
    plot(reduce(hcat, u)&#39;, title=&quot;Inputs&quot;)
)</code></pre><img src="f8f0c6ac.svg" alt="Example block output"/><p>This time, we define a cost function for the optimizer to optimize, we&#39;ll use the sum of squared errors (<code>sse</code>). It&#39;s important to define the UKF with an initial state distribution with the same element type as the parameter vector so that automatic differentiation through the state estimator works, hence the explicit casting <code>T.(x0)</code> and <code>T.(R1)</code>. We also make sure to use StaticArrays for the covariance matrices and the initial condition for performance reasons (optional).</p><pre><code class="language-julia hljs">nx = 4
R1 = SMatrix{nx,nx}(Diagonal([0.1, 0.1, 0.1, 0.1])) # Use of StaticArrays is generally good for performance
R2 = SMatrix{ny,ny}(Diagonal((1e-2)^2 * ones(ny)))
x0 = SA[2.0, 2, 3, 3]

function cost(p::Vector{T}) where T
    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), T.(R1)); ny, nu, Ts)
    LowLevelParticleFilters.sse(kf, u, y, p) # Sum of squared prediction errors
end</code></pre><p>We generate a random initial guess for the estimation problem</p><pre><code class="language-julia hljs">p_guess = p_true .+  0.1*p_true .* randn(length(p_true))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5-element Vector{Float64}:
 1.5524906519904813
 1.8775750226115546
 4.428448666554554
 0.02590304999150804
 0.1887687563066955</code></pre><h3 id="Solving-using-Optim"><a class="docs-heading-anchor" href="#Solving-using-Optim">Solving using Optim</a><a id="Solving-using-Optim-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-using-Optim" title="Permalink"></a></h3><p>We first minimize the cost using the BFGS optimization algorithm from <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a></p><pre><code class="language-julia hljs">using Optim
res = Optim.optimize(
    cost,
    p_guess,
    BFGS(),
    Optim.Options(
        show_trace = true,
        show_every = 5,
        iterations = 100,
        time_limit = 30,
    ),
    autodiff = :forward, # Indicate that we want to use forward-mode AD to derive gradients
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"> * Status: success

 * Candidate solution
    Final objective value:     4.112172e-01

 * Found with
    Algorithm:     BFGS

 * Convergence measures
    |x - x&#39;|               = 3.19e-09 ≰ 0.0e+00
    |x - x&#39;|/|x&#39;|          = 6.93e-10 ≰ 0.0e+00
    |f(x) - f(x&#39;)|         = 7.44e-15 ≰ 0.0e+00
    |f(x) - f(x&#39;)|/|f(x&#39;)| = 1.81e-14 ≰ 0.0e+00
    |g(x)|                 = 1.31e-10 ≤ 1.0e-08

 * Work counters
    Seconds run:   0  (vs limit 30)
    Iterations:    14
    f(x) calls:    37
    ∇f(x) calls:   37
</code></pre><p>We started out with a normalized parameter error of</p><pre><code class="language-julia hljs">using LinearAlgebra
norm(p_true - p_guess) / norm(p_true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.10171638186250584</code></pre><p>and ended with</p><pre><code class="language-julia hljs">p_opt = res.minimizer
norm(p_true - p_opt) / norm(p_true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.06043388874189955</code></pre><h3 id="Solving-using-Gauss-Newton-optimization"><a class="docs-heading-anchor" href="#Solving-using-Gauss-Newton-optimization">Solving using Gauss-Newton optimization</a><a id="Solving-using-Gauss-Newton-optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Solving-using-Gauss-Newton-optimization" title="Permalink"></a></h3><p>Below, we optimize the sum of squared residuals again, but this time we do it using a Gauss-Newton style algorithm (Levenberg Marquardt). These algorithms want the entire residual vector rather than the sum of squares of the residuals, so we define an alternative &quot;cost function&quot; called <code>residuals</code> that calls the lower-level function <a href="../api/#LowLevelParticleFilters.prediction_errors!"><code>LowLevelParticleFilters.prediction_errors!</code></a></p><pre><code class="language-julia hljs">using LeastSquaresOptim

function residuals!(res, p::Vector{T}) where T
    kf = UnscentedKalmanFilter(discrete_dynamics, measurement, R1, R2, MvNormal(T.(x0), T.(R1)); ny, nu, Ts)
    LowLevelParticleFilters.prediction_errors!(res, kf, u, y, p)
end

res_gn = optimize!(LeastSquaresProblem(x = copy(p_guess), f! = residuals!, output_length = length(y)*ny, autodiff = :forward), LevenbergMarquardt())

p_opt_gn = res_gn.minimizer
norm(p_true - p_opt_gn) / norm(p_true)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.05181296446739656</code></pre><p>When performing sum-of-squares minimization like here, we can, assuming that we converge to the global optimum, estimate the covariance of the estimated parameters. The <em>precision matrix</em> <span>$Λ$</span>, which is the inverse of the covariance matrix of the parameters, is given by a scaled Hessian of the cost function. The Gauss-Newton appoximation of the Hessian is given by <span>$J&#39;J$</span>, where <span>$J$</span> is the Jacobian of the residuals. </p><pre><code class="language-julia hljs">using ForwardDiff
T = length(y)
J = ForwardDiff.jacobian(residuals!, zeros(T * ny), res_gn.minimizer)
Λ = (T - length(p_guess)) * Symmetric(J&#39; * J) # Precision matrix of the estimated parameters
# Σ = inv(Λ) # Covariance matrix of the estimated parameters (only compute this if precision matrix is well conditioned)
svdvals(Λ)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">5-element Vector{Float64}:
     1.0581525693369225e7
 14925.359179054769
   862.8219878962076
   386.58162555667235
     3.4106051316475588e-12</code></pre><p>In this case, the precision matrix is singular, indicating that there is at least one diretion in parameter space that yields no increase in cost, and we can thus not determine where along a line in this direction the true parameter lies.</p><p>Gauss-Newton algorithms are often more efficient at sum-of-squares minimization than the more generic BFGS optimizer. This form of Gauss-Newton optimization of prediction errors is also available through <a href="https://baggepinnen.github.io/ControlSystemIdentification.jl/dev/nonlinear/#Identification-of-nonlinear-models">ControlSystemIdentification.jl</a>, which uses this package undernath the hood.</p><h2 id="Which-method-should-I-use?"><a class="docs-heading-anchor" href="#Which-method-should-I-use?">Which method should I use?</a><a id="Which-method-should-I-use?-1"></a><a class="docs-heading-anchor-permalink" href="#Which-method-should-I-use?" title="Permalink"></a></h2><p>The methods demonstrated above have slightly different applicability, here, we try to outline which methods to consider for different problems</p><table><tr><th style="text-align: right">Method</th><th style="text-align: right">Parameter Estimation</th><th style="text-align: right">Covariance Estimation</th><th style="text-align: right">Time Varying Parameters</th><th style="text-align: right">Online Estimation</th></tr><tr><td style="text-align: right">Maximum likelihood</td><td style="text-align: right">🟢</td><td style="text-align: right">🟢</td><td style="text-align: right">🟥</td><td style="text-align: right">🟥</td></tr><tr><td style="text-align: right">Joint state/par estim</td><td style="text-align: right">🔶</td><td style="text-align: right">🟥</td><td style="text-align: right">🟢</td><td style="text-align: right">🟢</td></tr><tr><td style="text-align: right">Prediction-error opt.</td><td style="text-align: right">🟢</td><td style="text-align: right">🟥</td><td style="text-align: right">🟥</td><td style="text-align: right">🟥</td></tr></table><p>When trying to optimize parameters of the noise distributions, most commonly the covariance matrices, maximum-likelihood (or MAP) is the only recommened method. Similarly, when parameters are time varying or you want an online estimate, the method that jointly estimates state and parameter is the only applicable method. When fitting standard parameters, all methods are applicable. In this case the joint state and parameter estimation tends to be inefficient and unneccesarily complex, and it is recommended to opt for maximum likelihood or prediction-error minimization. The prediction-error minimization (PEM) with a Gauss-Newtown optimizer is often the most efficient method for this type of problem.</p><p>Maximum likelihood estimation tends to yield an estimator with better estimates of posterior covariance since this is explicitly optimized for, while PEM tends to produce the smallest possible prediction errors.</p><h2 id="Identifiability"><a class="docs-heading-anchor" href="#Identifiability">Identifiability</a><a id="Identifiability-1"></a><a class="docs-heading-anchor-permalink" href="#Identifiability" title="Permalink"></a></h2><h3 id="Polynomial-methods"><a class="docs-heading-anchor" href="#Polynomial-methods">Polynomial methods</a><a id="Polynomial-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Polynomial-methods" title="Permalink"></a></h3><p>There is no guarantee that we will recover the true parameters by perfoming parameter estimation, especially not if the input excitation is poor. For the system in this tutorial, we will generally find parameters that results in a good predictor for the system (this is after all what we&#39;re optimizing for), but these may not be the &quot;correct&quot; parameters. A tool like <a href="https://github.com/SciML/StructuralIdentifiability.jl">StructuralIdentifiability.jl</a> may be used to determine the identifiability of parameters and state variables (for rational systems), something that for this system could look like</p><pre><code class="language-julia hljs">using StructuralIdentifiability

ode = @ODEmodel(
    h1&#39;(t) = -a1/A1 * h1(t) + a3/A1*h3(t) +     gam*k1/A1 * u1(t),
    h2&#39;(t) = -a2/A2 * h2(t) + a4/A2*h4(t) +     gam*k2/A2 * u2(t),
    h3&#39;(t) = -a3/A3*h3(t)                 + (1-gam)*k2/A3 * u2(t),
    h4&#39;(t) = -a4/A4*h4(t)                 + (1-gam)*k1/A4 * u1(t),
	y1(t) = h1(t),
    y2(t) = h2(t),
)

local_id = assess_local_identifiability(ode)</code></pre><p>where we have made the substitution <span>$\sqrt h \rightarrow h$</span> due to a limitation of the tool (it currently only handles rational ODEs). The output of the above analysis is </p><pre><code class="language-julia hljs">julia&gt; local_id = assess_local_identifiability(ode)
Dict{Nemo.fmpq_mpoly, Bool} with 15 entries:
  a3  =&gt; 0
  gam =&gt; 1
  k2  =&gt; 0
  A4  =&gt; 0
  h4  =&gt; 0
  h2  =&gt; 1
  A3  =&gt; 0
  a1  =&gt; 0
  A2  =&gt; 0
  k1  =&gt; 0
  a4  =&gt; 0
  h3  =&gt; 0
  h1  =&gt; 1
  A1  =&gt; 0
  a2  =&gt; 0</code></pre><p>indicating that we can not hope to resolve all of the parameters. However, using appropriate regularization from prior information, we might still recover a lot of information about the system. Regularization could easily be added to the function <code>cost</code> above, e.g., using a penalty like <code>(p-p_guess)&#39;Γ*(p-p_guess)</code> for some matrix <span>$\Gamma$</span>, to indicate our confidence in the initial guess.</p><h3 id="Linear-methods"><a class="docs-heading-anchor" href="#Linear-methods">Linear methods</a><a id="Linear-methods-1"></a><a class="docs-heading-anchor-permalink" href="#Linear-methods" title="Permalink"></a></h3><p>This package also contains an interface to <a href="https://juliacontrol.github.io/ControlSystems.jl/stable/">ControlSystemsBase</a>, which allows you to call <code>ControlSystemsBase.observability(f, x, u, p, t)</code> on a filter <code>f</code> to linearize (if needed) it in the point <code>x,u,p,t</code> and assess observability using linear methods (the PHB test). Also <code>ControlSystemsBase.obsv(f, x, u, p, t)</code> for computing the observability matrix is available.</p><h2 id="Videos"><a class="docs-heading-anchor" href="#Videos">Videos</a><a id="Videos-1"></a><a class="docs-heading-anchor-permalink" href="#Videos" title="Permalink"></a></h2><p>Examples of parameter estimation are available here</p><p>By using an optimizer to optimize the likelihood of an <a href="../api/#LowLevelParticleFilters.UnscentedKalmanFilter-Union{Tuple{AUGM}, Tuple{AUGD}, Tuple{IPM}, Tuple{IPD}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any}, Tuple{Any, LowLevelParticleFilters.AbstractMeasurementModel, Any, Any}} where {IPD, IPM, AUGD, AUGM}"><code>UnscentedKalmanFilter</code></a>:</p><iframe style="height: 315px; width: 560px" src="https://www.youtube.com/embed/0RxQwepVsoM" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>Estimation of time-varying parameters:</p><iframe style="height: 315px; width: 560px" src="https://www.youtube.com/embed/zJcOPPLqv4A?si=XCvpo3WD-4U3PJ2S" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p>Adaptive control by means of estimation of time-varying parameters:</p><iframe style="height: 315px; width: 560px" src="https://www.youtube.com/embed/Ip_prmA7QTU?si=Fat_srMTQw5JtW2d" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../measurement_models/">« Multiple measurement models</a><a class="docs-footer-nextpage" href="../benchmark/">Benchmark »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.14.1 on <span class="colophon-date" title="Thursday 9 October 2025 07:06">Thursday 9 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
