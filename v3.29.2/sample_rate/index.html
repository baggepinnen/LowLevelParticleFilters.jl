<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Influence of sample rate on performance · LowLevelParticleFilters Documentation</title><meta name="title" content="Influence of sample rate on performance · LowLevelParticleFilters Documentation"/><meta property="og:title" content="Influence of sample rate on performance · LowLevelParticleFilters Documentation"/><meta property="twitter:title" content="Influence of sample rate on performance · LowLevelParticleFilters Documentation"/><meta name="description" content="Documentation for LowLevelParticleFilters Documentation."/><meta property="og:description" content="Documentation for LowLevelParticleFilters Documentation."/><meta property="twitter:description" content="Documentation for LowLevelParticleFilters Documentation."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">LowLevelParticleFilters Documentation</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../discretization/">Discretization</a></li><li><a class="tocitem" href="../measurement_models/">Multiple measurement models</a></li><li><span class="tocitem">Parameter estimation</span><ul><li><a class="tocitem" href="../parameter_estimation/">Overview</a></li><li><a class="tocitem" href="../param_est_ml/">Maximum-likelihood and MAP</a></li><li><a class="tocitem" href="../param_est_bayesian/">Bayesian inference</a></li><li><a class="tocitem" href="../param_est_joint/">Joint state and parameter estimation</a></li><li><a class="tocitem" href="../param_est_mukf/">MUKF for parameter estimation</a></li><li><a class="tocitem" href="../param_est_optimizer/">Using an optimizer</a></li><li><a class="tocitem" href="../param_est_identifiability/">Identifiability</a></li></ul></li><li><a class="tocitem" href="../benchmark/">Benchmark</a></li><li><a class="tocitem" href="../distributions/">Performance tips</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../adaptive_kalmanfilter/">Kalman-filter tutorial with LowLevelParticleFilters</a></li><li><a class="tocitem" href="../noisetuning/">Noise tuning and disturbance modeling for Kalman filtering</a></li><li><a class="tocitem" href="../beetle_example/">Particle-filter tutorial</a></li><li><a class="tocitem" href="../beetle_example_imm/">IMM-filter tutorial</a></li><li><a class="tocitem" href="../rbpf_example/">Rao-Blackwellized filter tutorial</a></li><li><a class="tocitem" href="../dae/">State estimation for DAE systems</a></li><li><a class="tocitem" href="../adaptive_control/">Adaptive estimation and control</a></li><li><a class="tocitem" href="../neural_network/">Adaptive Neural-Network training</a></li><li><a class="tocitem" href="../friction_nn_example/">SciML: Adaptive Universal Differential Equation</a></li><li><a class="tocitem" href="../thermal_nn_example/">SciML: Learning a sunshine disturbance model</a></li><li><a class="tocitem" href="../fault_detection/">Fault detection</a></li><li><a class="tocitem" href="../ut/">Unscented transform</a></li><li><a class="tocitem" href="../disturbance_gallery/">Disturbance gallery</a></li><li class="is-active"><a class="tocitem" href>Influence of sample rate on performance</a><ul class="internal"><li><a class="tocitem" href="#Example-1:-Double-integrator"><span>Example 1: Double integrator</span></a></li><li><a class="tocitem" href="#Example-2:-Double-integrator-with-friction"><span>Example 2: Double integrator with friction</span></a></li></ul></li><li><a class="tocitem" href="../cross_covariance/">Cross-covariance between dynamics and measurement</a></li></ul></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Influence of sample rate on performance</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Influence of sample rate on performance</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/baggepinnen/LowLevelParticleFilters.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/baggepinnen/LowLevelParticleFilters.jl/blob/master/docs/src/sample_rate.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Influence-of-sample-rate-on-performance"><a class="docs-heading-anchor" href="#Influence-of-sample-rate-on-performance">Influence of sample rate on performance</a><a id="Influence-of-sample-rate-on-performance-1"></a><a class="docs-heading-anchor-permalink" href="#Influence-of-sample-rate-on-performance" title="Permalink"></a></h1><p>Naturally, if we sample more often, we obtain more information about the system and can thus expect better performance. Frequent sampling allows for an averaging effect that can mitigate the influence of measurement noise. Sampling &quot;frequently enough&quot; is also important in order to rely on theoretical concepts such as observability when analyzing what modes of the system can be accurately recovered. To understand this, consider an extreme case: a particle subject to a random force where we can measure the position of the particle (this is a double integrator system). If we measure the position of the particle often, we can infer both the position and the velocity of the particle, the system is <em>observable</em>. However, if we measure the position rather infrequently, we can&#39;t say much about the velocity of the particle since the noisy force driving the particle will have had a large influence on the velocity, which isn&#39;t directly measured, since the last measurement of the position. When analyzing observability traditionally, we may compute</p><ul><li>The observability matrix. This can tell us the theoretical observable and unobservable subspaces of the system. One may take measurement noise into account by scaling the outputs to have equal variance, but one can not take driving noise properties into account.</li><li>The observability Gramian. This gives us a measure of how well we can estimate modes of the system in a balanced realization from the available measurements, but there is once again no way to take the driving noise into account.</li></ul><p>To estimate the <em>practical observability</em> of the system we may instead consider an analysis of the <em>stationary error covariance</em> of a state estimator. For a linear-Gaussian system observed with a Kalman filter, the stationary Kalman gain and error covariance is obtained by solving an algebraic Riccati equation:</p><p class="math-container">\[\begin{align}
x^+ &amp;= Ax + w\\
y &amp;= Cx + e \\
\\
x̂^+ &amp;= Ax̂ + K(y - Cx̂)  \qquad &amp;\text{estimator}\\
\\
ε &amp;= x - x̂ \qquad &amp;\text{prediction error}\\
ε^+ &amp;= Ax + w - \big(Ax̂ + K(y - Cx̂) \big) \qquad &amp;\text{prediction error dynamics}\\
ε^+ &amp;= Ax + w - \big(Ax̂ + K(Cx + e - Cx̂) \big)\\
ε^+ &amp;= (A - KC)ε + w - Ke \\
[E(we^T) &amp;= 0] \Longrightarrow \\
E\{(w - Ke)(w - Ke)^T\} &amp;= R_1 + K R_2 K^T
\end{align}\]</p><p>The stationary covariance of the prediction error <span>$ε(t+1|t)$</span>, <span>$R_∞(t+1|t) = E_∞(ε(t+1|t)ε(t+1|t)^T)$</span>, is automatically computed by the solver of the algebraic Riccati equation that computes the stationary Kalman gain <span>$K$</span>.</p><p>By incorporating the measurement, we form a <em>filtering estimate</em> <span>$ε(t|t)$</span> and in doing so, reduce the covariance of the prediction error according to <span>$R_∞(t|t) = (I - KC)R_∞(t|t-1)$</span>. </p><div class="admonition is-info" id="Note-9725f69bc6b90b38"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-9725f69bc6b90b38" title="Permalink"></a></header><div class="admonition-body"><p>Due to the exact formulation of <span>$K$</span> returned by the Riccati solver in MatrixEquations.jl, we must either use <span>$A^{-1}K$</span> or compute <span>$K = RC^T (R_2 + C R C^T)^{-1}$</span> ourselves. <code>MatrixEquations.ared</code> solves the Riccati equation corresponding to the filter form, but returns the <span>$K$</span> matrix for the prediction form. The matrix <span>$A$</span> is invertible as long as the system has no poles in the origin, which physical systems does not tend to have since this would correspond to either a pole at <span>$-\infty$</span> in continuous time, i.e., a non-proper system, or a pole with much faster dynamics than the chosen discretization time.</p></div></div><pre><code class="language-julia hljs">using ControlSystemsBase, LinearAlgebra
import ControlSystemsBase.MatrixEquations

function kalman_are(sys::AbstractStateSpace{&lt;:Discrete}, R1, R2)
    A,B,C,D = ssdata(sys)
    R∞, p, K, args... = MatrixEquations.ared(A&#39;, C&#39;, R2, R1)
    K&#39;, R∞, args...
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">kalman_are (generic function with 1 method)</code></pre><p>To perform an analysis of the performance as a function of the sample rate, we will assume that we have a continuous-time LTI system with a continuous-time Gaussian noise process driving the system. This will allow us to discretize both the system dynamics and noise process at varying sample rates and compute the stationary Kalman filter and associated stationary covariance matrix (see <a href="../discretization/#Discretization">Discretization</a> for more details). We assume that the measurement noise is a <em>discrete-time</em> noise process with a fixed covariance, representing a scenario where the sensor equipment is predetermined but the sample rate is not. </p><h2 id="Example-1:-Double-integrator"><a class="docs-heading-anchor" href="#Example-1:-Double-integrator">Example 1: Double integrator</a><a id="Example-1:-Double-integrator-1"></a><a class="docs-heading-anchor-permalink" href="#Example-1:-Double-integrator" title="Permalink"></a></h2><p>A double integrator can be thought of as a particle subject to a force, the continuous-time dynamics are <span>$\ddot x = w$</span>.</p><pre><code class="language-julia hljs">using ControlSystemsBase, Plots, Test
sysc  = ss([0 1; 0 0], [0; 1], [1 0], 0) # Continuous-time double integrator
R1c   = [0 0; 0 1]                       # Continuous-time process noise covariance
R2    = [1;;]                            # Measurement noise covariance

Ts    = 1                                # Sample interval
sysd  = c2d(sysc, Ts)                    # Discretize the system
R1d   = c2d(sysc, R1c, Ts)               # Discretize the process noise covariance
K, R∞ = kalman_are(sysd, R1d, R2)        # Compute the stationary Kalman gain and covariance
R∞</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2×2 Matrix{Float64}:
 3.1108   2.02751
 2.02751  2.03429</code></pre><p>Does the computed stationary covariance matrix match the expected covariance matrix we derived above? </p><pre><code class="language-julia hljs">A,B,C,D = ssdata(sysd)
@test lyap(Discrete, A-K*C, R1d + K*R2*K&#39;) ≈ R∞</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr32"><span class="sgr1">Test Passed</span></span></code></pre><p>For this system, we expect the stationary <em>filtering covariance</em> <span>$R_∞(t|t)$</span> to go to zero for small <span>$T_s$</span> since the system is observable. For large <span>$T_s$</span>, we expect the variance of the position estimate to approach the variance of the measurement noise, i.e., we don&#39;t expect the model to be of any use if it&#39;s forced to predict for too long. The variance of the velocity estimate is expected to go to infinity since the disturbance force has increasingly more time to affect the velocity and we cannot measure this. Let&#39;s investigate:</p><pre><code class="language-julia hljs">Tss = exp10.(LinRange(-3, 3, 30))
R∞s = map(Tss) do Ts
    sysd    = c2d(sysc, Ts)
    A,B,C,D = ssdata(sysd)
    R1d     = c2d(sysc, R1c, Ts)
    AK, R∞  = kalman_are(sysd, R1d, R2)

    # diag((I-A\AK*C)*R∞) # This also works

    K = (R∞*C&#39;)/(R2 + C*R∞*C&#39;)
    diag((I-K*C)*R∞)
end
plot(Tss, reduce(hcat, R∞s)&#39;, label=[&quot;\$σ^2 p\$&quot; &quot;\$σ^2 v\$&quot;], xlabel=&quot;Sample interval [s]&quot;, ylabel=&quot;Stationary filtering variance&quot;, title=&quot;Double integrator&quot;, xscale=:log10, yscale=:log10)
hline!(R2, label=&quot;\$R_2\$&quot;, linestyle=:dash, legend=:bottomright)</code></pre><img src="e670f201.svg" alt="Example block output"/><p>The plot confirms our expectations. Note: this plot shows the <em>filtering covariance</em>, the prediction-error covariance <span>$R_∞(t+1|t)$</span> would in this case go to infinity for both state variables.</p><h2 id="Example-2:-Double-integrator-with-friction"><a class="docs-heading-anchor" href="#Example-2:-Double-integrator-with-friction">Example 2: Double integrator with friction</a><a id="Example-2:-Double-integrator-with-friction-1"></a><a class="docs-heading-anchor-permalink" href="#Example-2:-Double-integrator-with-friction" title="Permalink"></a></h2><p>If we take the same system as above, but introduce some friction in the system, we expect similar behavior for small sample intervals, but for large sample intervals we expect the stationary variance of the velocity to converge to a finite value due to the dissipation of energy in the system:</p><pre><code class="language-julia hljs">sysc = ss([0 1; 0 -0.02], [0; 1], [1 0], 0) # Continuous-time double integrator with friction

R∞s = map(Tss) do Ts
    sysd    = c2d(sysc, Ts)
    A,B,C,D = ssdata(sysd)
    R1d     = c2d(sysc, R1c, Ts)
    AK, R∞  = kalman_are(sysd, R1d, R2)
    K       = (R∞*C&#39;)/(R2 + C*R∞*C&#39;)
    diag((I-K*C)*R∞)
end
plot(Tss, reduce(hcat, R∞s)&#39;, label=[&quot;\$σ^2 p\$&quot; &quot;\$σ^2 v\$&quot;], xlabel=&quot;Sample interval [s]&quot;, ylabel=&quot;Stationary filtering variance&quot;, title=&quot;Double integrator with friction&quot;, xscale=:log10, yscale=:log10)
hline!(R2, label=&quot;\$R_2\$&quot;, linestyle=:dash, legend=:bottomright)</code></pre><img src="3ab782b7.svg" alt="Example block output"/><p>Nice, it did.</p><p>If we instead look at the prediction-error covariance, we see the opposite behavior</p><pre><code class="language-julia hljs">R∞s = map(Tss) do Ts
    sysd   = c2d(sysc, Ts)
    R1d    = c2d(sysc, R1c, Ts)
    AK, R∞ = kalman_are(sysd, R1d, R2)
    diag(R∞)
end
plot(Tss, reduce(hcat, R∞s)&#39;, label=[&quot;\$σ^2 p\$&quot; &quot;\$σ^2 v\$&quot;], xlabel=&quot;Sample interval [s]&quot;, ylabel=&quot;Stationary filtering variance&quot;, title=&quot;Double integrator with friction&quot;, xscale=:log10, yscale=:log10)
hline!(R2, label=&quot;\$R_2\$&quot;, linestyle=:dash, legend=:bottomright)</code></pre><img src="10de8629.svg" alt="Example block output"/><p>in this case, the variance of the position prediction goes to infinity for large <span>$T_s$</span> since the position dynamics still contain a pure integrator. The velocity prediction variance still converges to a finite value, the same finite value as the filtering variance, which also happens to be the same value as we get by computing the stationary covariance of the noise filtered through the system without any Kalman filter. This indicates that the estimator is completely useless for large sample intervals and we can&#39;t predict the velocity any better than its long-term average:</p><pre><code class="language-julia hljs">velocity_dynamics = ss(-0.02, 1, 1, 0)
R∞s[end][end] ≈ lyap(velocity_dynamics, [1;;])[]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><h3 id="Convergence-of-time-varying-Kalman-filter"><a class="docs-heading-anchor" href="#Convergence-of-time-varying-Kalman-filter">Convergence of time-varying Kalman filter</a><a id="Convergence-of-time-varying-Kalman-filter-1"></a><a class="docs-heading-anchor-permalink" href="#Convergence-of-time-varying-Kalman-filter" title="Permalink"></a></h3><p>When the dynamics is time invariant and the noise process is stationary, the time-varying Kalman filter converges to the stationary Kalman filter irrespective of what the inputs and outputs are. We can confirm this by running a simulation of the time-varying Kalman filter and checking that the stationary covariance converges to the stationary covariance we computed above. </p><pre><code class="language-julia hljs">using LowLevelParticleFilters
Ts    = 1
sysd  = c2d(sysc, Ts)
R1d   = c2d(sysc, R1c, Ts)
_, R∞ = kalman_are(sysd, R1d, R2)
kf    = KalmanFilter(sysd, R1d, R2) # A Kalman filter can be constructed from a discrete-time system statespace model
for i = 1:1000 # Perform 1000 prediction and measurement updates to let the filter converge
    update!(kf, [0], [0])
end
@test kf.R ≈ R∞ # The Kalman filter prediction error covariance converges to the stationary covariance</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr32"><span class="sgr1">Test Passed</span></span></code></pre><pre><code class="language-julia hljs">(; K) = correct!(kf, [0], [0])   # Perform a measurement update
@test K ≈ (R∞*C&#39;)/(R2 + C*R∞*C&#39;) # The time varying Kalman gain converges to the stationary Kalman gain (direct form)
@test kf.R ≈ (I-K*C)*R∞          # The time varying Kalman filter filtering error covariance (after measurement update) converges to the stationary covariance</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr32"><span class="sgr1">Test Passed</span></span></code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../disturbance_gallery/">« Disturbance gallery</a><a class="docs-footer-nextpage" href="../cross_covariance/">Cross-covariance between dynamics and measurement »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Thursday 29 January 2026 05:49">Thursday 29 January 2026</span>. Using Julia version 1.11.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
